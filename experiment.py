'''
Experiment of checking the necessity of adversarial edges generated by Nettack.

Author: is hidden (under rewiew)
'''
import os
import signal
import time
import math
import copy
import json
import random
import pickle
import logging
from itertools import combinations
from ast import literal_eval
from collections import defaultdict, namedtuple
import multiprocessing
from multiprocessing import Pool
from functools import partial
from tqdm import tqdm
import numpy as np
import scipy.sparse as sp
import pandas as pd
import torch
import torch.nn.functional as F
import torch.multiprocessing as mp
from torch_geometric.utils import to_undirected, sort_edge_index, k_hop_subgraph, is_undirected, negative_sampling
from torch_geometric.data import Data
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, roc_auc_score, accuracy_score, confusion_matrix
from deeprobust.graph.defense import GCN, SGC
from deeprobust.graph.global_attack import PGDAttack, MinMax
from deeprobust.graph.targeted_attack import IGAttack, RND, SGAttack, FGA

import argument
import data_loader
from model.gnn import GNN
from nettack_adapter import adapte as ntk
from gf_attack_adapter import adapte as gfa
from robust_gcn_structure.certify import is_1perturbation_fragile_node
from gta import generate_topo_input, generate_masks, backdoor_attack
from gua import iterative_minimum_perturbation, minimum_attack, _iterative_minimum_perturbation
from mibtack.attack import MiBTack
from verify_attack import Minimum_MinMax_Attack
from verify_attack_new import OneShotAttack
from certified_gnn import find_non_robust_nodes
from certified_fragile_nodes import CertifiedFragilenessLazy
from unlearn import unlearn
from detection import LinkPredDetector, OutlierDetector, ProximityDetector, GraphGenDetect, JaccardSimilarity
import utils



def _result_filename(args, name):
    timestamp = time.time()
    # result_path = f'{name}_{args.target}_{args.dataset}_{args.node_sampler}{args.num_target_nodes}_{args.edge_sampler}'
    result_path = f'{name}_cvx_{args.dataset}_{args.candidate_method}{args.candidate_size}_{args.candidate_hop}hop_{args.node_sampler}{args.num_target_nodes}'
    result_path += f'_{int(timestamp)}.csv'
    return result_path

def _baseline_result_filename(args, name):
    timestamp = time.time()
    result_path = f'{name}_baseline_{args.dataset}_{args.node_sampler}{args.num_target_nodes}_{args.edge_sampler}{args.num_perts}'
    result_path += f'_{int(timestamp)}.csv'
    return result_path

def _target_model_filename(args, name):
    # timestamp = time.time()
    result_path = f'{name}_target_model_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pt'
    # result_path += f'_{int(timestamp)}.pt'
    return result_path
def _get_target_model_filename(args, name, t):
    result_path = f'{name}{t}_target_model_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pt'
    return result_path

def _surrogate_model_filename(args, name):
    # timestamp = time.time()
    result_path = f'{name}_surrogate_model_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pt'
    # result_path += f'_{int(timestamp)}.pt'
    return result_path
def _get_surrogate_model_filename(args, name, t):
    result_path = f'{name}{t}_surrogate_model_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pt'
    return result_path

def _data_filename(args, name):
    # timestamp = time.time()
    result_path = f'{name}_data_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    # result_path += f'_{int(timestamp)}.pkl'
    return result_path
def _get_data_filename(args, name, t):
    result_path = f'{name}{t}_data_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    return result_path

def _attack_labels_filename(args, name, method):
    result_path = f'{name}_attack_labels_{method}_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    return result_path
def _get_attack_labels_filename(args, name, method, t):
    result_path = f'{name}{t}_attack_labels_{method}_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    return result_path

def _candidates_filename(args, name, method):
    result_path = f'{name}_candidates_{method}_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    return result_path
def _get_candidates_filename(args, name, method, t):
    result_path = f'{name}{t}_candidates_{method}_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    return result_path

def _perturbations_filename(args, name, method):
    result_path = f'{name}_perturbations_{method}_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    return result_path
def _get_perturbations_filename(args, name, method, t):
    result_path = f'{name}{t}_perturbations_{method}_{args.dataset}_{args.node_sampler}{args.num_target_nodes}.pkl'
    return result_path

def _escape_probability(K, K_t, q):
    return math.comb(K_t, K) * (q ** K) * ((1 - q) ** (K_t - K))

def _call_certify(pair, surrogate, data):
     v, y_v = pair
     return is_1perturbation_fragile_node(surrogate, data, v, y_v)

def find_non_robust_nodes_margin(surrogate, data, candidates, predictions, device):
    """ Find the nodes that are not robust to perturbation of size 1
    """
    pool = Pool(processes=10)
    res = list(tqdm(
            pool.imap_unordered(
            partial(_call_certify, surrogate=surrogate, data=data), 
            zip(candidates, predictions)
        ), total=len(candidates), desc='certifing'))
    # one_pert_fragile_nodes = defaultdict(list)
    non_robust_nodes = []
    for v, r in zip(candidates, res):
        if r:
            non_robust_nodes.append(v)
            # one_pert_fragile_nodes[v].append(r)
        # for c, certified in r.items():
        #     if certified:
        #         one_pert_fragile_nodes[v].append(c)
    return non_robust_nodes

    # with tqdm(total=len(candidates), desc='certifing') as pbar:
    #     for v, y_v in zip(candidates, predictions):
    #         res = is_1perturbation_fragile_node(surrogate, data, v, y_v)
    #         for c, certified in res.items():
    #             if certified:
    #                 one_pert_fragile_nodes[v].append(c)
    #         # if len(one_pert_fragile_nodes) >= 2:
    #         #     break

    #         pbar.update(1)
            
    # return one_pert_fragile_nodes


def sample_node_tokens(args, data, candidate_nodes, 
                       surrogate_model=None, posterior=None,
                       amplify=3, max_degree=math.inf):
    num_target_nodes = args.num_target_nodes * amplify

    if args.node_sampler == 'random':
        # result = random.sample(candidate_nodes, min(args.num_target_nodes, len(candidate_nodes)))
        result = []
        while len(result) < num_target_nodes:
            node = random.choice(candidate_nodes)
            if node in result:
                continue
            degree = data.degree(node)
            if degree < max_degree:
                result.append(node)
            # result.append(node)
    elif args.node_sampler == 'purity':
        _candidates = []
        for v in candidate_nodes:
            subgraph = k_hop_subgraph(v, 1, data.edge_index)[0]
            if torch.unique(data.y[subgraph]).size(0) == 1:
                _candidates.append(v)

        result = []
        while len(result) < num_target_nodes:
            v = random.choice(_candidates)
            if v in result:
                continue
            degree = data.degree(v)
            if  degree < max_degree:
                result.append(v)
            
    elif args.node_sampler == 'homophily':
        node2homophily = {}
        for v in candidate_nodes:
            if data.degree(v) == 0:
                continue

            subgraph, _edge_index, _, _ = k_hop_subgraph(v, 2, data.edge_index, relabel_nodes=True)
            node2homophily[v] = utils.homophily(
                subgraph.tolist(), 
                utils.to_directed(_edge_index).t().tolist(),
                data.y[subgraph].tolist()
            )
            # node2homophily[v] = utils.homophily_entropy(data.num_classes, data.y[subgraph])

        sorted_node2homophily = {k: v for k,v in sorted(node2homophily.items(), key=lambda item: item[1])}
        # sorted_node2homophily = {k: v for k,v in sorted(node2homophily.items(), key=lambda item: item[1], reverse=True)}
        _candidate_tokens = list(sorted_node2homophily.keys())
        if args.num_target_nodes == 1:
            v = random.choice(_candidate_tokens[:10])
            result = [v]
        else:
            i = 0
            result = []
            while len(result) < num_target_nodes:
                n = _candidate_tokens[i]
                degree = data.degree(n)
                if degree < max_degree:
                    result.append(n)
                # result.append(n)
                i += 1
            # result = _candidate_tokens[:args.num_target_nodes]
    # elif args.node_sampler == 'certify':
    #     result = find_certified_nodes(args, surrogate_model, data, utils.get_device(args))
    elif args.node_sampler == 'boundary' or args.node_sampler == 'distance':
        assert surrogate_model is not None or posterior is not None, 'Invalid input, at least one of surrogate model and posterior is not None.'
        if posterior is None:
            _, posterior = surrogate_model.predict(data, utils.get_device(args), target_nodes=candidate_nodes, return_posterior=True)

        near_boundary_nodes = {}
        for idx, p in enumerate(posterior):
            # if utils.near_boundary(z, args.k):
            near_boundary_nodes[candidate_nodes[idx]] = utils.boundary_score(p)
        sorted_boundary_nodes = {k: v for k,v in sorted(near_boundary_nodes.items(), key=lambda item: item[1], reverse=args.node_sampler=='distance')}
        theta_idx = np.where(np.array(list(sorted_boundary_nodes.values())) >= args.theta)[0][0] 
        print('theta_idx', theta_idx)
        _candidate_tokens = list(sorted_boundary_nodes.keys())[theta_idx:]

        if args.num_target_nodes == 1:
            while True:
                v = random.choice(_candidate_tokens[:10])
                degree = data.degree(v)
                if degree < 10:
                    break
            # v = random.choice(_candidate_tokens[:10])
            result = [v]
        else:
            i = 0
            result = []
            while len(result) < num_target_nodes:
                try:
                    n = _candidate_tokens[i]
                except IndexError as e:
                    print('IndexError', e, ', _candidate_tokens:', _candidate_tokens, ', i=', i)
                    raise e
                degree = data.degree(n)
                if degree >= max_degree:
                    continue
                # result.append(n)
                if len(result) == 0:
                    result.append(n)
                in_2hop = False
                for c in result:
                    if data.distance(n, c) <= 2:
                        in_2hop = True
                        break
                if not in_2hop:
                    result.append(n)
                i += 1
        # result = list(sorted_boundary_nodes.keys())[:min(len(candidate_nodes), args.num_target_nodes)]
        # return {v: sorted_boundary_nodes[v] for v in result}
    elif args.node_sampler == 'cluster':
        result = [400, 1796, 2768,  166, 1735, 3170, 1638, 1870, 1919, 3211, 1113, 2318,
                  1221, 1691,  833, 2337,  159, 2948,  462, 1729, 1993, 1270,  479, 1926,
                  354, 1688, 1595, 1265,  817, 2616,  368, 2721, 1231,  816, 2671,  182,
                  2138,  674, 2658,   44, 1656,  508, 3248, 1968, 3265, 2262, 2838,  569,
                  2496, 1107, 2094, 3012,   62,   68,  412, 3257, 1863, 2043, 3086, 2836,
                  1797, 1047,   21, 1073,  623, 3182, 1817, 2562, 1390,  987,  782,  285,
                  419, 1963,  875, 1574, 2979, 1477, 2567, 2548, 2051,  605, 2296, 3084,
                  2160, 2031,   80,  678, 1446,  494, 1530, 2344, 1164, 1849, 2634, 2231,
                  1784, 3216, 2963,  319]
    elif args.node_sampler == 'first_order':
        p = torch.from_numpy(posterior)
        return torch.topk(-p.max(-1).values, k=args.num_target_nodes).indices.tolist()
    elif args.node_sampler == 'certify':
        result = find_non_robust_nodes(args, surrogate_model, data, candidate_nodes)
    elif args.node_sampler == 'margin':
        pass
        # device = utils.get_device(args)
        # assert surrogate_model is not None or posterior is not None, 'Invalid input, at least one of surrogate model and posterior is not None.'
        # if posterior is None:
        #     predictions, _ = surrogate_model.predict(data, device, target_nodes=candidate_nodes, return_posterior=True)
        # else:
        #     predictions = posterior.argmax(-1)

        # one_pert_fragile_nodes = find_1perturbation_fragile_nodes(surrogate_model.model, data, candidate_nodes, predictions, device)
        # print('one_pert_fragile_nodes', one_pert_fragile_nodes)
        # return one_pert_fragile_nodes
    else:
        raise NotImplementedError('Unknow node sampler:', args.node_sampler)

    print(f'Found {args.num_target_nodes} {args.node_sampler} target nodes nodes.')
    return result

def sample_edge_tokens_batch(args, data, target_nodes, surroget_model, predictions):
    device = utils.get_device(args)
    E_t = minimum_attack(surroget_model, data, target_nodes, predictions, device)
    return E_t 

def sample_edge_tokens(args, data, target_node, surrogate_model=None, prediction=None, label=None, target_label=None):
    if args.edge_sampler == 'nettack':
        assert surrogate_model is not None, f'Invalid input, did not find surrogate model.'
        assert prediction is not None, f'Invalid input, did not find prediction.'
        # assert label is not None, f'Invalid input, did not find label.'
        # n_perturbations = random.randint(data.degree(target_node), data.degree(target_node) * 2)
        n_perturbations = args.num_perts
        # if args.node_sampler == 'certify':
        #     n_perturbations = args.local_changes
        # elif data.degree(target_node) <= 1:
        #     n_perturbations = 2
        # else:
        #     n_perturbations = min(data.degree(target_node), 10)
        nettack = ntk(surrogate_model, data, target_node, prediction, target_label=target_label)
        nettack.reset()
        nettack.attack_surrogate(n_perturbations, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
        E_t = nettack.structure_perturbations
        # _edge_index = to_undirected(torch.tensor(nettack.structure_perturbations).t())
    elif args.edge_sampler == 'gua':
        device = utils.get_device(args)
        # n_perturbations = int(data.degree(target_node)) if data.degree(target_node) > 1 else 2
        n_perturbations = 1
        # if data.degree(target_node) <= 1:
        #     n_perturbations = 2
        # else:
        #     n_perturbations = min(data.degree(target_node), 10)
        # E_t = _iterative_minimum_perturbation(surrogate_model, data, target_node, prediction[0], device, n_perturbation=n_perturbations)
        E_t = iterative_minimum_perturbation(surrogate_model, data, target_node, prediction[0], device, n_perturbation=n_perturbations)
    elif args.edge_sampler == 'gf':
        device = utils.get_device(args)
        # n_perturbations = int(data.degree(target_node)) if data.degree(target_node) > 1 else 2
        n_perturbations = args.num_perts
        # if data.degree(target_node) <= 1:
        #     n_perturbations = 2
        # else:
        #     n_perturbations = min(data.degree(target_node), 10)
        gf_attack = gfa(data, target_node, n_perturbations, device)
        E_t = gf_attack.structure_perturbations
    elif args.edge_sampler == 'mibtack':
        device = utils.get_device(args)
        # E_t = mibtack(args, surrogate_model, data, target_node, prediction, device)
        mibtack = MiBTack(
            surrogate_model.model, data, device, 
            target=args.target, dataset=args.dataset, verbose=False,
            explore=False
        )
        E_t = mibtack.attack(target_node, label, prediction)
    elif args.edge_sampler == 'ig':
        device = utils.get_device(args)
        # contruct features sparse
        row, col = np.where(data.x.numpy() == 1)
        value = np.ones((len(row)))
        x = sp.csr_matrix((value, (row, col)), shape=data.x.shape)
        labels = data.y.numpy()

        row = data.edge_index.numpy()[0]
        col = data.edge_index.numpy()[1]
        value = np.ones((len(row)))
        adj = sp.csr_matrix((value, (row, col)), shape=(data.num_nodes, data.num_nodes))

        attacker = IGAttack(surrogate_model, data.num_nodes, attack_structure=True, attack_features=False, device=device).to(device)
        n_perturbations = args.num_perts
        attacker.attack(x, adj, labels, data.train_set.nodes.tolist(), target_node, n_perturbations=n_perturbations, steps=10)
        perturbed_edges = np.array(np.where(attacker.modified_adj != adj.toarray()))
        perturbed_edges = perturbed_edges[:, perturbed_edges[0] < perturbed_edges[1]]
        E_t = list(map(tuple, perturbed_edges.T.tolist()))
    elif args.edge_sampler == 'pgd':
        device = utils.get_device(args)
        surrogate = GCN(nfeat=data.num_features, nclass=data.num_classes, nhid=16, with_relu=True, with_bias=False, device=device).to(device)
        # contruct adjacency matrix
        row = data.edge_index.numpy()[0]
        col = data.edge_index.numpy()[1]
        value = np.ones((len(row)))
        adj = torch.sparse_coo_tensor(
            (row, col), value, size=(data.num_nodes, data.num_nodes), dtype=torch.int
        ).to_dense().numpy()
        surrogate.fit(data.x, adj, data.y, data.train_set.nodes.tolist(), data.valid_set.nodes.tolist())
        # contruct features sparse
        # row, col = np.where(data.x.numpy() == 1)
        # value = np.ones((len(row)))
        # x = sp.csr_matrix((value, (row, col)), shape=data.x.shape)
        # labels = data.y.numpy()

        attacker = PGDAttack(surrogate, data.num_nodes, loss_type='CE', device=device).to(device)
        # n_perturbations = data.degree(target_node) if data.degree(target_node) > 1 else 2
        n_perturbations = args.num_perts
        attacker.attack(data.x.numpy(), adj, data.y.numpy(), data.train_set.nodes.tolist(), target_node, n_perturbations=n_perturbations)
        modified_adj = attacker.modified_adj.cpu().numpy()
        perturbed_edges = np.array(np.where(modified_adj != adj))
        perturbed_edges = perturbed_edges[:, perturbed_edges[0] < perturbed_edges[1]]
        # print(perturbed_edges)
        E_t = list(map(tuple, perturbed_edges.T.tolist()))

    elif args.edge_sampler == 'minmax':
        device = utils.get_device(args)
        surrogate = GCN(nfeat=data.num_features, nclass=data.num_classes, nhid=16, with_relu=True, with_bias=False, device=device).to(device)
        adj = data.adjacency_matrix().to_dense().numpy()
        surrogate.fit(data.x, adj, data.y, data.train_set.nodes.tolist(), data.valid_set.nodes.tolist())

        attacker = MinMax(surrogate, data.num_nodes, loss_type='CW', device=device).to(device)
        # n_perturbations = data.degree(target_node) if data.degree(target_node) > 1 else 2
        n_perturbations = args.num_perts
        # if data.degree(target_node) <= 1:
        #     n_perturbations = 2
        # else:
        #     n_perturbations = min(data.degree(target_node), 10)
        idx_nodes = data.train_set.nodes.to(device)
        attacker.attack(data.x.numpy(), adj, data.y.numpy(), idx_nodes, target_node, n_perturbations=n_perturbations+2)
        modified_adj = attacker.modified_adj.cpu().numpy()
        perturbed_edges = np.array(np.where(modified_adj != adj))
        perturbed_edges = perturbed_edges[:, perturbed_edges[0] < perturbed_edges[1]]
        E_t = list(map(tuple, perturbed_edges.T.tolist()))[:n_perturbations]

    elif args.edge_sampler == 'independent':
        # n_perturbations = int(data.degree(target_node)) if data.degree(target_node) > 1 else 2
        n_perturbations = random.randint(data.degree(target_node), data.degree(target_node) * 2)
        # find uninfected nodes and randomly generate edges
        k_hop_nodes, _, _, _ = k_hop_subgraph(target_node, 2, edge_index=data.edge_index)
        nodes = torch.arange(data.num_nodes)
        uninfected_nodes = nodes[~torch.isin(nodes, k_hop_nodes)]
        uninfected_edges, adv_nodes = [], []
        while len(uninfected_edges) < n_perturbations:
            u, v = random.sample(uninfected_nodes.tolist(), 2)
            comp = torch.isin(data.edge_index, torch.tensor([u, v]))
            if torch.sum(comp[0] & comp[1]) == 0:
                uninfected_edges.append([u, v])
                adv_nodes.extend([u, v]) 
        E_t = uninfected_edges
        # _edge_index = to_undirected(torch.tensor(uninfected_edges).t())
    elif args.edge_sampler == 'ours':
        attacker = OneShotAttack(surrogate_model, data)
        adj = data.adjacency_matrix()
        E_t = attacker.attack(data.x, adj, torch.tensor([prediction]), target_node)

        # attacker = Minimum_MinMax_Attack(surrogate_model, data)
        # adj = data.adjacency_matrix()
        # E_t = attacker.attack(data.x, adj, torch.tensor([prediction]), target_node)
    return E_t


def check_incompleteness(args, target_node, clean_pred, adv_pred, adv_data, triggers, device, type=None):
    # print('perturbations', triggers)
    incompleteness = False
    for length in range(len(triggers) - 1, 0, -1):
        for _edges in combinations(triggers, length):
            sub_adv_data = copy.deepcopy(adv_data)
            sub_adv_data.remove_edges(_edges)

            if type is not None:
                if type == '1-layer':
                    sub_adv_model = GNN(args, sub_adv_data.num_features, sub_adv_data.num_classes, surrogate=False, fix_weight=True, layer1=True)
                elif type == 'standard':
                    sub_adv_model = GNN(args, sub_adv_data.num_features, sub_adv_data.num_classes, surrogate=False, fix_weight=True)
                elif type == 'large':
                    args.hidden_size = 64
                    sub_adv_model = GNN(args, sub_adv_data.num_features, sub_adv_data.num_classes, surrogate=False, fix_weight=True)
                    args.hidden_size = 16
            else:
                sub_adv_model = GNN(args, sub_adv_data.num_features, sub_adv_data.num_classes, surrogate=False, fix_weight=True)
            sub_adv_model.train(sub_adv_data, device)
            sub_adv_pred = sub_adv_model.predict(sub_adv_data, device, target_nodes=[target_node])            
            # print(' testing subset', _edges, 'the prediction is', sub_adv_pred[0])
            # print(f'  testing {_edges}, the prediction is {sub_adv_pred[0]}')
            # count how many subsets have diff prediction than all triggers
            if sub_adv_pred[0].item() != adv_pred:
                incompleteness = True
                # print('  testing subset', _edges, 'the prediction is', sub_adv_pred[0], 'and the adv prediction is', adv_pred)
                break
            # find a subset that flips the prediction back to be equal to clean prediction
            # if adv_pred != sub_adv_pred[0]: 
            #     flip_back_clean = True
            #     failed_comb = _edges
            #     print(f'under the combination of {_edges}, the prediction is {sub_adv_pred[0]}, and the clean prediction is {clean_pred}')
            #     break

        if incompleteness:
            break

    # return flip_back_clean, failed_comb
    # print(f'node {target_node}:  total number of combinations: {total_comb}, number of completeness: {complete_count}')
    return incompleteness


def _get_target_model(args, data, device, type=None):
    # suppose the verifier has the full access of dataset
    if args.gcn_type is not None:
        if args.gcn_type == '1-layer':
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False, layer1=True)
        elif args.gcn_type == 'standard':
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
    else:
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
    target_model.train(data, device)
    return target_model

def _vary_surrogate(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False
        args.seed = random.randint(-1e+5, 1e+5)
    ts = int(time.time())

    data = data_loader.load(args)

    target_model = _get_target_model(args, data, device)
    target_preds, target_posts = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist(), return_posterior=True)
    surrogate_data = copy.deepcopy(data)
    surrogate_data.train_set.y = target_preds

    result = defaultdict(list)
    for t in range(5):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        seed_file = f'surrogate_seed_{t}_{args.dataset}_{ts}.pkl'
        with open(os.path.join('intermediate', seed_file), 'wb') as fp:
            pickle.dump(args.seed, fp)

        for surrogate_type in ['simplified', '3-layer']:
            # simplified GCN as surrogate model
            if surrogate_type == 'simplified':
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False)
            elif surrogate_type == '3-layer':
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=True)
            surrogate.train(surrogate_data, device)

            weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
            verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False)
            # prediction, posterior = surrogate.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
            # c_star, p_star = [], []
            predictions, posteriors = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
            c_star = _second_best_labels(posteriors)
            t0 = time.time()
            num_processes = 5
            with multiprocessing.Pool(processes=num_processes) as pool:
                pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
                v_star = multiprocessing.Manager().list()
                e_star = multiprocessing.Manager().list()
                iter_count = multiprocessing.Value('i', 0)
                for v, perb in pool.imap_unordered(
                    partial(certify_fragile_with_perturbations, args=args, verifier=verifier, data=data),
                    zip(data.test_set.nodes.tolist(), predictions, c_star)
                ):
                    if perb is not None:
                        v_star.append(v)
                        e_star.append(perb)
                        pbar.update(1)
                    else:
                        pass
                    if len(v_star) == args.num_target_nodes:
                        break
                    iter_count.value += 1
                        # if iter_count == args.num_target_nodes:
                        #     break

            # p_star = target_model.predict(data, device, target_nodes=list(v_star))
            preparation_time = time.time() - t0
            # ts = int(time.time())
            data_filename = _data_filename(args, f'surrogate{t}_{ts}_{surrogate_type}')
            with open(os.path.join('intermediate', data_filename), 'wb') as fp:
                pickle.dump(data, fp)
            perturbations_filename = _perturbations_filename(args, f'surrogate{t}_{ts}_{surrogate_type}', 'ours')
            with open(os.path.join('intermediate', perturbations_filename), 'wb') as fp:
                pickle.dump(list(e_star), fp)
            candidates_filename = _candidates_filename(args, f'surrogate{t}_{ts}_{surrogate_type}', 'ours')
            with open(os.path.join('intermediate', candidates_filename), 'wb') as fp:
                pickle.dump(list(v_star), fp)
            attack_labels_filename = _attack_labels_filename(args, f'surrogate{t}_{ts}_{surrogate_type}', 'ours')
            with open(os.path.join('intermediate', attack_labels_filename), 'wb') as fp:
                pickle.dump(list(c_star), fp)
            target_filename = _target_model_filename(args, f'surrogate{t}_{ts}_{surrogate_type}')
            target_model.save_model(os.path.join('intermediate', target_filename))
            surrogate_filename = _surrogate_model_filename(args, f'surrogate{t}_{ts}_{surrogate_type}')
            surrogate.save_model(os.path.join('intermediate', surrogate_filename))
            print('preparation time:', preparation_time)

def compare_node_samplers(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
    else:
        args.seed = random.randint(-1e+5, 1e+5)

    data = data_loader.load(args)

    target_model = _get_target_model(args, data, device)
    target_preds, target_posts = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist(), return_posterior=True)
    
    surrogate_data = copy.deepcopy(data)
    surrogate_data.train_set.y = target_preds
    surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False)
    surrogate.train(surrogate_data, device)

    candidates = data.train_set.nodes.tolist()
    args.node_sampler = 'boundary'
    boundary_ours = sample_node_tokens(args, data, candidates, surrogate, torch.from_numpy(target_posts))

    args.node_sampler = 'first_order'
    boundary_first_order = sample_node_tokens(args, data, candidates, surrogate, torch.from_numpy(target_posts))

    print('boundary_ours', boundary_ours[:20])
    print('boundary_theirs', boundary_first_order[:20])

    print('Union size:', len(set(boundary_ours + boundary_first_order)))
    print('Intersection size:', len(set(boundary_ours).intersection(set(boundary_first_order))))

def _second_best_labels(posteriors):
    """ Get the second best label based on the posterior.
    """
    return np.argsort(posteriors, axis=1)[:, -2]

def _adv_predict_without_retrain(args, model, data, perturbations, target_nodes, device):
    adv_data = copy.deepcopy(data)
    adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
    adv_pred = model.predict(adv_data, device, target_nodes=target_nodes)
    return adv_pred

def _adv_train_predict(args, data, perturbations, target_nodes, device, type=None):
    adv_data = copy.deepcopy(data)
    adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))

    if type is not None:
        if type == '1-layer':
            adv = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True, layer1=True)
        elif type == 'standard':
            adv = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        elif type == 'large':
            args.hidden_size = 64
            adv = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            args.hidden_size = 16
        elif type == '3-layer':
            args.hidden_size = 16
            adv = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False, layer3=True)
        else:
            raise ValueError(f'Unknown type {type}')
    else:
        adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
    adv.train(adv_data, device)
    adv_pred = adv.predict(adv_data, device, target_nodes=target_nodes)
    return adv_pred

def _unlearn_train_predict(args, data, perturbations, target_nodes, device, type=None):
    t0 = time.time()
    unlearn_data = copy.deepcopy(data)
    unlearn_data.remove_edges(perturbations)
    if type is not None:
        if type == '1-layer':
            unlearn = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True, layer1=True)
        elif type == 'standard':
            unlearn = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        elif type == 'large':
            args.hidden_size = 64
            unlearn = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            args.hidden_size = 16
        elif type == '3-layer':
            args.hidden_size = 16
            unlearn = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True, layer3=True)
        else:
            raise ValueError(f'Unknown type {type}')
    else:
        unlearn = GNN(args, unlearn_data.num_features, unlearn_data.num_classes, surrogate=False, fix_weight=True)
    unlearn.train(unlearn_data, device)
    retrain_time = time.time() - t0

    t0 = time.time()
    unlearn_pred = unlearn.predict(unlearn_data, device, target_nodes=target_nodes)
    verify_time = time.time() - t0
    return unlearn_pred, verify_time, retrain_time

def _verify(target_label, args, verifier, data, target_node, prediction, device):
    if args.candidate_method == 'label':
        # Method 1: random sample nodes based on their labels
        candidates = data.train_set.nodes[data.train_set.y == target_label].tolist()
    elif args.candidate_method == 'twohop':
        # Method 2: two-hop neighbors
        candidates = data.neighbors([target_node], l=2).tolist()
    elif args.candidate_method == 'random':
        candidates = random.sample(data.train_set.nodes.tolist(), args.candidate_size)
    else:
        raise NotImplementedError('Invalid candidate method:', args.candidate_method)

    if len(candidates) > args.candidate_size:
        candidates = random.sample(candidates, args.candidate_size)
    candidates.insert(0, target_node)

    t0 = time.time()
    res = verifier.certify(target_node, prediction, target_label, candidates=candidates, solver=args.solver)
    print(f'  ==> certifing {target_label} done, time:', time.time() - t0)

    res['candidates'] = candidates
    if res['fragile']:
        t0 = time.time()
        perturbations = res['perturbations']

        _single_predictions = []
        for e in perturbations[:5]: # Maximum 5 perturbation for speed up
            if isinstance(e, list) or isinstance(e, np.ndarray):
                e = tuple(e)
            single_adv_pred = _adv_train_predict(args, data, [e], [target_node], device)[0]
            _single_predictions.append(single_adv_pred.item())
        union_adv_pred = _adv_train_predict(args, data, [e], [target_node], device)[0].item()

        res['target_label'] = target_label
        res['single_predictions'] = _single_predictions
        res['union_predictions'] = union_adv_pred
        res['first_one_verified'] = _single_predictions[0] == target_label
        res['at_least_one_verified'] = target_label in _single_predictions
        res['all_verified'] = np.all(np.array(_single_predictions) == target_label).item()
        print(f'  ==> verify {target_label} done, time:', time.time() - t0)

    return res

def _verify_fragileness(iter_inputs, args, model, verifier, data, device):
    target_node, prediction, target_posterior = iter_inputs
    attack_label = _second_best_labels([target_posterior])[0].item()

    v_fragileness = {
        'target_node': target_node,
        'ground_truth': data.y[target_node].item(),
        'prediction': prediction,
        'second_best_label': attack_label,
        'posterior': target_posterior.tolist(),
        '1-hop label dist': data.label_distribution(target_node, 1).tolist(),
        '2-hop label dist': data.label_distribution(target_node, 2).tolist(),
        'certified': {}
    }

    # for target_label in range(data.num_classes):
    success_count = 0
    for i in range(args.num_perts):
        # if target_label == prediction:
        #     continue
        # if target_label != attack_label:
        #     continue

        if args.candidate_method == 'label':
            # Method 1: random sample nodes based on their labels
            candidates = data.train_set.nodes[data.train_set.y == attack_label].tolist()
            candidates = list(set(candidates) - set(data.adj_list[target_node]))
            
            # filter out the candidates whose majority neighbors are target label.
            # candidates = []
            # for candidate in _candidates:
            #     dist = data.label_distribution(candidate, 1)
            #     _dist = dist / np.sum(dist)
            #     if _dist[target_label] >= 0.5:
            #         candidates.append(candidate) 
        elif args.candidate_method == 'twohop':
            # Method 2: two-hop neighbors
            candidates = data.neighbors([target_node], l=2).tolist()
        elif args.candidate_method == 'random':
            candidates = random.sample(data.train_set.nodes.tolist(), args.candidate_size)
        else:
            raise NotImplementedError('Invalid candidate method:', args.candidate_method)
        
        if len(candidates) > args.candidate_size:
            candidates = random.sample(candidates, args.candidate_size)
        # candidates.insert(0, target_node)

        if args.verbose:
            print('  ==> certifing', target_node, '...')
        t0 = time.time()
        res = verifier.certify(target_node, prediction, attack_label, candidates=candidates, solver=args.solver)
        if attack_label not in v_fragileness['certified']:
            v_fragileness['certified'][attack_label] = {}

        if args.verbose:
            print('  ==> certifing', target_node, f', done, in {(time.time() - t0):.2f}s with {len(candidates)} candidates.')
        if res['error']:
            print('  ==> certifing', target_node, 'error:', res['error'])
            v_fragileness['certified'][attack_label][i] = {
                'candidates': candidates,
                'error': True,
            }
            continue

        v_fragileness['certified'][attack_label][i] = {
            'candidates': candidates,
            'neighbors': res['neighbors'],
            'perturbations': res['perturbations'],
            'adj_diff': str(res['adj_diff']),
            # 'adj': verifier._adj,
            # 'adj_pert': res['adj_pert'],
            'fragile': res['fragile'],
            'fragile_score': res['fragile_score'],
            'logit_diff_before': str(res['logit_diff_before']), 
        }

        _single_predictions = []
        _single_predictions_wo_retrain = []
        if res['fragile']:
            for idx, e in enumerate(res['perturbations'][:1]): # Maximum 5 perturbation for speed up
                if isinstance(e, list) or isinstance(e, np.ndarray):
                    e = tuple(e)
                single_adv_pred = _adv_train_predict(args, data, [e], [target_node], device)[0]
                if idx == 0:
                    if single_adv_pred != attack_label:
                        print(f'target {target_node}, pred: {prediction}, attack label {attack_label}')
                        print(f'  ==> single adv pred {single_adv_pred}, perturbation {e}')
                        for n in e:
                            data.detail_info(n)
                        print('  ==> adj diff', res['adj_diff'])
                        e2 = res['perturbations'][1]
                        double_adv_pred = _adv_train_predict(args, data, [e, e2], [target_node], device)[0]
                        if double_adv_pred == attack_label:
                            print(f'  ==> double perturbations work')
                        else:
                            print(f'  ==> double perturbations do not work, adv pred {double_adv_pred}, ')
                    else:
                        success_count += 1

                single_adv_pred_wo_retrain = _adv_predict_without_retrain(args, model, data, [e], [target_node], device)[0]
                _single_predictions_wo_retrain.append(single_adv_pred_wo_retrain.item())
                _single_predictions.append(single_adv_pred.item())
            union_adv_pred = _adv_train_predict(args, data, [e], [target_node], device)[0].item()

            v_fragileness['certified'][attack_label][i].update({
                'single_predictions':  _single_predictions,
                'single_predictions_wo_retrain': _single_predictions_wo_retrain,
                'union_predictions': union_adv_pred,
                'first_one_verified': _single_predictions[0] == attack_label,
                'at_least_one_verified': attack_label in _single_predictions,
                'all_verified': np.all(np.array(_single_predictions) == attack_label).item(),
            })
        else:
            print(target_node, 'is not fragile.')
        
        # v_fragileness['certified'][target_label] = certified
    print('The success count of 1-perturbation:', success_count)
    return v_fragileness

def _verify_fragileness_mp(args, model, data, target_node, prediction, second_label, device):
    # target_labels = list(range(data.num_classes))
    # target_labels.remove(prediction)
    target_labels = [second_label]

    verifier = CertifiedFragileness(args, model, data, device, verbose=False)
    pool = Pool(processes=len(target_labels))
    res = list(pool.imap_unordered(
            partial(
                _verify, args=args, verifier=verifier, data=data, target_node=target_node, 
                prediction=prediction, device=device
            ),
            target_labels
    ))
    certified = {}
    for r in res:
        if r['fragile']:
            certified[r['target_label']] = {
                'candidates': r['candidates'],
                'neighbors': r['neighbors'],
                'perturbations': r['perturbations'],
                'adj_diff': str(r['adj_diff']),
                'fragile': True,
                'fragile_score': r['fragile_score'],
                'logit_diff_before': str(r['logit_diff_before']),
                'single_predictions': r['single_predictions'],
                'union_predictions': r['union_predictions'],
                'first_one_verified': r['first_one_verified'],
                'at_least_one_verified': r['at_least_one_verified'],
                'all_verified': r['all_verified'],
                # 'adj_pert': r['adj_pert'],
            }
    return certified

def verify_1perturbation_fragile_nodes(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        if_fix_seed = True
    else:
        is_fix_seed = False
    
    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fix_seed:
            args.seed = random.randint(-1e+5, 1e+5)
        data = data_loader.load(args)

        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        target_test_preds = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist())
        res_target = target_model.evaluate(data, device)
        print('The results of target model:', res_target)

        # surrogate_data = copy.deepcopy(data)
        # surrogate_data.train_set.y = target_train_preds 
        # surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, bias=args.edge_sampler != 'nettack', fix_weight=not args.cpf_random)
        # surrogate.train(surrogate_data, device)

        if args.node_sampler == 'margin':
            candidates = find_non_robust_nodes_margin(target_model.model, data, data.test_set.nodes.tolist(), target_test_preds, device)
        elif args.node_sampler == 'smooth':
            candidates = find_non_robust_nodes(args, target_model, data, data.test_set.nodes.tolist())
        elif args.node_sampler == 'boundary':
            candidates = sample_node_tokens(args, data, data.test_set.nodes.tolist(), target_model, amplify=1)
        elif args.node_sampler == 'high_degree':
            node2degree = {v: data.degree(v) for v in data.test_set.nodes.tolist()}
            sorted_node2degree = {k: v for k,v in sorted(node2degree.items(), key=lambda item: item[1], reverse=True)}
            candidates = list(sorted_node2degree.keys())[:args.num_target_nodes]
        elif args.node_sampler == 'all':
            if args.num_target_nodes == -1:
                candidates = data.test_set.nodes.tolist()
            else:
                candidates = random.sample(data.test_set.nodes.tolist(), args.num_target_nodes)
        else:
            raise ValueError('Invalid node sampler:', args.node_sampler)
        
        print(f'{args.node_sampler} sampler found {len(candidates)} candidates.')

        target_preds, posteriors = target_model.predict(data, device, target_nodes=candidates, return_posterior=True)
        second_best_labels = _second_best_labels(posteriors)
        verifier = CertifiedFragileness(args, target_model, data, device, verbose=False)

        # for i in range(len(candidates)):
        #     _verify_fragileness((candidates[i], target_preds.tolist()[i], posteriors[i]), args, target_model, verifier, data, device)
        certified_fragile_num = 0
        fargile_but_failed_num = 0
        pool = Pool(processes=5)
        nodes_fragileness_result = list(tqdm(
            pool.imap_unordered(
                partial(_verify_fragileness, args=args, model=target_model, verifier=verifier, data=data, device=device),
                zip(candidates, target_preds.tolist(), posteriors)
            ),
            total=len(candidates), desc=f'At trial {t}, certifing'
        ))
        pool.close()

        pert_results = []
        for res in nodes_fragileness_result:
            """ {
                'target_node': xx,
                'prediction': xx,
                'second_best_label: xx,
                'bundary_score': xx,
                'certified': {
                    'x': {
                        'target_label': x,
                        'perturbations': [(u1, v1), (u2, v2), ...]
                        'adj_diff.': [xx, xx, ...]
                        'fragile': True, 
                        'fragile_score': 0.1,
                        'single_predictions': [],
                        'union_predictions': []
                    }, ...
                }
            }
            """

            failed_count = 0
            for i in range(args.num_perts):
                if 'first_one_verified' in res['certified'][res['second_best_label']][i]:
                    if res['certified'][res['second_best_label']][i]['fragile']:
                        certified_fragile_num += 1
                    if res['certified'][res['second_best_label']][i]['fragile'] and not res['certified'][res['second_best_label']][i]['first_one_verified']:
                        # print('!!!!!!!!!!', res['target_node'], 'failed to verify', res['second_best_label'])
                        failed_count += 1 
                    # pert_results.append(res['certified'][res['second_best_label']][i]['first_one_verified']) 
                    # if res['certified'][res['second_best_label']][i]['fragile']:
                    #     certified_fragile_num += 1
            if failed_count > 0:
                print('Failed:', res['target_node'], 'failed to verify', res['second_best_label'], 'for', failed_count, 'times')
                print()
                fargile_but_failed_num += 1

            # if 'first_one_verified' in res['certified'][res['second_best_label']]:
            #     if not res['certified'][res['second_best_label']]['first_one_verified']:
            #         print('!!!!!!!!!!', res['target_node'], 'failed to verify', res['second_best_label'])

            #     pert_results.append(res['certified'][res['second_best_label']]['first_one_verified']) 
            #     if res['certified'][res['second_best_label']]['fragile']:
            #         certified_fragile_num += 1
                # if not res['certified'][res['second_best_label']]['first_one_verified']:
                #     print(res)
                #     print()
                #     exit(0)

            # if res['second_best_label'] in res['certified']:
            #     del res['certified'][res['second_best_label']]['adj']
            #     del res['certified'][res['second_best_label']]['adj_pert']
            result[t].append(res)

        # print('  ==> the number of certified fragile nodes:', certified_fragile_num)
        print('Trial', t)
        print('  ==> the number of certified fragile nodes:', certified_fragile_num)
        print('  ==> Among those nodes, the number of nodes that 1-pert failed:', fargile_but_failed_num)
        print()

    result_file = _result_filename(args, 'fragile')
    try:
        with open(result_file, 'w') as fp:
            json.dump(dict(result), fp, indent=4)
    except TypeError as err:
        print('result', result)
        raise err

    print('-' * 80)
    print('  ', 'Experiment results are saved to', result_file)
    print('-' * 80)

        # iter = tqdm(one_pert_fragile_nodes.items() if isinstance(one_pert_fragile_nodes, dict) else one_pert_fragile_nodes, desc='verify')
        # for item in iter:
        #     # if isinstance(item, tuple):
        #     #     v, fragile_classes = item
        #     #     fragile_class = fragile_classes[0]
        #     # else:
        #     #     v = item
        #     #     fragile_class = None

        #     v, label2perturbations = item
        #     clean_pred = target_model.predict(data, device, target_nodes=[v])
        #     print('Attacking node', v, ', prediction:', clean_pred[0])
        #     for target_label, perturbations in label2perturbations.items():
        #         perturbation2pred = {}
        #         verification_edges = []
        #         for e in random.sample(perturbations, 10) if len(perturbations) > 10 else perturbations:
        #             if isinstance(e, list) or isinstance(e, np.ndarray):
        #                 e = tuple(e)

        #             adv_data = copy.deepcopy(data)
        #             adv_data.add_edges(torch.tensor([[e[0], e[1]], [e[1], e[0]]]))

        #             adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
        #             adv.train(adv_data, device)

        #             adv_pred = adv.predict(adv_data, device, target_nodes=[v])
        #             perturbation2pred[e] = adv_pred[0]
        #             if adv_pred[0] == target_label:
        #                 verification_edges.append(e)
            
        #         # apply all the pontential perturbations at once
        #         adv_data = copy.deepcopy(data)
        #         adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
        #         adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
        #         adv.train(adv_data, device)

        #         adv_pred = adv.predict(adv_data, device, target_nodes=[v])
        #         print(f'  ==> fragile on label {target_label}, potential perturbations are {perturbations}, single pert predictions: {perturbation2pred}, union prediction: {adv_pred}')
        #         print()

            # for edge_sampler in ['nettack', 'ours', 'mibtack']:
            # for edge_sampler in ['nettack']:
            #     args.edge_sampler = edge_sampler
            #     perturbations = sample_edge_tokens(args, data, v, surrogate, clean_pred[0], data.y[v], target_label=fragile_class)
            #     print('perturbations', perturbations)

            #     if perturbations is None or len(perturbations) == 0:
            #         result['trial'].append(t)
            #         result['target'].append(v)
            #         result['label'].append(data.y[v])
            #         result['clean prediction'].append(clean_pred[0])
            #         result['target class'].append(fragile_class)
            #         result['method'].append(edge_sampler)
            #         result['perturbations'].append([])
            #         result['single adv predictions'].append([])
            #         result['adv prediction'].append(-1)
            #         result['sub adv prediction'].append(-2)
            #         result['fragileness'].append(0)
            #         result['consistency'].append(-1)
            #         result['incomplete'].append(-1)
            #         continue

                # consistency check
                # perturbation2pred = {}
                # verification_edges = []
                # for e in random.sample(perturbations, 10) if len(perturbations) > 10 else perturbations:
                #     adv_data = copy.deepcopy(data)
                #     adv_data.add_edges(torch.tensor([[e[0], e[1]], [e[1], e[0]]]))

                #     adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                #     adv.train(adv_data, device)

                #     adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                #     perturbation2pred[e] = adv_pred[0]
                #     if adv_pred[0] == fragile_class:
                #         verification_edges.append(e)
                
                # result['trial'].append(t)
                # result['target'].append(v)
                # result['label'].append(data.y[v].item())
                # result['clean prediction'].append(clean_pred[0])
                # result['target class'].append(fragile_class)
                # result['method'].append(edge_sampler)
                # result['perturbations'].append(perturbations)
                # result['single adv predictions'].append(list(perturbation2pred.values()))
                # result['fragileness'].append(1 if len(verification_edges) > 0 else 0)
                # result['consistency'].append(1 if np.sum(np.array(list(perturbation2pred.values())) != fragile_class) == 0 else 0)

                # verification
                # if len(verification_edges) > 1:
                #     adv_data = copy.deepcopy(data)
                #     edge_index_t = to_undirected(torch.tensor(verification_edges).t()) 
                #     adv_data.add_edges(edge_index_t)
                #     adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                #     adv.train(adv_data, device)
                #     adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                #     result['adv prediction'].append(adv_pred[0])

                #     if check_incompleteness(args, v, clean_pred[0], adv_pred[0], adv_data, verification_edges, device):
                #         # print('Yes, it is incompleteness!')
                #         result['sub adv prediction'].append(clean_pred[0])
                #         result['incomplete'].append(1)
                #     else:
                #         # print('No, not incompleteness!')
                #         result['sub adv prediction'].append(adv_pred[0])
                #         result['incomplete'].append(0)
                # else:
                #     result['adv prediction'].append(-1)
                #     result['sub adv prediction'].append(-2)
                #     result['incomplete'].append(-1)

                # if len(verification_edges) > 1:
                #     adv_data = copy.deepcopy(data)
                #     edge_index_t = to_undirected(torch.tensor(perturbations).t()) 
                #     adv_data.add_edges(edge_index_t)
                #     adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                #     adv.train(adv_data, device)
                #     adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                #     result['union adv prediction'].append(adv_pred[0])
                # else:
                #     result['union adv prediction'].append(-1)
    
    # df = pd.DataFrame(result)

    # for edge_sampler in ['nettack', 'ours', 'mibtack']:
    # for edge_sampler in ['nettack']:
    #     _df = df[df['method'] == edge_sampler]
    #     num_fraigle = 0
    #     num_inconsistent = 0
    #     for idx, row in _df.iterrows():
    #         # single_adv_predictions = literal_eval(row['single adv predictions'])
    #         single_adv_predictions = row['single adv predictions']
    #         clean_pred = row['clean prediction']
    #         target_class = row['target class']
    #         if (np.array(single_adv_predictions) != target_class).sum() > 0:
    #             num_inconsistent += 1
    #         for single_pred in single_adv_predictions:
    #             if single_pred != clean_pred:
    #                 num_fraigle += 1
    #                 break
    #     print(f'The certified fragile nodes are {num_fraigle} out of {len(_df)} nodes.')
    #     print(f'The inconsistent nodes are {num_inconsistent} out of {len(_df)} nodes.')

    #     args.edge_sampler = edge_sampler
    #     result_filename = _result_filename(args, 'fragile')
    #     _df.to_csv(os.path.join('result', result_filename))
    #     print('Verifing the fragility is Done, the result file is saved to', result_filename)


def _verify_1perturbation_fragile(data, v, prediction, perturbations, device):
    verification_edges = []
    verification_preds = []
    for e in perturbations:
        adv_data = copy.deepcopy(data)
        adv_data.add_edges(torch.tensor([[e[0],e[1]], [e[1],e[0]]]))

        adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
        adv.train(adv_data, device)

        adv_pred = adv.predict(adv_data, device, target_nodes=[v])
        if adv_pred[0] != prediction:
            verification_edges.append(e)
            verification_preds.append(adv_pred[0])

    # print('verification_edges', verification_edges)
    # print('verification_preds', verification_preds)
    return verification_edges, verification_preds

def _certify_fragile_mp(inputs, args, data, verifier, target_node, prediction, attack_label):
    idx, candidates = inputs
    # candidates = data.train_set.nodes[data.train_set.y == attack_label].tolist()
    # candidates = list(set(candidates) - set(data.adj_list[target_node]))
    # if len(candidates) > args.candidate_size:
    #     candidates = random.sample(candidates, args.candidate_size)
    t0 = time.time()
    res = verifier.certify(target_node, prediction, attack_label, candidates=candidates, solver=args.solver)
    if (time.time() - t0) > 100:
        print('  ==> certifing', target_node, f', done, in {(time.time() - t0):.2f}s')
        print('step:', res['step'])
        print('built_time:', res['buit_time'])
    if args.verbose:
        print('  ==> certifing', target_node, f', done, in {(time.time() - t0):.2f}s')
    if res['fragile']:
        p = tuple(res['perturbations'][0])
        return p
    else:
        return None

def certify_fragile_with_perturbations(inputs, args, verifier, data):
    target_node, prediction, attack_label = inputs
    # print(mp.current_process().name, 'certifing', target_node, ', prediction:', prediction, 'attack_label:', attack_label, '...')
    if args.candidate_method == 'no':
        candidates = None
    else:
        if args.candidate_method == 'label':
            # Method 1: random sample nodes based on their labels
            candidates = data.train_set.nodes[data.train_set.y == attack_label].tolist()
            candidates = list(set(candidates) - set(data.adj_list[target_node]))
            # print('the number of candidates:', len(candidates))
        elif args.candidate_method == 'random':
            candidates = random.sample(data.train_set.nodes.tolist(), args.candidate_size)
        else:
            raise NotImplementedError('Invalid candidate method:', args.candidate_method)
        # if args.candidate_size > 0 and len(candidates) > args.candidate_size:
        #     candidates = random.sample(candidates, args.candidate_size)
        #     print('candidates:', candidates)

    num_iter = 0
    ps = []
    while len(ps) < args.num_perts:
        if len(candidates) < args.candidate_size:
            break

        if candidates is not None and args.candidate_size > 0:
            _candidates = random.sample(candidates, args.candidate_size)
            # print('candidates:', len(_candidates))
        else:
            _candidates = None

        if args.verbose:
            print('  ==> certifing', target_node, '...')
        t0 = time.time()
        try:
            res = verifier.certify(target_node, prediction, attack_label, candidates=_candidates, solver=args.solver, mask=np.array(ps))
        except Exception as err:
            print('  ==> certifing', target_node, 'error:', err)
            raise err
            # continue
            # return target_node, None

        if (time.time() - t0) > 50:
            print('  ==> certifing', target_node, f', done, in {(time.time() - t0):.2f}s')
            # print('step:', res['step'])
            # print('fragile_score:', res['fragile_score'])
            # print('built_time:', res['buit_time'])
            if not res['fragile']:
                break
        # if args.verbose:
        #     print('  ==> certifing', target_node, f', done, in {(time.time() - t0):.2f}s')
        if res['fragile']:
            p = tuple(res['perturbations'][0])
            if candidates is not None:
                if p[0] == target_node:
                    if p[1] in candidates:
                        candidates.remove(p[1])
                else:
                    if p[0] in candidates:
                        candidates.remove(p[0])

            if p not in ps:
                ps.append(p)
                # print('  ==> certifing', target_node, 'found perturbations,', ps)
        if num_iter == args.T:
            break
        num_iter += 1
        # if num_iter % 5 == 0:
        #     print('  ==> certifing', target_node, 'iter:', num_iter, 'found perturbations,', ps, 'number:', len(ps))

    # print('target:', target_node, ': using ', num_iter, 'iterations to find', len(ps), 'ps')
    if len(ps) != args.num_perts:
        return target_node, None, None
    else:
        return target_node, ps, attack_label

def verify_unlearning_backdoor(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)

        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = target_train_preds
        surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False)
        surrogate.train(surrogate_data, device)

        if args.node_sampler == 'boundary':
            candidates = sample_node_tokens(args, data, data.test_set.nodes.tolist(), target_model, amplify=1)
        elif args.node_sampler == 'random':
            candidates = random.sample(data.test_set.nodes.tolist(), args.num_target_nodes)
        target_preds, posteriors = target_model.predict(data, device, target_nodes=candidates, return_posterior=True)
        # attack_labels = _second_best_labels(posteriors)

        """ Add hyper-parameters of GTA, details can be found in gta.py
        """
        _args = copy.deepcopy(args)
        _args.trigger_size = 3
        _args.num_triggers = 10
        _args.bilevel_steps = 4
        _args.gtn_lr = 0.01
        _args.topo_thrd = 0.5
        _args.gtn_epochs = 10
        _args.topo_activation = 'sigmoid'
        _args.gta_batch_size = 16
        _args.lr_decay_steps = [25, 35]
        _args.train_epochs = 40
        _args.lambd = 1
        _args.gtn_input_type = '2hop'
        _args.feat_perb = False

        # Call GTA and get backdoored model, topo generator, and backdoored edges
        bkd_model, topo_net, bkd_edges, bkd_label = backdoor_attack(_args, surrogate, data)
        bkd_data = copy.deepcopy(data)
        bkd_data.add_edges(to_undirected(torch.tensor(bkd_edges).t()))
        bkd_adj = bkd_data.adjacency_matrix().to_dense().to(device)

        subset_retrain_mdoel = {}
        for v, pred in tqdm(zip(candidates, target_preds), total=len(candidates), desc='verify'):
            result['trial'].append(t)
            result['target node'].append(v)
            result['ground truth'].append(data.y[v].item())
            result['prediction'].append(pred)
            result['attack_label'].append(bkd_label)

            subset, edge_index, _, _ = k_hop_subgraph(v, 2, bkd_data.edge_index)
            # print('subset:', subset)
            subgraph = random.sample(subset.tolist(), min(len(subset), _args.trigger_size))

            # obtain trigger of the target node
            topo_input, feat_input = generate_topo_input(_args, bkd_data, device)
            topo_mask, _ = generate_masks(bkd_data, [(subgraph, None)], device)
            rst_bkd_adj = topo_net(topo_input, topo_mask, _args.topo_thrd, device, _args.topo_activation, 'topo')
            trigger_edges = torch.nonzero(rst_bkd_adj * (1 - bkd_adj)).tolist()
            if len(trigger_edges) == 0:
                result['incomplete prediction'].append(-1)
                result['incomplete'].append(0)
                result['failed perturbation'].append([])
                result['bkd prediction'].append(-1)
                continue

            _trigger_data = copy.deepcopy(bkd_data)
            _trigger_data.add_edges(to_undirected(torch.tensor(trigger_edges).t()))

            bkd_pred = bkd_model.predict(_trigger_data, device, target_nodes=[v])
            result['bkd prediction'].append(bkd_pred[0])

            equal_to_bkd_label = True
            for length in range(len(bkd_edges) - 1, 0, -1):
                for _edges in combinations(bkd_edges, length):
                    sub_bkd_data = copy.deepcopy(bkd_data)
                    sub_bkd_data.remove_edges(_edges)

                    # print('_edges:', _edges)
                    _edges_key = tuple(map(tuple, _edges))
                    if _edges_key in subset_retrain_mdoel:
                        sub_bkd_model = subset_retrain_mdoel[_edges_key]
                    else:
                        sub_bkd_model = GNN(args, sub_bkd_data.num_features, sub_bkd_data.num_classes, surrogate=False)
                        sub_bkd_model.train(sub_bkd_data, device)
                        subset_retrain_mdoel[_edges_key] = sub_bkd_model
                    
                    sub_bkd_pred = sub_bkd_model.predict(sub_bkd_data, device, target_nodes=[v])
                    if sub_bkd_pred[0] != bkd_label:
                        equal_to_bkd_label = False
                        break
                if not equal_to_bkd_label:
                    break
            if not equal_to_bkd_label:
                result['incomplete prediction'].append(sub_bkd_pred[0].item())
                result['incomplete'].append(1)
                result['failed perturbation'].append(_edges)
            else:
                result['incomplete prediction'].append(-1)
                result['incomplete'].append(0)
                result['failed perturbation'].append([])

        _df = pd.DataFrame(result)
        trial_df = _df[_df['trial'] == t]
        fpr = utils.calc_fpr(trial_df, len(trial_df))
        fnr = utils.calc_fnr(trial_df, len(trial_df))
        print(f' At trial {t}, the result of {args.edge_sampler}', '-' * 80)
        print('  => FPR:', fpr)
        print('  => FNR:', fnr)
        print('=' * 100)

    try:    
        df = pd.DataFrame(result)
    except ValueError as err:
        print('result', result)
        raise err

    for t in range(args.num_trials):
        _df = df[df['trial'] == t]
        print(f'Trial {t}, the number of incompleteness:', _df['incomplete'].values.sum())
        # print(f'Trial {t}, the number of fragile:', _df['fragileness'].values.sum())
    # incompleteness = df['incomplete'].values.sum()
    # print('  ==> The incompleteness:', incompleteness)

    result_filename = _baseline_result_filename(args, 'verify')
    df.to_csv(os.path.join('result', result_filename))
    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print('-' * 80)
    

def verify_unlearning_baselines(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)

        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        # target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
        
        # surrogate_data = copy.deepcopy(data)
        # surrogate_data.train_set.y = target_train_preds
        # if args.edge_sampler == 'nettack':
        #     surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False)
        #     surrogate.train(surrogate_data, device)
        # else:
        #     # surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True)
        #     surrogate = GCN(nfeat=data.num_features, nclass=data.num_classes, nhid=16, with_relu=True, with_bias=False, device=device).to(device)
        #     # contruct adjacency matrix
        #     row = data.edge_index.numpy()[0]
        #     col = data.edge_index.numpy()[1]
        #     value = np.ones((len(row)))
        #     adj = sp.csr_matrix((value, (row, col)), shape=(data.num_nodes, data.num_nodes))
        #     surrogate.fit(data.x, adj, data.y, data.train_set.nodes.tolist(), data.valid_set.nodes.tolist())
        # surr_test_preds = surrogate.predict(surrogate_data, device, target_nodes=data.test_set.nodes.tolist())

        # if args.node_sampler == 'boundary':
        #     candidates = sample_node_tokens(args, data, data.test_set.nodes.tolist(), target_model, amplify=1)
        # elif args.node_sampler == 'random':
        #     candidates = random.sample(data.test_set.nodes.tolist(), args.num_target_nodes)
        # target_preds, posteriors = target_model.predict(data, device, target_nodes=candidates, return_posterior=True)
        # attack_labels = _second_best_labels(posteriors)
        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)

        for method in ['sga', 'fga', 'rnd', 'ig', 'nettack']:
        # for method in ['nettack']:
            m = max(math.log(1 - _alpha, 1 - _q[args.dataset][method]), math.log(1 - _beta, 1 - _p[args.dataset][method]))
            args.num_target_nodes = m
            num_completeness = 0
            num_correctness = 0
            if method == 'nettack':
                surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False)
                surrogate.train(surrogate_data, device)
                # surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pt')
                # surrogate.save_model(surrogate_filename)

                v_star, e_star, c_star = [], [], []
                pbar = tqdm(total=args.num_target_nodes, desc='attacking')
                while len(v_star) < args.num_target_nodes:
                    v = random.choice(data.test_set.nodes.tolist())
                    if v in v_star:
                        continue
                    pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                    nettack = ntk(surrogate, data, v, pred)
                    nettack.reset()
                    nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                    E_t = nettack.structure_perturbations
                    v_star.append(v)
                    e_star.append(E_t)
                    c_star.append(_second_best_labels(post)[0])
                    pbar.update(1)
                pbar.close()
                p_star = target_model.predict(data, device, target_nodes=v_star)
            else:
                v_star, e_star, c_star = targeted_attack(surrogate_data, method, args.num_perts, t, ts, device)
                p_star = target_model.predict(data, device, target_nodes=v_star)

            for v, pred, perturbations, attack_label in tqdm(zip(v_star, p_star, e_star, c_star), total=len(v_star), desc=f'verify {method}'):
                # result['trial'].append(t)
                # result['target node'].append(v)
                # result['ground truth'].append(data.y[v].item())
                # result['prediction'].append(pred)
                # result['attack_label'].append(attack_label)

                # verification
                # if perturbations is None or len(perturbations) == 0:
                #     result['perturbations'].append([])
                #     result['adv prediction'].append(-1)
                #     result['incomplete prediction'].append(-1)
                #     result['incomplete'].append(0)
                #     result['failed perturbation'].append([])
                #     # result['single adv predictions'].append([])
                #     continue
                # result['perturbations'].append(perturbations)

                adv_data = copy.deepcopy(data)
                edge_index_t = to_undirected(torch.tensor(perturbations).t()) 
                adv_data.add_edges(edge_index_t)
                adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=False)
                adv.train(adv_data, device)
                adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                if adv_pred != pred:
                    num_correctness += 1
                if not check_incompleteness(args, v, pred, adv_pred[0], adv_data, perturbations, device):
                    num_completeness += 1
                # num_incompleteness += check_incompleteness(args, v, pred, adv_pred[0], adv_data, perturbations, device)

                # if pred == adv_pred[0]:
                #     print('Attack failed:', v, 'prediction:', pred, 'adv prediction:', adv_pred[0])
                # result['adv prediction'].append(adv_pred[0])

                # if len(perturbations)  == 1:
                #     result['incomplete prediction'].append(-1)
                #     result['incomplete'].append(0)
                #     result['failed perturbation'].append([])
                #     # result['single adv predictions'].append([])
                #     continue
                
                # is_incomplete, _failed_pert = check_incompleteness(args, v, pred, adv_pred[0], adv_data, perturbations, device)
                # if is_incomplete:
                #     result['incomplete prediction'].append(pred)
                #     result['incomplete'].append(1)
                #     result['failed perturbation'].append(_failed_pert)
                #     print('Yes, it is incompleteness!')
                # else:
                #     # print('No, not incompleteness!')
                #     result['incomplete prediction'].append(-1)
                #     result['incomplete'].append(0)
                #     result['failed perturbation'].append([])
                #     # result['single adv predictions'].append([])
            # _df = pd.DataFrame(result)
            # trial_df = _df[_df['trial'] == t]
            # fpr = utils.calc_fpr(trial_df, len(trial_df))
            # fnr = utils.calc_fnr(trial_df, len(trial_df))
            # print(f' At trial {t}, the result of {method}', '-' * 80)
            # print('  => FPR:', fpr)
            # print('  => FNR:', fnr)
            # print('=' * 100)
            # _df.to_csv(os.path.join('result', f'baseline{t}_{ts}.csv'))
            print(' Method:', method)
            print('m', m)
            print(' Trial', t, 'the number of completeness:', num_completeness)
            print(' Trial', t, 'the number of correctness:', num_correctness)
            print()
            result['trial'].append(t)
            result['completeness'].append(num_completeness)
            result['correctness'].append(num_correctness)
            result['p'].append(num_correctness / len(v_star))
            result['q'].append(num_completeness / len(v_star))
            # result['q'].append(num_completeness / (len(v_star) * (2 ** args.num_perts - 2)))

        # try:    
        #     df = pd.DataFrame(result)
        # except ValueError as err:
        #     print('result', result)
        #     raise err

        # for t in range(args.num_trials):
        #     _df = df[df['trial'] == t]
        #     print(f'Trial {t}, the number of incompleteness:', _df['incomplete'].values.sum())
        #     # print(f'Trial {t}, the number of fragile:', _df['fragileness'].values.sum())
        # # incompleteness = df['incomplete'].values.sum()
        # # print('  ==> The incompleteness:', incompleteness)

        # result_filename = f'baseline_{ts}.csv'
        # df.to_csv(os.path.join('result', result_filename))
        # fpr = utils.calc_fpr(df, 100)
        # fnr = utils.calc_fnr(df, 100)
        # print('-' * 80)
        # print('Verifing unlearning is done, the result file is saved to', result_filename)
        # print('-' * 80)
    try:
        df = pd.DataFrame(result)
    except ValueError as err:
        print('result', result)
        raise err

    result_filename = f'baselines_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print(df.mean())
    print('-' * 80)



def find_1pf(args, target, surrogate, data, device, num_layer=2, verbose=False, surrogate_data=None, used_token_nodes=None):
    weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
    if surrogate_data is not None:
        verifier = CertifiedFragilenessLazy(args, weights, surrogate_data, num_layer=num_layer, verbose=False)
    else:
        verifier = CertifiedFragilenessLazy(args, weights, data, num_layer=num_layer, verbose=False)
    v_star, e_star, c_star = [], [], []
    if verbose:
        pbar = tqdm(total=args.num_target_nodes, desc=f'certifing')
    iter_count = 0
    running_times = []

    candidate_pool = data.test_set.nodes.tolist() if surrogate_data is None else surrogate_data.test_set.nodes.tolist()
    if used_token_nodes is not None:
        candidate_pool = list(set(candidate_pool) - set(used_token_nodes))
    while len(v_star) < args.num_target_nodes:
        # sample a node
        v = random.choice(candidate_pool)
        if v in v_star:
            continue
        if surrogate_data is not None:
            if isinstance(target, unlearn.Unlearn):
                pred, post = target.predict(target_nodes=[surrogate_data.partial_to_original[v]], return_posterior=True)
            else:
                pred, post = target.predict(data, device, target_nodes=[surrogate_data.partial_to_original[v]], return_posterior=True)
        else:
            if isinstance(target, unlearn.Unlearn):
                pred, post = target.predict(target_nodes=[v], return_posterior=True)
            else:
                pred, post = target.predict(data, device, target_nodes=[v], return_posterior=True)
        c = _second_best_labels(post)[0]

        # sample a perturbation
        # perturbation = sample_edge_tokens(args, data, v, surrogate, predictions[v], target_label=c_star[v])
        t0 = time.time()
        if surrogate_data is not None:
            v, perturbation, c = certify_fragile_with_perturbations((v, pred, c), args, verifier, surrogate_data)
        else:
            v, perturbation, c = certify_fragile_with_perturbations((v, pred, c), args, verifier, data)
        running_times.append(time.time() - t0)
        if perturbation is not None:
            if surrogate_data is not None:
                v_star.append(surrogate_data.partial_to_original[v])
                e_star.append([(surrogate_data.partial_to_original[e[0]], surrogate_data.partial_to_original[e[1]]) for e in perturbation])
            else:
                v_star.append(v)
                e_star.append(perturbation)
            c_star.append(c)
            if verbose:
                pbar.update(1)
        iter_count += 1
        if verbose:
            pbar.set_description(f'after certifying {iter_count} nodes')
    if verbose:
        pbar.close()

    # print('-' * 20, 'efficiency performance', '-' * 20)
    # print('  => The average running time:', np.mean(running_times), f', for {len(running_times)} times')
    # print('  => The number of iterations:', iter_count)
    # print('  => The number of token nodes:', args.num_target_nodes)
    # print('  =>', running_times)
    # print('-' * 60)
    return v_star, e_star, c_star
    
def _verification_prob_guarantee(N, m, p):
    return N * (1 - math.pow(1-p, 1/m))


# def verify_mix_unlearning(args):
#     device = utils.get_device(args)
#     N = 100
#     p = 0.95

#     result = defaultdict(list)
#     for t in range(args.num_trials):
#         args.seed = random.randint(0, 1e+5)
#         torch.manual_seed(args.seed)
#         torch.cuda.manual_seed_all(args.seed)
#         np.random.seed(args.seed)
#         random.seed(args.seed)

#         data = data_loader.load(args)

#         target = _get_target_model(args, data, device)

#         surroget = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
#         surroget.train(data, device)

#         for m in range(10, 60, 10):
#             k = math.ceil(_verification_prob_guarantee(N, m, p))
#             tp = 0
#             args.num_target_nodes = 1
#             args.num_perts = k 
#             num_challenges = []
#             for _ in tqdm(range(500), desc=f'Verifying m={m}, k={k}'):
#                 v_star, e_star, c_star = find_1pf(args, target, surroget, data, device)
#                 v, e = v_star[0], e_star[0]
#                 benign_edges = random.sample(data.edges.tolist(), N - k)
#                 edges_to_remove = list(map(tuple, benign_edges)) + e

#                 adv_data = copy.deepcopy(data)
#                 adv_data.add_edges(to_undirected(torch.tensor(edges_to_remove).t()))
#                 adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
#                 adv.train(adv_data, device)
#                 adv_pred = adv.predict(adv_data, device, target_nodes=v_star)[0]

#                 sub_perts = random.sample(edges_to_remove, N - m)

#                 cheat_edges = set(edges_to_remove) - set(sub_perts)
#                 count = 0
#                 for _e in cheat_edges:
#                     if _e in e:
#                         count += 1
#                 num_challenges.append(count)
#                 pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, sub_perts, v_star, device)
#                 if pos_pred[0] == adv_pred:
#                     tp += 1
 
#             result['trial'].append(t)
#             result['m'].append(m)
#             result['k'].append(k)
#             result['tpr'].append(tp / 100)
#             result['num_challenges'].append(num_challenges)
    
#     df = pd.DataFrame(result)
#     df.to_csv(os.path.join('result', f'mix_unlearning_{args.dataset}.csv'))
#     _df = df[['m', 'k', 'tpr']]
#     print('reuslt', _df.groupby(['m', 'k']).mean())


def verify(args):
    device = utils.get_device(args)
    
    ts = int(time.time())
    result = defaultdict(list)
    # for t in range(args.num_trials):
    # t = args.trial
    for t in range(args.num_trials):
        # for method in ['ours']:
        if os.path.exists(os.path.join('archive', str(t), args.dataset, f'seed_{args.method}.pkl')):
            with open(os.path.join('archive', str(t), args.dataset, f'seed_{args.method}.pkl'), 'rb') as f:
                args.seed = pickle.load(f)
        else:
            args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data_file = os.path.join('archive', str(t), args.dataset, f'data_{args.method}.pkl')
        print('data_file', data_file)
        with open(data_file, 'rb') as f:
            data = pickle.load(f)
        target_model_file = os.path.join('archive', str(t), args.dataset, f'target_{args.method}.pt')
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        target_model.load_model(target_model_file)

        # surrogate_model_file = os.path.join('archive1', str(t), args.dataset, f'surrogate_{method}.pt')
        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=method=='nettack', fix_weight=False)
        # surrogate.load_model(surrogate_model_file)
        v_star_file = os.path.join('archive', str(t), args.dataset, f'v_star_{args.method}.pkl')
        with open(v_star_file, 'rb') as f:
            v_star = pickle.load(f)
        e_star_file = os.path.join('archive', str(t), args.dataset, f'e_star_{args.method}.pkl')
        with open(e_star_file, 'rb') as f:
            e_star = pickle.load(f)
        p_star = target_model.predict(data, device, target_nodes=v_star)
        v_star = v_star[:args.num_target_nodes]
        e_star = e_star[:args.num_target_nodes]
        p_star = p_star[:args.num_target_nodes]

        target_res = target_model.evaluate(data, device)
        tn, fp = 0, 0
        tp, fn = defaultdict(int), defaultdict(int)
        acc_losses = []
        t0 = time.time()
        for v, e, pred in tqdm(zip(v_star, e_star, p_star), total=len(v_star), desc=f'Trial {t}, method {args.method}, evaluating'):
            if e is None or len(e) == 0:
                continue
            adv_data = copy.deepcopy(data)
            adv_data.add_edges(to_undirected(torch.tensor(e).t()))
            adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
            adv_filename = os.path.join('archive', str(t), args.dataset, f'adv_{args.method}_{v}.pt')
            if os.path.exists(adv_filename):
                adv.load_model(adv_filename)
            else:
                adv.train(adv_data, device)
                adv.save_model(adv_filename)
            adv_pred = adv.predict(adv_data, device, target_nodes=[v])

            adv_res = adv.evaluate(adv_data, device) 
            acc_loss = np.abs(target_res['accuracy'] - adv_res['accuracy']) / target_res['accuracy']
            acc_losses.append(acc_loss)

            neg_pred, verify_time1 = _unlearn_train_predict(args, adv_data, e, [v], device)
            if neg_pred[0] != adv_pred:
                tn += 1
            else:
                fp += 1

            ''' Enumerate all the p percent of edges to verify'''
            # false_neg = False
            # for _edges in combinations(e, math.ceil(len(e) * p)):
            #     print('  ==> verifying', _edges)
            #     pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, _edges, [v], device)
            #     if pos_pred[0] != adv_pred:
            #         false_neg = True
            #         print('label changed! when edge:', _edges)
            #         break
            # if false_neg:
            #     fn += 1
            # else:
            #     tp += 1

            ''' Randomly pick one p percent of edges to verify'''
            for p in args.percentages:
                sub_perts = random.sample(e, min(int(len(e) * (1 - p)), len(e) - 1))
                pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)
                if pos_pred[0] == adv_pred:
                    tp[p] += 1
                else:
                    fn[p] += 1                

        for p in args.percentages:
            result['trial'].append(t)
            result['method'].append(args.method)
            result['num node tokens'].append(args.num_target_nodes)
            result['p'].append(p)
            result['tp'].append(tp[p])
            result['tn'].append(tn)
            result['fp'].append(fp)
            result['fn'].append(fn[p])
            result['accuracy loss'].append(np.mean(acc_losses))
            result['verify time'].append((verify_time1 + verify_time2) / 2)
            result['total time'].append(time.time() - t0)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('-' * 80)
        print('Trial', t)
        print(trial_df.groupby(['method', 'p']).mean()[['tp', 'tn', 'fp', 'fn', 'accuracy loss']])
        print('-' * 80)
        
    df = pd.DataFrame(result)
    print(df.groupby(['method', 'p']).mean()[['tp', 'tn', 'fp', 'fn', 'accuracy loss']])
    result_filename = f'verify_{ts}_{args.dataset}.csv'
    df.to_csv(os.path.join('result', result_filename)) 
    print('Verifing is done, the result file is saved to', result_filename)


def accuracy_loss(args):
    device = utils.get_device(args)

    result = defaultdict(list)
    for t in range(args.num_trials):
        seed_filename = os.path.join('archive', str(t), args.dataset, f'seed_{args.method}.pkl')
        if os.path.exists(seed_filename):
            with open(seed_filename, 'rb') as f:
                args.seed = pickle.load(f)
        else:
            args.seed = random.randint(0, 1e+5) 
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data_filename = os.path.join('archive', str(t), args.dataset, f'data_{args.method}.pkl')
        with open(data_filename, 'rb') as f:
            data = pickle.load(f)

        target_filename = os.path.join('archive', str(t), args.dataset, f'target_{args.method}.pt')
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        target_model.load_model(target_filename)

        v_star_filename = os.path.join('archive', str(t), args.dataset, f'v_star_{args.method}.pkl')
        with open(v_star_filename, 'rb') as f:
            v_star = pickle.load(f)
        
        e_star_file = os.path.join('archive', str(t), args.dataset, f'e_star_{args.method}.pkl')
        with open(e_star_file, 'rb') as f:
            e_star = pickle.load(f)

        p_star = target_model.predict(data, device, target_nodes=v_star)
        target_res = target_model.evaluate(data, device)
        for v, e, p in tqdm(zip(v_star, e_star, p_star), total=len(v_star), desc='evaluating'):
            if e is None or len(e) == 0:
                continue
            adv_data = copy.deepcopy(data)
            adv_data.add_edges(to_undirected(torch.tensor(e).t()))
            adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
            adv_model_filename = os.path.join('archive', str(t), args.dataset, f'adv_{args.method}_{v}.pt')
            if os.path.exists(adv_model_filename):
                adv.load_model(adv_model_filename)
            else:
                adv.train(adv_data, device)
                adv.save_model(adv_model_filename)

            adv_res = adv.evaluate(adv_data, device) 
            acc_loss = np.abs(target_res['accuracy'] - adv_res['accuracy']) / target_res['accuracy']

            result['trial'].append(t)
            result['method'].append(args.method)
            result['v'].append(v)
            result['target accuracy'].append(target_res['accuracy'])
            result['adv accuracy'].append(adv_res['accuracy'])
            result['acc loss'].append(acc_loss)

        df = pd.DataFrame(result)
        _df = df[df['trial'] == t]
        print('At trial', t, 'method:', args.method, 'acc loss:', _df['acc loss'].values.mean())

    ts = int(time.time())
    df = pd.DataFrame(result)
    result_filename = f'accloss_{ts}_{args.dataset}_{args.method}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print('The result file is saved to', result_filename)


def check_1pf_success_rate(args):
    device = utils.get_device(args)

    result = defaultdict(list)

    ts = int(time.time())
    for t in range(args.num_trials):
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        seed_filename = os.path.join('intermediate', f'1pf_seed{t}_{ts}.pkl')
        with open(seed_filename, 'wb') as f:
            pickle.dump(args.seed, f)

        data = data_loader.load(args)
        data_filename = os.path.join('intermediate', f'1pf_data{t}_{ts}.pkl')
        with open(data_filename, 'wb') as f:
            pickle.dump(data, f)

        # target_model = _get_target_model(args, data, device)
        if args.gcn_type == '1-layer':
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True, layer1=True)
        elif args.gcn_type == 'standard':
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        target_filename = os.path.join('intermediate', f'1pf_target{t}_{ts}.pt')
        target_model.save_model(target_filename)

        for method in ['ours']:
            if method == 'ours':
                surrogate = copy.deepcopy(target_model)
                weights = [p.detach().cpu().numpy() for p in target_model.model.parameters()]
                verifier = CertifiedFragilenessLazy(args, weights, data, max_iter=50, num_layer=1 if args.gcn_type == '1-layer' else 2)
                
                v_star, e_star, c_star = [], [], []
                pbar = tqdm(total=args.num_target_nodes, desc='certifying')
                num_iter = 0
                while len(v_star) < args.num_target_nodes:
                    v = random.choice(data.test_set.nodes.tolist())
                    if v in v_star:
                        continue
                    pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                    c = _second_best_labels(post)[0]
                    v, p, c = certify_fragile_with_perturbations((v, pred[0], c), args, verifier, data)
                    if p is not None:
                        v_star.append(v)
                        e_star.append(p)
                        c_star.append(c)
                        pbar.update(1)
                    num_iter += 1
                    pbar.set_description(f'after certifying {num_iter} nodes')
                pbar.close()
            else:
                args.edge_sampler = method
                v_star = random.sample(data.test_set.nodes.tolist(), args.num_target_nodes)
                preds = target_model.predict(data, device, target_nodes=v_star)

                surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False, fix_weight=True)
                surrogate_data = copy.deepcopy(data)
                surrogate_data.train_set.y = target_train_preds
                surrogate.train(surrogate_data, device)

                e_star, c_star = [], []
                for v, pred in zip(v_star, preds):
                    perturbations = sample_edge_tokens(args, data, v, surrogate_model=surrogate, prediction=pred)
                    e_star.append(perturbations)
                    c_star.append(data.y[v].item())

            p_star = target_model.predict(data, device, target_nodes=v_star)
            v_star_filename = os.path.join('intermediate', f'1pf{t}_v_star_{method}_{ts}.pkl')
            with open(v_star_filename, 'wb') as f:
                pickle.dump(v_star, f)
            e_star_filename = os.path.join('intermediate', f'1pf{t}_e_star_{method}_{ts}.pkl')
            with open(e_star_filename, 'wb') as f:
                pickle.dump(e_star, f)
            c_star_filename = os.path.join('intermediate', f'1pf{t}_c_star_{method}_{ts}.pkl')
            with open(c_star_filename, 'wb') as f:
                pickle.dump(c_star, f)

            # for v, e, pred, c in tqdm(zip(v_star, e_star, p_star, c_star), total=len(v_star), desc='checking 1PF'):
            #     tn, fp, fn, tp = 0, 0, 0, 0
            #     one_pf = False
            #     one_p = 0
            #     # one_pf_no_retrain = False
            #     # one_p_no_retrain = 0
            #     history, history2 = [], []
            #     for one_pert in e:
            #         adv_pred = _adv_train_predict(args, data, [one_pert], [v], device, type=args.gcn_type)[0]
            #         # adv_pred_no_retrain = _adv_predict_without_retrain(args, target_model, data, [one_pert], [v], device)[0]
            #         if adv_pred != pred:
            #             one_pf = True
            #             one_p += 1
            #         history.append(adv_pred)
            #         # history2.append(adv_pred_no_retrain)
            #         # if adv_pred_no_retrain != pred:
            #         #     one_pf_no_retrain = True
            #         #     one_p_no_retrain += 1

            #     result['trial'].append(t)
            #     result['method'].append(method)
            #     # result['target nodes'].append(v_star)
            #     result['1pf'].append(one_pf)
            #     result['1p'].append(one_p)
            #     # result['1pf_no_retrain'].append(one_pf_no_retrain)
            #     # result['1p_no_retrain'].append(one_p_no_retrain)

            #     adv = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            #     adv_data = copy.deepcopy(data)
            #     adv_data.add_edges(to_undirected(torch.tensor(e).t()))
            #     adv.train(adv_data, device)
            #     adv_pred = adv.predict(adv_data, device, target_nodes=[v])[0]
                
            #     print('original prediction:', pred, ', attack label:', c)
            #     print('history', history, ', + adv prediction:', adv_pred)
            #     # print('history2', history2)

            #     neg_pred, verify_time1 = _unlearn_train_predict(args, adv_data, e, [v], device)
            #     if neg_pred[0] != adv_pred:
            #         tn += 1
            #     else:
            #         fp += 1

            #     ''' Enumerate all the p percent of edges to verify'''
            #     # false_neg = False
            #     # for _edges in combinations(e, math.ceil(len(e) * p)):
            #     #     print('  ==> verifying', _edges)
            #     #     pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, _edges, [v], device)
            #     #     if pos_pred[0] != adv_pred:
            #     #         false_neg = True
            #     #         print('label changed! when edge:', _edges)
            #     #         break
            #     # if false_neg:
            #     #     fn += 1
            #     # else:
            #     #     tp += 1

            #     ''' Randomly pick one p percent of edges to verify'''
            #     sub_perts = random.sample(e, min(int(len(e) * (1 - 0.1)), len(e) - 1))
            #     pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)
            #     if pos_pred[0] == adv_pred:
            #         tp += 1
            #     else:
            #         fn += 1
                
            #     result['p'].append(0.1)
            #     result['clean prediction'].append(pred)
            #     result['adv prediction'].append(adv_pred)
            #     result['pos prediction'].append(pos_pred[0])
            #     result['neg prediction'].append(neg_pred[0])
            #     result['tp'].append(tp)
            #     result['tn'].append(tn)
            #     result['fp'].append(fp)
            #     result['fn'].append(fn)
            #     # result['verify time'].append((verify_time1 + verify_time2) / 2)

            # _df = pd.DataFrame(result)
            # _df = _df[(_df['trial'] == t) & (_df['method'] == method)]
            # one_pf_success_rate = _df['1pf'].values.sum() / len(_df)
            # one_p_success_rate = _df['1p'].values.sum() / (len(_df) * args.num_perts)
            # print('At trial', t, ', Method:', method, '-' * 80)
            # print('  ==> 1PF success rate:', one_pf_success_rate)
            # print('  ==> 1P success rate:', one_p_success_rate)
            # print('  ==> TPR', _df['tp'].values.sum() / (_df['tp'].values.sum() + _df['fn'].values.sum()))
            # print('  ==> TNR', _df['tn'].values.sum() / (_df['tn'].values.sum() + _df['fp'].values.sum()))
    print('result', result)
    print('       ==> the data model is saved to ', data_filename)
    print('     ==> the target model is saved to ', target_filename)
    print('           ==> the v_star is saved to ', v_star_filename)
    print('           ==> the e_star is saved to ', e_star_filename)
    print('           ==> the c_star is saved to ', c_star_filename)
    print('             ==> the seed is saved to ', seed_filename)
    


def check_num_trials_and_success_rate(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)

        if args.gcn_type == '1-layer':
            args.condidate_size = 1
            args.candidate_hop = 1
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True, layer1=True)
        elif args.gcn_type == 'standard':
            args.candidate_hop = 2
            args.condidate_size = 1
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        # target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        # target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)

        weights = [p.detach().cpu().numpy() for p in target_model.model.parameters()]
        verifier = CertifiedFragilenessLazy(args, weights, data, max_iter=50, num_layer=1 if args.gcn_type == '1-layer' else 2)

        v_star, e_star, c_star = [], [], []
        pbar = tqdm(total=args.num_target_nodes, desc='certifying')
        num_iter = 0
        while len(v_star) < args.num_target_nodes:
            v = random.choice(data.test_set.nodes.tolist())
            if v in v_star:
                continue
            pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
            c = _second_best_labels(post)[0]

            v, p, c = certify_fragile_with_perturbations((v, pred[0], c), args, verifier, data)
            if p is not None:
                v_star.append(v)
                e_star.append(p)
                c_star.append(c)
                pbar.update(1)
            num_iter += 1
            pbar.set_description(f'after certifying {num_iter} nodes')
        pbar.close()
        p_star = target_model.predict(data, device, target_nodes=v_star)

        for v, e, p, c in tqdm(zip(v_star, e_star, p_star, c_star), total=len(v_star), desc='At {t}, evaluating'):
            success_count = 0
            for _e in e:
                adv_pred = _adv_train_predict(args, data, [_e], [v], device, type=args.gcn_type)[0]
                if adv_pred != p:
                    success_count += 1
                    break
            
        result['trial'].append(t)
        result['target nodes'].append(v_star)
        result['attack label'].append(c_star)
        result['perturbations'].append(e_star)
        result['target prediction'].append(p_star)
        result['success count'].append(success_count)
        result['num_iter'].append(num_iter)
    
    df = pd.DataFrame(result)
    avg_iter_per_1pf = np.mean(df['num_iter'].values / args.num_target_nodes)
    avg_success_rate = df['success count'].values.sum() / (args.num_perts * args.num_target_nodes)

    print('avg_iter_per_1pf:', avg_iter_per_1pf)
    print('avg_success_rate:', avg_success_rate)


def new_verify_unlearning(args):
    # args.num_target_nodes = math.ceil(_calc_m(_alpha, _q[args.dataset]))
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False
    result = defaultdict(list)
    ts = int(time.time())

    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        surrogate.train(surrogate_data, device)

        _num_behaviors = 50
        # for beta in [0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:
        for beta in [0.7, 0.8, 0.9, 0.95]:
            # q = 0.46
            m = _calc_m(_alpha, beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
            args.num_target_nodes = math.ceil(m)
            tp, tn = 0, 0
            for _ in tqdm(range(_num_behaviors), desc=f'Verifying beta={beta}, m={math.ceil(m)}'):
                # t0 = time.time()
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device)
                p_star = target_model.predict(data, device, target_nodes=v_star)
                # print('duration for 1PF:', int(time.time() - t0))

                # print(f'number of token nodes:', len(v_star))

                _tp_count, tn_count = 0, 0
                # t0 = time.time()
                for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))
                    
                    adv_pred = _adv_train_predict(args, adv_data, e, [v], device)[0]
                    if adv_pred != p:
                        tn_count += 1

                    # for p in [0.2]:
                    p = 0.2
                    sub_perts = random.sample(e, min(int(len(e) * (1 - p)), len(e) - 1))
                    pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                    if pos_pred == adv_pred:
                        # tp += 1
                        _tp_count += 1
                    

                    # result['trial'].append(t)
                    # result['target nodes'].append(v)
                    # result['attack label'].append(c)
                    # result['perturbations'].append(e)
                    # result['target prediction'].append(p)
                    # result['success count'].append(success_count)
                # print('duration for verification:', int(time.time() - t0))
                if _tp_count != 0:
                    tp += 1
                if tn_count == args.num_target_nodes:
                    tn += 1
            # print(f'At trial {t}, TPR: {tp / 50}, TNR: {tn / 50}')
            result['trial'].append(t)
            result['beta'].append(beta)
            result['m'].append(m)
            result['TPR'].append(tp / _num_behaviors)
            result['TNR'].append(tn / _num_behaviors)
        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('At trial', t, 'result', trial_df)

    df = pd.DataFrame(result)
    df.to_csv(os.path.join('result', f'new_verify_unlearning_{ts}_{args.dataset}.csv'))
    print('-' * 80)
    print('  ==>', df.groupby(['beta', 'm']).mean())
    print('The result is saved to', f'new_verify_unlearning_{ts}_{args.dataset}.csv')


def performance_comparison(args):
    # args.num_target_nodes = math.ceil(_calc_m(_alpah, _p[args.dataset]))
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False
    result = defaultdict(list)
    ts = int(time.time())

    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        # target_model = _get_target_model(args, data, device)
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        target_res = target_model.evaluate(data, device)

        surrogate_data = copy.deepcopy(data)
        surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        # surrogate.train(surrogate_data, device)

        _num_behaviors = 10
        for method in ['sga', 'fga', 'nettack', 'ours']:
        # for method in ['nettack']:
            # args.num_target_nodes = math.ceil(max(math.log(1 - _alpha, 1 - _q[args.dataset][method]), math.log(1 - _beta, 1 - _p[args.dataset][method])))
            m = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
            if m is None:
                raise ValueError(f'm is None, with alpha={_alpha}, beta={_beta}, p={_p[args.dataset]["ours"]}, q={_q[args.dataset]["ours"]}')
            args.num_target_nodes = m
            tp, tn = 0, 0
            statistics = defaultdict(list)
            used_node_tokens = set()
            acc_loss = []
            for _ in tqdm(range(_num_behaviors), desc=f'method={method}'):
                if method == 'nettack':
                    surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False, fix_weight=False)
                    surrogate.train(surrogate_data, device)
                    v_star, e_star, c_star = [], [], []
                    while len(v_star) < args.num_target_nodes:
                        v = random.choice(data.test_set.nodes.tolist())
                        if v in v_star:
                            continue
                        if used_node_tokens is not None and v in used_node_tokens:
                            continue
                        pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                        nettack = ntk(surrogate, data, v, pred)
                        nettack.reset()
                        nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                        E_t = nettack.structure_perturbations
                        v_star.append(v)
                        e_star.append(E_t)
                        c_star.append(_second_best_labels(post)[0])
                    p_star = target_model.predict(data, device, target_nodes=v_star)
                elif method == 'ours':
                    surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, bias=True, fix_weight=True)
                    surrogate.train(surrogate_data, device)
                    v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=False)
                    p_star = target_model.predict(data, device, target_nodes=v_star)
                else:
                    v_star, e_star, c_star = targeted_attack(surrogate_data, method, args.num_perts, t, ts, device, used_node_tokens)
                    p_star = target_model.predict(data, device, target_nodes=v_star)

                _tp_count, _tn_count = 0, 0
                _acc_loss = []
                for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                    used_node_tokens.add(v)

                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))                    
                    # adv_pred = _adv_train_predict(args, adv_data, e, [v], device)[0]
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                    adv.train(adv_data, device)
                    adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                    adv_res = adv.evaluate(adv_data, device) 
                    _acc_loss.append(np.abs(target_res['accuracy'] - adv_res['accuracy']) / target_res['accuracy'])

                    if adv_pred != p:
                        _tn_count += 1

                    # p = 0.2
                    # sub_perts = random.sample(e, min(int(len(e) * (1 - 0.2)), len(e) - 1))
                    # unlearn_data = copy.deepcopy(adv_data)
                    # unlearn_data.remove_edges(sub_perts)
                    # unlearn = GNN(args, unlearn_data.num_features, unlearn_data.num_classes, surrogate=False, fix_weight=True)
                    # unlearn.train(unlearn_data, device)
                    # unlearn_pred = unlearn.predict(unlearn_data, device, target_nodes=[v])
                    # if unlearn_pred == adv_pred:
                    #     _tp_count += 1
                    
                    # if _tp_count != 0 and _tn_count != 0:
                    #     break

                statistics['tp count'].append(_tp_count)
                statistics['tn count'].append(_tn_count)
                statistics['accuracy loss'].append(np.sum(_acc_loss))

                if _tp_count != 0:
                    tp += 1
                if _tn_count == args.num_target_nodes:
                    tn += 1
                acc_loss.append(_acc_loss)
                # if _tp_count >= len(v_star) * 0.5:
                #     tp += 1
                # if _tn_count >= len(v_star) * 0.5:
                #     tn += 1
            # print(f'At trial {t}, TPR: {tp / 50}, TNR: {tn / 50}')
            result['trial'].append(t)
            result['method'].append(method)
            result['m'].append(args.num_target_nodes)
            result['TPR'].append(tp / _num_behaviors)
            result['TNR'].append(tn / _num_behaviors)
            result['accuracy loss1'].append(np.sum(acc_loss))
            result['accuracy loss2'].append(np.array(acc_loss).mean())

            print('-' * 80)
            print('At trial', t, 'method:', method)
            print('accuracy loss', acc_loss)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('At trial', t, 'result', trial_df)
        print('statistics', statistics)
        print('-' * 80)

    df = pd.DataFrame(result)
    df.to_csv(os.path.join('result', f'new_verify_unlearning_{ts}_{args.dataset}.csv'))
    print('-' * 80)
    print('  ==>', df.groupby(['method']).mean())
    print('The result is saved to', f'new_verify_unlearning_{ts}_{args.dataset}.csv')

def detect_challenge_edges(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False
    result = defaultdict(list)
    ts = int(time.time())

    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        target_res = target_model.evaluate(data, device)

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        # surrogate.train(surrogate_data, device)

        _num_behaviors = 50
        for method in ['ours']:
            # for _ in tqdm(range(_num_behaviors), desc=f'method={method}'):
            if method == 'nettack':
                surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False)
                surrogate.train(surrogate_data, device)
                v_star, e_star, c_star = [], [], []
                while len(v_star) < args.num_target_nodes:
                    v = random.choice(data.test_set.nodes.tolist())
                    if v in v_star:
                        continue
                    pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                    nettack = ntk(surrogate, data, v, pred)
                    nettack.reset()
                    nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                    E_t = nettack.structure_perturbations
                    v_star.append(v)
                    e_star.append(E_t)
                    c_star.append(_second_best_labels(post)[0])
                p_star = target_model.predict(data, device, target_nodes=v_star)
            elif method == 'ours':
                surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, bias=True, fix_weight=True)
                surrogate.train(surrogate_data, device)
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=True)
                p_star = target_model.predict(data, device, target_nodes=v_star)
            elif method == 'random':
                v_star, e_star, c_star = [], [], []
                for _ in range(args.num_target_nodes):
                    _edges = []
                    while len(_edges) < args.num_perts:
                        u, v = random.sample(range(data.num_nodes), 2)
                        if data.has_edge(u, v):
                            _edges.append((u, v))
                    v_star.append(u)
                    e_star.append(_edges)
                    c_star.append(data.y[u].item())
            else:
                v_star, e_star, c_star = targeted_attack(surrogate_data, method, args.num_perts, t, ts, device)
                p_star = target_model.predict(data, device, target_nodes=v_star)

            history = {'tp': {}, 'tn': {}}
            tp_count, tn_count = 0, 0
            for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(e).t()))                    
                # adv_pred = _adv_train_predict(args, adv_data, e, [v], device)[0]
                adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                adv.train(adv_data, device)
                adv_pred = adv.predict(adv_data, device, target_nodes=[v])

                if adv_pred != p:
                    tn_count += 1
                    tn = True
                else:
                    tn = False

                sub_perts = random.sample(e, min(int(len(e) * (1 - 0.2)), len(e) - 1))
                # pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                # unlearn_data = copy.deepcopy(adv_data)
                adv_data.remove_edges(sub_perts)
                unlearn = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                unlearn.train(adv_data, device)
                unlearn_pred = unlearn.predict(adv_data, device, target_nodes=[v])

                if unlearn_pred == adv_pred:
                    tp_count += 1
                    tp = True
                else:
                    tp = False

                history['tp'][v] = tp
                history['tn'][v] = tn
                
                # history['trial'].append(t)
                # history['method'].append(method)
                # history['v'].append(v)
                # history['e'].append(e)
                # history['p'].append(p)
                # history['c'].append(c)
                # history['adv_pred'].append(adv_pred)
                # history['pos_pred'].append(pos_pred)
                # history['adv_res'].append(adv_res)
                # history['acc_loss'].append(_acc_loss)
                # history['tp'].append(tp)
                # history['tn'].append(tn)

            # for detector_type in ['lp', 'od', 'pd', 'js']:
            for detector_type in ['od', 'js']:
                if detector_type == 'lp':
                    detector = LinkPredDetector(data, v_star, e_star, device)
                elif detector_type == 'od':
                    detector = OutlierDetector(data, v_star, e_star)
                elif detector_type == 'ggd':
                    detector = GraphGenDetect(data, v_star, e_star, device)
                elif detector_type == 'pd':
                    detector = ProximityDetector(data, v_star, e_star, device)
                elif detector_type == 'js':
                    detector = JaccardSimilarity(data, v_star, e_star, device)
                r1, r2, escaped_nodes = detector.detect_all()
                tp_detect = sum([history['tp'][_v] for _v in escaped_nodes]) / len(v_star)
                tn_detect = sum([history['tn'][_v] for _v in escaped_nodes]) / len(v_star)
                tp_detect2 = sum([history['tp'][_v] for _v in escaped_nodes]) / len(escaped_nodes)
                tn_detect2 = sum([history['tn'][_v] for _v in escaped_nodes]) / len(escaped_nodes)
                
                result['trial'].append(t)
                result['method'].append(method)
                result['detector'].append(detector_type)
                result['original tp'].append(tp_count)
                result['original tn'].append(tn_count)
                result['detected tp'].append(tp_detect)
                result['detected tn'].append(tn_detect)
                result['detected tp 2'].append(tp_detect2)
                result['detected tn 2'].append(tn_detect2)
                result['detection ratio (edge)'].append(r1)
                result['detection ratio (node)'].append(r2)

        
        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        trial_df.to_csv(os.path.join('result', f'detect_challenge_edges_{ts}_{args.dataset}_{t}.csv'))
        print('At trial', t, f'result of {method}: ', trial_df.groupby(['method', 'detector']).mean())
    
    df = pd.DataFrame(result)
    df.to_csv(os.path.join('result', f'detect_challenge_edges_{ts}_{args.dataset}.csv'))
    # df2 = pd.DataFrame(history)
    # df2.to_csv(os.path.join('result', f'detect_challenge_edges_{ts}_{args.dataset}_history.csv'))

    print('-' * 80)
    print('  ==>', df.groupby(['method', 'detector']).mean())
    # print('  ==>', df2)

def find_adv_edges(args, target_model, surrogate, data, device, v_star):
    args.T = args.num_perts * 100
    weights = [p.detach().cpu().numpy() for p in surrogate.model.parameters()]
    verify = CertifiedFragilenessLazy(args, weights, data)

    _v_star, e_star, c_star = [], [], []
    for v in v_star:
        pred, post = target_model.predict(data, device, target_nodes=[v], return_posterior=True)
        c = _second_best_labels(post)[0]
        v, p, c = certify_fragile_with_perturbations((v, pred[0], c), args, verify, data)
        if p is not None:
            _v_star.append(v)
            e_star.append(p)
            c_star.append(c)
        else:
            raise ValueError(f'No adversarial edges found for node {v}.')
    args.T = args.num_perts * 3
    return _v_star, e_star, c_star

def verification_with_detection(args):
    args.num_target_nodes = math.ceil(_calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours']))
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False
    result = defaultdict(list)
    ts = int(time.time())

    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        surrogate.train(surrogate_data, device)

        _num_behaviors = 5
        tp, tn = 0, 0
        tp_detection = defaultdict(int)
        tn_detection = defaultdict(int)
        detection_result = defaultdict(list)

        for _ in tqdm(range(_num_behaviors), desc=f'verify vs detect'):
            v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device)
            p_star = target_model.predict(data, device, target_nodes=v_star)

            _tp_count, _tn_count = 0, 0
            # _tp_detect_count, _tn_detect_count = defaultdict(int), defaultdict(int)
            # _tp_detect_count1, _tn_detect_count1 = defaultdict(int), defaultdict(int)
            # history = {'tp': {}, 'tn': {}}
            for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(e).t()))
                
                adv_pred = _adv_train_predict(args, adv_data, e, [v], device)[0]
                if adv_pred != p:
                    _tn_count += 1

                sub_perts = random.sample(e, min(int(len(e) * (1 - 0.2)), len(e) - 1))
                pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                if pos_pred == adv_pred:
                    _tp_count += 1

            if _tp_count != 0:
                tp += 1
            if _tn_count == args.num_target_nodes:
                tn += 1


            # detection
            v_star_detect, e_star_detect, c_star_detect = find_adv_edges(args, target_model, surrogate, data, device, v_star)
            # print(f'v_star_detect: {v_star_detect}', f', e_star_detect: {e_star_detect}')
            # for detector_type in ['lp', 'od', 'js']:
            for detector_type in ['js']:
                _tp_count, _tn_count = 0, 0
                _detection_count = 0
                for v, e, p, c in zip(v_star_detect, e_star_detect, p_star, c_star_detect):
                    if detector_type == 'lp':
                        detector = LinkPredDetector(data, v_star, [e], device)
                    elif detector_type == 'od':
                        detector = OutlierDetector(data, v_star, [e])
                    elif detector_type == 'ggd':
                        detector = GraphGenDetect(data, v_star, [e], device)
                    elif detector_type == 'pd':
                        detector = ProximityDetector(data, v_star, [e], device)
                    elif detector_type == 'js':
                        detector = JaccardSimilarity(data, v_star, [e], device)

                    if detector.detect_all():
                        _detection_count += 1
                        continue
                    # if detector.detect_one(e):
                    #     _detection_count += 1
                    #     continue

                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))
                    adv_pred = _adv_train_predict(args, adv_data, e, [v], device)[0]
                    if adv_pred != p:
                        _tn_count += 1
                    
                    sub_perts = random.sample(e, min(int(len(e) * (1 - 0.2)), len(e) - 1))
                    unlearn_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                    if unlearn_pred == adv_pred:
                        _tp_count += 1

                if _tp_count != 0:
                    tp_detection[detector_type] += 1
                if _tn_count == args.num_target_nodes:
                    tn_detection[detector_type] += 1
                detection_result[detector_type].append(_detection_count)

                # detection_result['trial'].append(t)
                # detection_result['detector'].append(detector_type)
                # detection_result['target'].append(v)
                # detection_result['perturbations'].append(e)
                # detection_result['malicious'].append(1 if malicious else 0)
                # detection_result['malicious2'].append(1 if malicious2 else 0)


        # print(f'At trial {t}, TPR: {tp / 50}, TNR: {tn / 50}')
        result['trial'].append(t)
        result['m'].append(args.num_target_nodes)
        result['TPR'].append(tp / _num_behaviors)
        result['TNR'].append(tn / _num_behaviors)
        for d_type in ['lp', 'od', 'js']:
            result[f'TPR {d_type}'].append(tp_detection[d_type] / _num_behaviors)
            result[f'TNR {d_type}'].append(tn_detection[d_type] / _num_behaviors)
            # result[f'TPR1 {d_type}'].append(tp_detection1[d_type] / _num_behaviors)
            # result[f'TNR1 {d_type}'].append(tn_detection1[d_type] / _num_behaviors)
        # result['TPR detection'].append(tp_detection / _num_behaviors)
        # result['TNR detection'].append(tn_detection / _num_behaviors)
        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('At trial', t)
        print('Detection result', detection_result)
        print('  ==>', trial_df)

        # for d_type in ['lp', 'od', 'js']:
        #     print(f'  {d_type} 1 ==>', trial_df[f'TPR {d_type}'].values, trial_df[f'TNR {d_type}'].values)
        #     print(f'  {d_type} 2 ==>', trial_df[f'TPR1 {d_type}'].values, trial_df[f'TNR1 {d_type}'].values)
        # print('detection result', pd.DataFrame(detection_result).groupby('detector')['malicious'].mean())

    df = pd.DataFrame(result)
    df.to_csv(os.path.join('result', f'detection_verify_unlearning_{ts}_{args.dataset}.csv'))

    # df_detect = pd.DataFrame(detection_result)
    # df_detect.to_csv(os.path.join('result', f'detection_result_{ts}_{args.dataset}.csv'))
    print('-' * 80)
    print('  ==>', df)
    # print('  ==>', df_detect.groupby('detector')['malicious'].mean())
    print('The result is saved to', f'detection_verify_unlearning_{ts}_{args.dataset}.csv')
    print('-' * 80)
    print()
    # print('The result is saved to', f'detection_result_{ts}_{args.dataset}.csv')


def verify_unlearning_ours(args):
    device = utils.get_device(args)
    if args.seed is not None: 
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    result = defaultdict(list)
    # ts = ['1705829748', '1705835110', '1705838852', '1705843237', '1705847761']
    ts = time.time()
    for t in range(args.num_trials):
        if not is_fixed_seed:
            # with open(f'intermediate/{args.dataset}/seed_{t}_{args.dataset}_{ts[t]}.pkl', 'rb') as fp:
            #     args.seed = pickle.load(fp)
            # print('seed:', args.seed)
            # args.seed = random.randint(0, 1e+5)
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        # data_file = _get_data_filename(args, 'main', f'{t}_{ts[t]}')    
        # with open(os.path.join('intermediate', args.dataset, data_file), 'rb') as f:
        #     data = pickle.load(f)

        target_model = _get_target_model(args, data, device)
        # target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        # target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
        # target_model_file = _get_target_model_filename(args, 'main', f'{t}_{ts[t]}')
        # target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        # target_model.load_model(os.path.join('intermediate', args.dataset, target_model_file))
        # with open(target_model_file, 'rb') as f:
        #     target_model = pickle.load(f)
        
        # surrogate_data = copy.deepcopy(data)
        # surrogate_data.train_set.y = target_train_preds
        # if args.edge_sampler == 'nettack':
        #     surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False)
        # else:
        #     surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True)
        # surrogate.train(surrogate_data, device)
        # surr_test_preds = surrogate.predict(surrogate_data, device, target_nodes=data.test_set.nodes.tolist())
        # surrogate_model_filename = _get_surrogate_model_filename(args, 'main', f'{t}_{ts[t]}')
        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        # surrogate.load_model(os.path.join('intermediate', args.dataset, surrogate_model_filename))

        # candidates_filename = _get_candidates_filename(args, 'main', 'ours', f'{t}_{ts[t]}')
        # with open(os.path.join('intermediate', args.dataset, candidates_filename), 'rb') as f:
        #     v_star = pickle.load(f)
        # perturbations_filename = _get_perturbations_filename(args, 'main', 'ours', f'{t}_{ts[t]}')
        # with open(os.path.join('intermediate', args.dataset, perturbations_filename), 'rb') as f:
        #     e_star = pickle.load(f)
        v_star, e_star, c_star = find_1pf(args, target_model, target_model, data, device)
        p_star = target_model.predict(data, device, target_nodes=v_star)

        for num_node_tokens in [args.num_target_nodes]:
            _candidates, _perturbations, _predictions = [], [], []
            for candidate, perturbation, pred in zip(v_star[:num_node_tokens], e_star[:num_node_tokens], p_star[:num_node_tokens]):
                if perturbation is not None and len(perturbation) > 1:
                    _candidates.append(candidate)
                    _perturbations.append(perturbation)
                    _predictions.append(pred)
                    # _attack_label.append(attack_label)
            # _candidates = np.array(_candidates)
            # _perturbations = np.array(_perturbations)
            all_perturbations = [p for pert in _perturbations for p in pert]
            _predictions = np.array(_predictions)
            # _attack_label = np.array(_attack_label)

            # add perturbations to the graph
            adv_predictions = _adv_train_predict(args, data, all_perturbations, _candidates, device)
            # how many nodes are successfully attacked
            # consist_asr = np.sum(adv_predictions == _attack_label) / len(_candidates)
            asr = np.sum(adv_predictions != _predictions) / len(_candidates)
            adv_data = copy.deepcopy(data)
            adv_data.add_edges(to_undirected(torch.tensor(all_perturbations).t()))

            tp, tn, fp, fn = {}, {}, {}, {}
            # for p in args.percentages:
            for p in [0.2]:
                tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
                t0 = time.time()
                for idx in tqdm(range(len(_candidates)), desc=f'At trial {t}, ours verifying {p}%'):
                    # rand_idx = random.choice(range(len(_candidates)))
                    trial_v = _candidates[idx]
                    trial_perts = _perturbations[idx]
                    if len(trial_perts) != args.num_perts:
                        logging.warning('The number of perturbations is less than 10, but %d', len(trial_perts))
                    # trial_pred = _predictions[idx]

                    adv_pred = adv_predictions[idx]

                    neg_pred = _unlearn_train_predict(args, adv_data, trial_perts, [trial_v], device)
                    if neg_pred[0] != adv_pred:
                        tn[p] += 1
                    else:
                        fp[p] += 1

                    sub_perts = random.sample(trial_perts, max(int(len(trial_perts) * (1 - p)), 1))
                    pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [trial_v], device)
                    if pos_pred[0] == adv_pred:
                        tp[p] += 1
                    else:
                        fn[p] += 1

                    # if p == 0.5:
                        # print('adv_pred:', adv_pred)
                        # print('neg_pred:', neg_pred)
                        # print('pos_pred:', pos_pred)
                        # print('trial_perts:', trial_perts)
                        # print('sub_perts:', sub_perts)
                        # print('trial_v:', trial_v)
                        # print('pred:', _predictions[idx])
                        # exit(0)

                verify_time = time.time() - t0
                result['trial'].append(t)
                result['method'].append('ours')
                # result['total_preparation_time'].append(total_preparation_time)
                # result['total_iteration'].append(iter_count.value)
                result['num node tokens'].append(num_node_tokens)
                result['p'].append(p)
                result['tp'].append(tp[p])
                result['tn'].append(tn[p])
                result['fp'].append(fp[p])
                result['fn'].append(fn[p])    
                result['verify time'].append(verify_time)
        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        trial_df.to_csv(os.path.join('intermediate', f'tmp_result_{args.dataset}_at{t}.csv'))

        print('-' * 80)
        print(f'trial {t} is done')
        # print(f'  ==> the surrogate model is saved to', surrogate_model_filename)
        print(f'  ==> The main result at {t}:')
        print(f'  ', trial_df.groupby(['method', 'num node tokens', 'p']).mean()[['tp', 'tn', 'fp', 'fn']])
        print('-' * 80)

    df = pd.DataFrame(result)
    result_filename = _result_filename(args, 'verify')
    df.to_csv(os.path.join('result', result_filename))

    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print('-' * 80)


def test_nettack_on_lastfm(args):
    args.dataset = 'lastfm'

    device = utils.get_device(args)
    args.seed = random.randint(0, 1e+5)
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed_all(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)

    data = data_loader.load(args)
    target_model = _get_target_model(args, data, device)
    target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

    surrogate_data = copy.deepcopy(data)
    surrogate_data.train_set.y = target_train_preds
    surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False)
    surrogate.train(surrogate_data, device)

    v_star, e_star, c_star = [], [], []
    pbar = tqdm(total=args.num_target_nodes, desc='attacking')

    # low_freq_nodes = data.test_set.nodes[data.test_set.y == 1].tolist()
    # low_freq_nodes += data.test_set.nodes[data.test_set.y == 2].tolist()
    # low_freq_nodes += data.test_set.nodes[data.test_set.y == 4].tolist()
    # low_freq_nodes += data.test_set.nodes[data.test_set.y == 7].tolist()
    # low_freq_nodes += data.test_set.nodes[data.test_set.y == 9].tolist()
    # low_freq_nodes += data.test_set.nodes[data.test_set.y == 12].tolist()
    # low_freq_nodes += data.test_set.nodes[data.test_set.y == 13].tolist()
    # print('number of low freq nodes:', len(low_freq_nodes))
    while len(v_star) < args.num_target_nodes:
        # v = random.choice(low_freq_nodes)
        v = random.choice(data.test_set.nodes.tolist())
        if v in v_star:
            continue
        pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
        nettack = ntk(surrogate, surrogate_data, v, pred)
        nettack.reset()
        nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
        E_t = nettack.structure_perturbations
        v_star.append(v)
        e_star.append(E_t)
        c_star.append(_second_best_labels(post)[0])
        pbar.update(1)
    pbar.close()

    success_count = 0
    p_star = target_model.predict(data, device, target_nodes=v_star)
    for v, e, pred in tqdm(zip(v_star, e_star, p_star), total=len(v_star), desc=f'evaluating Nettack'):
        if e is None or len(e) == 0:
            continue
        adv_data = copy.deepcopy(data)
        adv_data.add_edges(to_undirected(torch.tensor(e).t()))
        adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
        adv.train(adv_data, device)

        adv_pred = adv.predict(adv_data, device, target_nodes=[v])[0]
        print('target node:', v)
        print('ground truth:', data.y[v].item())
        print('original prediction:', pred)
        print('adv prediction:', adv_pred)
        print('perturbations:', e)
        print('perturbation labels:', [data.y[_e[1]].item() for _e in e])
        print('perturbation degree:', [data.degree(_e[1]) for _e in e])

        if adv_pred == pred:
            success_count += 1
    
    print('Nettack success rate:', success_count / len(v_star))

def targeted_attack(surrogate_data, method, num_perts, trial, ts, device, used_node_tokens=None): 
    adj = surrogate_data.adjacency_matrix().to(device)
    if method == 'sga':
        surrogate = SGC(nfeat=surrogate_data.num_features,
                        nclass=surrogate_data.num_classes,
                        K=2,
                        device=device).to(device)
        # Data = namedtuple('Data', 'x y edge_index')
        x = surrogate_data.x.to(device)
        y = surrogate_data.y.to(device)
        data = Data(x=x, y=y, edge_index=to_undirected(surrogate_data.edge_index))
        data.train_mask = surrogate_data.train_set.nodes
        data.val_mask = surrogate_data.valid_set.nodes
        surrogate.fit((data, x.size(1), torch.max(y).item() + 1), verbose=False)
    else:
        surrogate = GCN(nfeat=surrogate_data.num_features, 
                        nclass=surrogate_data.num_classes, 
                        nhid=8, 
                        with_relu=True, 
                        with_bias=True, 
                        device=device).to(device)
        surrogate.fit(surrogate_data.x.to(device), 
                    adj, 
                    surrogate_data.y.to(device), 
                    surrogate_data.train_set.nodes.tolist(), 
                    surrogate_data.valid_set.nodes.tolist())

    if method == 'sga':
        attacker = SGAttack(surrogate, nnodes=surrogate_data.num_nodes, attack_structure=True, attack_features=False, device=device)
    elif method == 'fga':
        attacker = FGA(surrogate, surrogate_data.num_nodes, attack_structure=True, attack_features=False, device=device)
    elif method == 'rnd':
        attacker = RND(surrogate, nnodes=surrogate_data.num_nodes, attack_structure=True, attack_features=False, device=device)
    elif method == 'ig':
        attacker = IGAttack(surrogate, nnodes=surrogate_data.num_nodes, attack_structure=True, attack_features=False, device=device)
    elif method == 'pgd':
        attacker = PGDAttack(surrogate, nnodes=surrogate_data.num_nodes, attack_structure=True, attack_features=False, device=device)
    elif method == 'minmax':
        attacker = MinMax(surrogate, nnodes=surrogate_data.num_nodes, attack_structure=True, attack_features=False, device=device)

    n_perturbations = num_perts
    v_star, e_star, c_star = [], [], []
    # pbar = tqdm(total=args.num_target_nodes, desc='attacking')
    while len(v_star) < args.num_target_nodes:
        v = random.choice(surrogate_data.test_set.nodes.tolist())
        if v in v_star:
            continue
        if used_node_tokens is not None and v in used_node_tokens:
            continue

        # pred, post= surrogate.predict(surrogate_data, device, target_nodes=[v], return_posterior=True)
        if isinstance(surrogate, SGC):
            post = surrogate.predict().cpu().detach().numpy()
        else:
            post = surrogate.predict(surrogate_data.x.to(device), adj)[v].cpu().detach().numpy()
            post = post[np.newaxis, :]

        row = surrogate_data.edge_index.numpy()[0]
        col = surrogate_data.edge_index.numpy()[1]
        value = np.ones((len(row)))
        _adj = sp.csr_matrix((value, (row, col)), shape=(surrogate_data.num_nodes, surrogate_data.num_nodes))
        if method == 'sga':
            try:
                attacker.attack(surrogate_data.x.to(device), 
                                _adj, 
                                surrogate_data.y, 
                                v, n_perturbations, direct=True)
            except RuntimeError as e:
                print('RuntimeError:', e)
                # raise e
                continue

        elif method == 'rnd':
            attacker.attack(_adj, 
                            surrogate_data.y.numpy(),
                            surrogate_data.train_set.nodes.tolist(), 
                            v, n_perturbations, direct=True)
        else:
            attacker.attack(surrogate_data.x,
                            _adj, 
                            surrogate_data.y,
                            surrogate_data.train_set.nodes.tolist(), 
                            v, 
                            n_perturbations, 
                            direct=True)
        if method in ['fga', 'rnd', 'ig']:
            modified_adj = attacker.modified_adj
            perturbed_edges = np.array(np.where(modified_adj != _adj.todense()))
            perturbed_edges = perturbed_edges[:, perturbed_edges[0] < perturbed_edges[1]]
            E_t = list(map(tuple, perturbed_edges.T.tolist()))[:n_perturbations]
        else:
            E_t = attacker.structure_perturbations
        if E_t is None or len(E_t) == 0:
            continue
        v_star.append(v)
        e_star.append(E_t)
        c_star.append(_second_best_labels(post)[0])
        # pbar.update(1)
    # pbar.close()
    return v_star, e_star, c_star

def find_perturbations_baselines(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time()) 
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        data_filename = os.path.join('intermediate', args.dataset, f'data{t}_{ts}_{args.method}.pkl')
        with open(data_filename, 'wb') as f:
            pickle.dump(data, f)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        target_model.train(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        target_filename = os.path.join('intermediate', args.dataset, f'target{t}_{ts}_{args.method}.pt')
        target_model.save_model(target_filename)

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = target_train_preds
        surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)

        if args.method == 'nettack':
            surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False)
            surrogate.train(surrogate_data, device)
            surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pt')
            surrogate.save_model(surrogate_filename)

            v_star, e_star, c_star = [], [], []
            pbar = tqdm(total=args.num_target_nodes, desc='attacking')
            while len(v_star) < args.num_target_nodes:
                v = random.choice(data.test_set.nodes.tolist())
                if v in v_star:
                    continue
                pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                nettack = ntk(surrogate, data, v, pred)
                nettack.reset()
                nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                E_t = nettack.structure_perturbations
                v_star.append(v)
                e_star.append(E_t)
                c_star.append(_second_best_labels(post)[0])
                pbar.update(1)
            pbar.close()
        elif args.method == 'gf':
            surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pkl')
            # with open(surrogate_filename, 'wb') as f:
            #     pickle.dump(surrogate, f)

            n_perturbations = args.num_perts
            v_star, e_star, c_star = [], [], []
            pbar = tqdm(total=args.num_target_nodes, desc='attacking')
            while len(v_star) < args.num_target_nodes:
                v = random.choice(data.test_set.nodes.tolist())
                if v in v_star:
                    continue
                pred, post= target_model.predict(surrogate_data, device, target_nodes=[v], return_posterior=True)
                gf_attack = gfa(surrogate_data, v, n_perturbations, device)
                E_t = gf_attack.structure_perturbations
                if E_t is None or len(E_t) == 0:
                    continue
                v_star.append(v)
                e_star.append(E_t)
                c_star.append(_second_best_labels(post)[0])
                pbar.update(1)
            pbar.close()
        else:  # method in ['sga', 'fga', 'rnd', 'ig', 'pgd', 'minmax']
            v_star, e_star, c_star = targeted_attack(surrogate_data, args.method, args.num_perts, t, ts, device)
        # elif args.method == 'sga':
        #     surrogate = GCN(nfeat=data.num_features, 
        #                     nclass=data.num_classes, 
        #                     nhid=16, 
        #                     with_relu=True, 
        #                     with_bias=True, 
        #                     device=device).to(device)
        #     adj = surrogate_data.adjacency_matrix().to(device)
        #     surrogate.fit(surrogate_data.x.to(device), 
        #                   adj, 
        #                   surrogate_data.y.to(device), 
        #                   data.train_set.nodes.tolist(), 
        #                   data.valid_set.nodes.tolist())

        #     surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pkl')
        #     with open(surrogate_filename, 'wb') as f:
        #         pickle.dump(surrogate, f)

        #     attack = SGAttack(surrogate, attack_structure=True, attack_features=False, device=device)
        #     n_perturbations = args.num_perts
        #     v_star, e_star, c_star = [], [], []
        #     pbar = tqdm(total=args.num_target_nodes, desc='attacking')
        #     while len(v_star) < args.num_target_nodes:
        #         v = random.choice(data.test_set.nodes.tolist())
        #         if v in v_star:
        #             continue
        #         pred, post= target_model.predict(surrogate_data, device, target_nodes=[v], return_posterior=True)
        #         E_t = attack.structure_perturbations
        #         if E_t is None or len(E_t) == 0:
        #             continue
        #         v_star.append(v)
        #         e_star.append(E_t)
        #         c_star.append(_second_best_labels(post)[0])
        #         pbar.update(1)
        #     pbar.close()
        # elif args.method == 'ig':
        #     surrogate = GCN(nfeat=data.num_features, nclass=data.num_classes, nhid=16, with_relu=True, with_bias=True, device=device).to(device)
        #     surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pkl')
        #     with open(surrogate_filename, 'wb') as f:
        #         pickle.dump(surrogate, f)

        #     # contruct adjacency matrix
        #     row = data.edge_index.numpy()[0]
        #     col = data.edge_index.numpy()[1]
        #     value = np.ones((len(row)))
        #     adj = sp.csr_matrix((value, (row, col)), shape=(data.num_nodes, data.num_nodes))
        #     surrogate.fit(surrogate_data.x, adj, surrogate_data.y, data.train_set.nodes.tolist(), data.valid_set.nodes.tolist())
        #     # contruct features sparse
        #     row, col = np.where(data.x.numpy() == 1)
        #     value = np.ones((len(row)))
        #     x = sp.csr_matrix((value, (row, col)), shape=data.x.shape)
        #     labels = surrogate_data.y.numpy()
        #     attacker = IGAttack(surrogate, data.num_nodes, attack_structure=True, attack_features=False, device=device).to(device)
        #     v_star, e_star, c_star = [], [], []
        #     pbar = tqdm(total=args.num_target_nodes, desc='attacking')
        #     while len(v_star) < args.num_target_nodes:
        #         v = random.choice(data.test_set.nodes.tolist())
        #         if v in v_star:
        #             continue
        #         pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
        #         n_perturbations = args.num_perts
        #         idx_nodes = data.train_set.nodes.to(device)
        #         try:
        #             attacker.attack(x, adj, labels, data.train_set.nodes.tolist(), v, n_perturbations=n_perturbations, steps=10)
        #         except Exception as e:
        #             print('error:', e)
        #             continue
                
        #         perturbed_edges = np.array(np.where(attacker.modified_adj != adj.toarray()))
        #         perturbed_edges = perturbed_edges[:, perturbed_edges[0] < perturbed_edges[1]]
        #         E_t = list(map(tuple, perturbed_edges.T.tolist()))
        #         if E_t is None or len(E_t) == 0:
        #             continue
        #         v_star.append(v)
        #         e_star.append(E_t)
        #         c_star.append(_second_best_labels(post)[0])
        #         pbar.update(1)
        #     pbar.close()
        # elif args.method == 'pgd':
        #     surrogate_data = copy.deepcopy(data)
        #     surrogate_data.train_set.y = target_train_preds
        #     surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)
            
        #     surrogate = GCN(nfeat=data.num_features, nclass=data.num_classes, nhid=16, with_relu=True, with_bias=True, device=device).to(device)
        #     surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pkl')

        #     with open(surrogate_filename, 'wb') as f:
        #         pickle.dump(surrogate, f)
        #     # contruct adjacency matrix
        #     row = data.edge_index.numpy()[0]
        #     col = data.edge_index.numpy()[1]
        #     value = np.ones((len(row)))
        #     adj = torch.sparse_coo_tensor(
        #         (row, col), value, size=(data.num_nodes, data.num_nodes), dtype=torch.int
        #     ).to_dense().numpy()
        #     surrogate.fit(surrogate_data.x, adj, surrogate_data.y, data.train_set.nodes.tolist(), data.valid_set.nodes.tolist())
        #     attacker = PGDAttack(surrogate, data.num_nodes, loss_type='CE', device=device).to(device)

        #     v_star, e_star, c_star = [], [], []
        #     pbar = tqdm(total=args.num_target_nodes, desc='attacking')
        #     while len(v_star) < args.num_target_nodes:
        #         v = random.choice(data.test_set.nodes.tolist())
        #         if v in v_star:
        #             continue
        #         pred, post= target_model.predict(surrogate_data, device, target_nodes=[v], return_posterior=True)

        #         n_perturbations = args.num_perts
        #         idx_nodes = data.train_set.nodes.to(device)
        #         try:
        #             attacker.attack(surrogate_data.x.numpy(), adj, surrogate_data.y.numpy(), idx_nodes, v, n_perturbations=n_perturbations+2)
        #         except Exception as e:
        #             print('error:', e)
        #             continue
        #         modified_adj = attacker.modified_adj.cpu().numpy()
        #         perturbed_edges = np.array(np.where(modified_adj != adj))
        #         perturbed_edges = perturbed_edges[:, perturbed_edges[0] < perturbed_edges[1]]
        #         E_t = list(map(tuple, perturbed_edges.T.tolist()))[:n_perturbations]
        #         if E_t is None or len(E_t) == 0:
        #             continue
        #         v_star.append(v)
        #         e_star.append(E_t)
        #         c_star.append(_second_best_labels(post)[0])
        #         pbar.update(1)
        #     pbar.close()
        
        #     # v_star_filename = os.path.join('intermediate', args.dataset, f'v_star{t}_{ts}_{args.method}.pkl')
        #     # with open(v_star_filename, 'wb') as f:
        #     #     pickle.dump(v_star, f)
        #     # e_star_filename = os.path.join('intermediate', args.dataset, f'e_star{t}_{ts}_{args.method}.pkl')
        #     # with open(e_star_filename, 'wb') as f:
        #     #     pickle.dump(e_star, f)
        #     # c_star_filename = os.path.join('intermediate', args.dataset, f'c_star{t}_{ts}_{args.method}.pkl')
        #     # with open(c_star_filename, 'wb') as f:
        #     #     pickle.dump(c_star, f)
        #     # seed_filename = os.path.join('intermediate', args.dataset, f'seed{t}_{ts}_{args.method}.pkl')
        #     # with open(seed_filename, 'wb') as f:
        #     #     pickle.dump(args.seed, f)
        # else:
        #     surrogate_data = copy.deepcopy(data)
        #     surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)
        #     surrogate = GCN(nfeat=data.num_features, nclass=data.num_classes, nhid=16, with_relu=True, with_bias=False, device=device).to(device)
        #     adj = data.adjacency_matrix().to_dense().numpy()
        #     surrogate.fit(data.x, adj, data.y, data.train_set.nodes.tolist(), data.valid_set.nodes.tolist())
        #     surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pt')
        #     with open(surrogate_filename, 'wb') as f:
        #         pickle.dump(surrogate, f)

        #     v_star, e_star, c_star = [], [], []
        #     pbar = tqdm(total=args.num_target_nodes, desc='attacking')
        #     while len(v_star) < args.num_target_nodes:
        #         v = random.choice(data.test_set.nodes.tolist())
        #         if v in v_star:
        #             continue
        #         pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)

        #         attacker = MinMax(surrogate, data.num_nodes, loss_type='CW', device=device).to(device)
        #         n_perturbations = args.num_perts
        #         idx_nodes = data.train_set.nodes.to(device)
        #         try:
        #             attacker.attack(data.x.numpy(), adj, data.y.numpy(), idx_nodes, v, n_perturbations=n_perturbations+2)
        #         except Exception as e:
        #             print('error:', e)
        #             continue
        #         modified_adj = attacker.modified_adj.cpu().numpy()
        #         perturbed_edges = np.array(np.where(modified_adj != adj))
        #         perturbed_edges = perturbed_edges[:, perturbed_edges[0] < perturbed_edges[1]]
        #         E_t = list(map(tuple, perturbed_edges.T.tolist()))[:n_perturbations]
        #         if E_t is None or len(E_t) == 0:
        #             continue
        #         v_star.append(v)
        #         e_star.append(E_t)
        #         c_star.append(_second_best_labels(post)[0])
        #         pbar.update(1)
        #     pbar.close()
        
        v_star_filename = os.path.join('intermediate', args.dataset, f'v_star{t}_{ts}_{args.method}.pkl')
        with open(v_star_filename, 'wb') as f:
            pickle.dump(v_star, f)
        e_star_filename = os.path.join('intermediate', args.dataset, f'e_star{t}_{ts}_{args.method}.pkl')
        with open(e_star_filename, 'wb') as f:
            pickle.dump(e_star, f)
        c_star_filename = os.path.join('intermediate', args.dataset, f'c_star{t}_{ts}_{args.method}.pkl')
        with open(c_star_filename, 'wb') as f:
            pickle.dump(c_star, f)
        seed_filename = os.path.join('intermediate', args.dataset, f'seed{t}_{ts}_{args.method}.pkl')
        with open(seed_filename, 'wb') as f:
            pickle.dump(args.seed, f)

        print('At trial', t, 'method:', args.method, 'is done')
        print('       ==> the data model is saved to ', data_filename)
        print('     ==> the target model is saved to ', target_filename)
        print('           ==> the v_star is saved to ', v_star_filename)
        print('           ==> the e_star is saved to ', e_star_filename)
        print('           ==> the c_star is saved to ', c_star_filename)
        print('             ==> the seed is saved to ', seed_filename)


def find_1pf_and_perturbation(args):
    device = utils.get_device(args)

    ts = int(time.time())
    for t in range(args.num_trials):
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        
        seed_file = f'seed_{t}_{args.dataset}_{ts}.pkl'
        with open(os.path.join('intermediate', seed_file), 'wb') as fp:
            pickle.dump(args.seed, fp)
        
        data = data_loader.load(args)
        data_filename = _data_filename(args, f'main{t}_{ts}')
        with open(os.path.join('intermediate', data_filename), 'wb') as fp:
            pickle.dump(data, fp)

        target_model = _get_target_model(args, data, device, type=args.gcn_type)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        target_filename = _target_model_filename(args, f'main{t}_{ts}')
        target_model.save_model(os.path.join('intermediate', target_filename))


        # surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=False)
        # surrogate.train(data, device)
        # surrogate.load_model(os.path.join('intermediate', surrogate_file))
        surrogate = copy.deepcopy(target_model)
        surrogate_filename = _surrogate_model_filename(args, f'main{t}_{ts}')
        surrogate.save_model(os.path.join('intermediate', surrogate_filename))

        weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
        verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False)
        v_star, e_star, c_star = [], [], []
        t0 = time.time()
        pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
        iter_count = 0
        while len(v_star) < args.num_target_nodes:
            # sample a node
            v = random.choice(data.test_set.nodes.tolist())
            if v in v_star:
                continue
            pred, post = target_model.predict(data, device, target_nodes=[v], return_posterior=True)
            c = _second_best_labels(post)[0]
            # sample a perturbation
            # perturbation = sample_edge_tokens(args, data, v, surrogate, predictions[v], target_label=c_star[v])
            v, perturbation, c = certify_fragile_with_perturbations((v, pred, c), args, verifier, data)
            if perturbation is not None:
                v_star.append(v)
                e_star.append(perturbation)
                c_star.append(c)
                pbar.update(1)
            iter_count += 1
            pbar.set_description(f'after certifying {iter_count} nodes')

        # using multiprocessing to improve the efficiency
        # predictions, posterior = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
        # c_star = _second_best_labels(posterior)

        # t0 = time.time()
        # weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
        # v_star, e_star = [], []
        # t0 = time.time()
        # num_processes = 5
        # with multiprocessing.Pool(processes=num_processes) as pool:
        #     verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False)
        #     pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
        #     v_star = multiprocessing.Manager().list()
        #     e_star = multiprocessing.Manager().list()
        #     iter_count = multiprocessing.Value('i', 0)
        #     lock = multiprocessing.Lock()
        #     for v, perb in pool.imap_unordered(
        #         partial(certify_fragile_with_perturbations, args=args, verifier=verifier, data=data),
        #         zip(data.test_set.nodes.tolist(), predictions, c_star)
        #     ):
        #         print('v:', perb)
        #         if perb is not None:
        #             with lock:
        #                 v_star.append(v)
        #                 e_star.append(perb)
        #                 pbar.update(1)
        #         else:
        #             pbar.set_description(f'At trial {t}, after certifing {iter_count.value} nodes')
        #         with lock:
        #             if len(v_star) == args.num_target_nodes:
        #                 break
        #             iter_count.value += 1

        # p_star = target_model.predict(data, device, target_nodes=list(v_star))

        preparation_time = time.time() - t0
        perturbations_filename = _perturbations_filename(args, f'main{t}_{ts}', 'ours')
        with open(os.path.join('intermediate', perturbations_filename), 'wb') as fp:
            pickle.dump(list(e_star), fp)
        candidates_filename = _candidates_filename(args, f'main{t}_{ts}', 'ours')
        with open(os.path.join('intermediate', candidates_filename), 'wb') as fp:
            pickle.dump(list(v_star), fp)
        attack_labels_filename = _attack_labels_filename(args, f'main{t}_{ts}', 'ours')
        with open(os.path.join('intermediate', attack_labels_filename), 'wb') as fp:
            pickle.dump(list(c_star), fp)
        print('preparation time:', preparation_time)
        print('-' * 80)
        print(f'trial {t} is done')
        print('       ==> the data model is saved to ', data_filename)
        print('     ==> the target model is saved to ', target_filename)
        print('           ==> the v_star is saved to ', candidates_filename)
        print('           ==> the e_star is saved to ', perturbations_filename)
        print('           ==> the c_star is saved to ', attack_labels_filename)
        print('             ==> the seed is saved to ', seed_file)


def find_perturbations(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        logging.info('Start verifing unlearning at trial %d ...', t)
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        data_filename = _data_filename(args, f'main{t}_{ts}')
        with open(os.path.join('intermediate', data_filename), 'wb') as fp:
            pickle.dump(data, fp)

        logging.info('  ==> Loading the target model ...')
        t0 = time.time()
        target_model = _get_target_model(args, data, device)
        target_model_filename = _target_model_filename(args, f'main{t}_{ts}')
        target_model.save_model(os.path.join('intermediate', target_model_filename))
        print('training time:', time.time() - t0)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        # target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = target_train_preds
        # surr_test_preds = surrogate.predict(surrogate_data, device, target_nodes=data.test_set.nodes.tolist())

        for method in args.methods:
            logging.info('  ==> Sampling node tokens ...')
            if args.node_sampler == 'boundary':
                v_star = sample_node_tokens(args, data, data.test_set.nodes.tolist(), target_model, amplify=1)
            elif args.node_sampler == 'random':
                v_star = random.sample(data.test_set.nodes.tolist(), args.num_target_nodes)
            p_star, posteriors = target_model.predict(data, device, target_nodes=v_star, return_posterior=True)
            # c_star = _second_best_labels(posteriors)

            surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False, fix_weight=False)
            surrogate.train(data, device)
            surrogate_preds = surrogate.predict(data, device, target_nodes=v_star)
            surrogate_model_filename = _surrogate_model_filename(args, f'main{t}_{ts}')
            surrogate.save_model(os.path.join('intermediate', surrogate_model_filename))

            args.edge_sampler = method
            e_star = []
            for v, pred in tqdm(zip(v_star, p_star), total=len(v_star), desc=f'At trial {t}, {method} attacking'):
                perturbations = sample_edge_tokens(args, data, v, surrogate, pred)
                e_star.append(perturbations)
            perturbations_filename = _perturbations_filename(args, f'main{t}_{ts}', method)
            with open(os.path.join('intermediate', perturbations_filename), 'wb') as fp:
                pickle.dump(list(e_star), fp)
            candidates_filename = _candidates_filename(args, f'main{t}_{ts}', method)
            with open(os.path.join('intermediate', candidates_filename), 'wb') as fp:
                pickle.dump(list(v_star), fp)
            total_preparation_time = time.time() - t0

        print('-' * 80)
        print(f'trial {t} is done')
        print(f'  ==> the target model is saved to', target_model_filename)
        print(f'  ==> the surrogate model is saved to', surrogate_model_filename)
        print(f'  ==> the data is saved to', data_filename)
        print(f'  ==> the perturbations are saved to', perturbations_filename)
        print(f'  ==> the candidates are saved to', candidates_filename)
        print(f'  ==> preparation time:', total_preparation_time)
        print('-' * 80)

    # try:    
    #     df = pd.DataFrame(result, index=None)
    # except ValueError as err:
    #     print('result', result)
    #     raise err
    
    # result_filename = _result_filename(args, 'verify')
    # df.to_csv(os.path.join('result', result_filename))
    
    # print('-' * 80)
    # print('Verifing unlearning is done')
    # print(f'  ==> the result file is saved to', result_filename)
    # print('-' * 80)


def verify_unlearning(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        logging.info('Start verifing unlearning at trial %d ...', t)
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        data_filename = _data_filename(args, f'main{t}_{ts}')
        with open(os.path.join('intermediate', data_filename), 'wb') as fp:
            pickle.dump(data, fp)

        logging.info('  ==> Loading the target model ...')
        t0 = time.time()
        target_model = _get_target_model(args, data, device)
        target_model_filename = _target_model_filename(args, f'main{t}_{ts}')
        target_model.save_model(os.path.join('intermediate', target_model_filename))

        print('training time:', time.time() - t0)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        # target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = target_train_preds
        # surr_test_preds = surrogate.predict(surrogate_data, device, target_nodes=data.test_set.nodes.tolist())

        iter_count = 0
        for method in args.methods:
            t0 = time.time()
            if method in ['nettack', 'minmax', 'ig', 'pgd', 'gf']:
                logging.info('  ==> Sampling node tokens ...')
                if args.node_sampler == 'boundary':
                    v_star = sample_node_tokens(args, data, data.test_set.nodes.tolist(), target_model, amplify=1)
                elif args.node_sampler == 'random':
                    v_star = random.sample(data.test_set.nodes.tolist(), args.num_target_nodes)
                p_star, posteriors = target_model.predict(data, device, target_nodes=v_star, return_posterior=True)
                # c_star = _second_best_labels(posteriors)

                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False, fix_weight=False)
                surrogate.train(data, device)
                surrogate_preds = surrogate.predict(data, device, target_nodes=v_star)
                surrogate_model_filename = _surrogate_model_filename(args, f'main{t}_{ts}')
                surrogate.save_model(os.path.join('intermediate', surrogate_model_filename))

                args.edge_sampler = method
                e_star = []
                for v, pred in tqdm(zip(v_star, p_star), total=len(v_star), desc=f'At trial {t}, {method} attacking'):
                    perturbations = sample_edge_tokens(args, data, v, surrogate, pred)
                    e_star.append(perturbations)
                perturbations_filename = _perturbations_filename(args, f'main{t}_{ts}', method)
                with open(os.path.join('intermediate', perturbations_filename), 'wb') as fp:
                    pickle.dump(list(e_star), fp)
                candidates_filename = _candidates_filename(args, f'main{t}_{ts}', method)
                with open(os.path.join('intermediate', candidates_filename), 'wb') as fp:
                    pickle.dump(list(v_star), fp)
            elif method == 'ours':
                # logging.info('  ==> Loading the surrogate model ...') 
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=False)
                surrogate.train(data, device)

                # num_processes = 5
                # shared_condition = multiprocessing.Values('num_1pf_nodes', 0)

                # processes = []
                # for i in range(num_processes):
                #     process = multiprocessing.Process(target=certify_fragile_with_perturbations, )

                print('  ==> start to run CVX searching ...')
                weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
                predictions, posteriors = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
                c_star = _second_best_labels(posteriors)
                # verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False)
                v_star, e_star = [], []
                # c_star = []
                t0 = time.time()
                num_processes = 5
                with multiprocessing.Pool(processes=num_processes) as pool:
                    verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False)
                    pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
                    v_star = multiprocessing.Manager().list()
                    e_star = multiprocessing.Manager().list()
                    iter_count = multiprocessing.Value('i', 0)
                    lock = multiprocessing.Lock()
                    for v, perb in pool.imap_unordered(
                        partial(certify_fragile_with_perturbations, args=args, verifier=verifier, data=data),
                        zip(data.test_set.nodes.tolist(), predictions, c_star)
                    ):
                        print('v:', perb)
                        if perb is not None:
                            with lock:
                                v_star.append(v)
                                e_star.append(perb)
                                pbar.update(1)
                        else:
                            pbar.set_description(f'At trial {t}, after certifing {iter_count.value} nodes')
                        with lock:
                            if len(v_star) == args.num_target_nodes:
                                break
                            iter_count.value += 1

                p_star = target_model.predict(data, device, target_nodes=list(v_star))
                # verifier = CertifiedFragileness(args, surrogate, data, device, verbose=False)
                # c_star, p_star = [], []
                # predictions, posteriors = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
                # c_star = _second_best_labels(posteriors)
                # # test_nodes = data.test_set.nodes.tolist()
                # num_processes = 5
                # with multiprocessing.Pool(processes=num_processes) as pool:
                #     pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
                #     v_star = multiprocessing.Manager().list()
                #     e_star = multiprocessing.Manager().list()
                #     iter_count = multiprocessing.Value('i', 0)
                #     for v, perb, c in pool.imap_unordered(
                #         partial(certify_fragile_with_perturbations, args=args, verifier=verifier, data=data),
                #         zip(data.test_set.nodes.tolist(), predictions, c_star)
                #     ):
                #         print('what ha')
                #         if perb is not None:
                #             v_star.append(v)
                #             e_star.append(perb)
                #             c_star.append(c)
                #             pbar.update(1)
                #         if len(v_star) == args.num_target_nodes:
                #             break
                #         iter_count.value += 1

                # p_star = target_model.predict(data, device, target_nodes=list(v_star))

                # pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
                # while len(v_star) < args.num_target_nodes:
                #     v = random.choice(test_nodes)
                #     pred, posterior = target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                #     c = _second_best_labels(posterior)[0].item()
                #     # c_list = list(range(data.num_classes))
                #     # c_list.remove(pred[0].item())
                #     # c = random.choice(c_list)

                #     t0 = time.time()
                #     perturbations = certify_fragile_with_perturbations((v, pred[0], c), args, verifier, data)
                #     print('  ==> certifing', v, f', done, in {(time.time() - t0):.2f}s')
                #     if perturbations is not None:
                #         v_star.append(v)
                #         e_star.append(perturbations)
                #         c_star.append(c)
                #         p_star.append(pred[0].item())
                #         pbar.update(1)
                    
                #     test_nodes.remove(v)
                #     iter_count += 1
                
                print('Convex searching is done, the number of iterations:', iter_count.value)
                # for c, ta, p in tqdm(zip(candidates, target_preds.tolist(), posteriors), total=len(candidates), desc=f'At trial {t}, {method} attacking'):
                #     certify_fragile_with_perturbations((c, ta, p), args, verifier, data)
                # pool = Pool(processes=5)
                # target_nodes_perts = list(tqdm(
                #     pool.imap(
                #         partial(certify_fragile_with_perturbations, args=args,verifier=verifier, data=data),
                #         zip(candidates, target_preds.tolist(), posteriors)
                #     ),
                #     total=len(candidates), desc=f'At trial {t}, certifing'
                # ))
                # pool.close()
            else:
                raise NotImplementedError('Invalid method:', method)
            total_preparation_time = time.time() - t0

            """ Simulate the behavior of malicious service provider
                that randomly sample p% edges as a subset and do the unlearning or retraining.
            """
            # for num_node_tokens in [10, 20, 30, 40, 50]:
            for num_node_tokens in [args.num_target_nodes]:
                _candidates, _perturbations, _predictions = [], [], []
                for candidate, perturbation, pred in zip(v_star[:num_node_tokens], e_star[:num_node_tokens], p_star[:num_node_tokens]):
                    if perturbation is not None and len(perturbation) > 1:
                        _candidates.append(candidate)
                        _perturbations.append(perturbation)
                        _predictions.append(pred)
                        # _attack_label.append(attack_label)
                # _candidates = np.array(_candidates)
                # _perturbations = np.array(_perturbations)
                all_perturbations = [p for pert in _perturbations for p in pert]
                _predictions = np.array(_predictions)
                # _attack_label = np.array(_attack_label)

                # add perturbations to the graph
                adv_predictions = _adv_train_predict(args, data, all_perturbations, _candidates, device)
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(all_perturbations).t()))

                tp, tn, fp, fn = {}, {}, {}, {}
                for p in args.percentages:
                    tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
                    t0 = time.time()
                    pos_verify_time = 0
                    neg_verify_time = 0
                    for idx in tqdm(range(len(_candidates)), desc=f'At trial {t}, {method} verifying {p}%'):
                        # rand_idx = random.choice(range(len(_candidates)))
                        trial_v = _candidates[idx]
                        trial_perts = _perturbations[idx]
                        if len(trial_perts) != args.num_perts:
                            logging.warning(f'The number of perturbations is less than {args.num_perts}, but %d', len(trial_perts))
                        # trial_pred = _predictions[idx]

                        adv_pred = adv_predictions[idx]
                        neg_pred, _neg_verify_time = _unlearn_train_predict(args, adv_data, trial_perts, [trial_v], device)
                        if neg_pred[0] != adv_pred:
                            tn[p] += 1
                        else:
                            fp[p] += 1
                        neg_verify_time += _neg_verify_time

                        sub_perts = random.sample(trial_perts, max(int(len(trial_perts) * p), 1))
                        pos_pred, _pos_verify_time = _unlearn_train_predict(args, adv_data, sub_perts, [trial_v], device)
                        if pos_pred[0] == adv_pred:
                            tp[p] += 1
                        else:
                            fn[p] += 1
                        pos_verify_time += _pos_verify_time
                    
                    retrain_time = time.time() - t0

                    result['trial'].append(t)
                    result['method'].append(method)
                    result['total_preparation_time'].append(total_preparation_time)
                    result['num node tokens'].append(num_node_tokens)
                    result['p'].append(p)
                    result['tp'].append(tp[p])
                    result['tn'].append(tn[p])
                    result['fp'].append(fp[p])
                    result['fn'].append(fn[p])    
                    result['retrain time'].append(retrain_time)
                    result['pos verify time'].append(pos_verify_time / len(_candidates))
                    result['neg verify time'].append(neg_verify_time / len(_candidates))

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        trial_df.to_csv(os.path.join('intermediate', f'tmp_result_{args.dataset}_at{t}.csv'))

        print('-' * 80)
        print(f'trial {t} is done')
        print(f'  ==> the target model is saved to', target_model_filename)
        print(f'  ==> the surrogate model is saved to', surrogate_model_filename)
        print(f'  ==> the data is saved to', data_filename)
        print(f'  ==> The main result at {t}:')
        print(f'  ', trial_df.groupby(['method', 'num node tokens', 'p']).mean()[['tp', 'tn', 'fp', 'fn']])
        print('-' * 80)

    try:    
        df = pd.DataFrame(result, index=None)
    except ValueError as err:
        print('result', result)
        raise err
    
    result_filename = _result_filename(args, 'verify')
    df.to_csv(os.path.join('result', result_filename))
    
    print('-' * 80)
    print('Verifing unlearning is done')
    print(f'  ==> the result file is saved to', result_filename)
    print('-' * 80)


def _verify_unlearning(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    result = defaultdict(list)
    for t in range(args.num_trials):
        logging.info('Start verifing unlearning at trial %d ...', t)
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)

        logging.info('  ==> Loading the target model ...')
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        # target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = target_train_preds
        # surr_test_preds = surrogate.predict(surrogate_data, device, target_nodes=data.test_set.nodes.tolist())

        # logging.info('  ==> Sampling node tokens ...')
        # if args.node_sampler == 'boundary':
        #     candidates = sample_node_tokens(args, data, data.test_set.nodes.tolist(), target_model, amplify=1)
        # elif args.node_sampler == 'random':
        #     candidates = random.sample(data.test_set.nodes.tolist(), args.num_target_nodes)
        # target_preds, posteriors = target_model.predict(data, device, target_nodes=candidates, return_posterior=True)
        # attack_labels = _second_best_labels(posteriors)

        # Run our method first to get candidates
        surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=False)
        surrogate.train(data, device)
        logging.info('  ==> start to run CVX searching ...')
        verifier = CertifiedFragileness(args, surrogate, data, device, verbose=False)
        v_star, e_star = [], []
        c_star, p_star = [], []
        test_nodes = data.test_set.nodes.tolist()
        iter_count = 0
        t0 = time.time()

        pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
        while len(v_star) < args.num_target_nodes:
            v = random.choice(test_nodes)
            pred, posterior = target_model.predict(data, device, target_nodes=[v], return_posterior=True)
            c_list = list(range(data.num_classes))
            c_list.remove(pred[0].item())
            c = random.choice(c_list)

            perturbations = certify_fragile_with_perturbations((v, pred[0], c), args, verifier, data)
            if perturbations is not None:
                v_star.append(v)
                e_star.append(perturbations)
                c_star.append(c)
                p_star.append(pred[0].item())
                pbar.update(1)
            
            test_nodes.remove(v)
            iter_count += 1
        total_preparation_time = time.time() - t0
        
        method = 'ours'
        # for num_node_tokens in [10, 20, 30, 40, 50]:
        for num_node_tokens in [args.num_target_nodes]:
            _candidates, _perturbations, _predictions, _attack_label = [], [], [], []
            for candidate, perturbation, pred, attack_label in zip(v_star[:num_node_tokens], e_star[:num_node_tokens], p_star[:num_node_tokens], c_star[:num_node_tokens]):
                if perturbation is not None and len(perturbation) > 1:
                    _candidates.append(candidate)
                    _perturbations.append(perturbation)
                    _predictions.append(pred)
                    _attack_label.append(attack_label)
            # _candidates = np.array(_candidates)
            # _perturbations = np.array(_perturbations)
            all_perturbations = [p for pert in _perturbations for p in pert]
            _predictions = np.array(_predictions)
            _attack_label = np.array(_attack_label)

            # add perturbations to the graph
            adv_predictions = _adv_train_predict(args, data, all_perturbations, _candidates, device)
            # how many nodes are successfully attacked
            consist_asr = np.sum(adv_predictions == _attack_label) / len(_candidates)
            asr = np.sum(adv_predictions != _predictions) / len(_candidates)
            adv_data = copy.deepcopy(data)
            adv_data.add_edges(to_undirected(torch.tensor(all_perturbations).t()))

            tp, tn, fp, fn = {}, {}, {}, {}
            for p in args.percentages:
                tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
                t0 = time.time()
                for idx in tqdm(range(len(_candidates)), desc=f'At trial {t}, {method} verifying {p}%'):
                    """ Temporarily Add
                        Each trail only has one target node, and randomly sample 1, 2, 3, 4 perturbations as a subset.
                    """

                    # rand_idx = random.choice(range(len(_candidates)))
                    trial_v = _candidates[idx]
                    trial_perts = _perturbations[idx]
                    if len(trial_perts) != args.num_perts:
                        logging.warning('The number of perturbations is less than 5, but %d', len(trial_perts))
                    # trial_pred = _predictions[idx]

                    adv_pred = adv_predictions[idx]

                    neg_pred = _unlearn_train_predict(args, adv_data, trial_perts, [trial_v], device)
                    if neg_pred[0] != adv_pred:
                        tn[p] += 1
                    else:
                        fn[p] += 1

                    sub_perts = random.sample(trial_perts, max(int(len(trial_perts) * p), 1))
                    pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [trial_v], device)
                    if pos_pred[0] == adv_pred:
                        tp[p] += 1
                    else:
                        fp[p] += 1 

                verify_time = time.time() - t0
                result['trial'].append(t)
                result['method'].append(method)
                result['total_preparation_time'].append(total_preparation_time)
                result['total_iteration'].append(iter_count)
                result['num node tokens'].append(num_node_tokens)
                result['p'].append(p)
                result['tp'].append(tp[p])
                result['tn'].append(tn[p])
                result['fp'].append(fp[p])
                result['fn'].append(fn[p])    
                result['verify time'].append(verify_time)

        for method in ['nettack']:
            t0 = time.time()
            if method == 'nettack' or method == 'minmax':
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False, fix_weight=False)
                surrogate.train(data, device)
                surrogate_preds = surrogate.predict(data, device, target_nodes=v_star)

                args.edge_sampler = method
                e_star = []
                for v, pred in tqdm(zip(v_star, p_star), total=len(v_star), desc=f'At trial {t}, {method} attacking'):
                    perturbations = sample_edge_tokens(args, data, v, surrogate, pred)
                    e_star.append(perturbations)
                # logging.info('  ==> Loading the surrogate model ...') 

                # for c, ta, p in tqdm(zip(candidates, target_preds.tolist(), posteriors), total=len(candidates), desc=f'At trial {t}, {method} attacking'):
                #     certify_fragile_with_perturbations((c, ta, p), args, verifier, data)
                # pool = Pool(processes=5)
                # target_nodes_perts = list(tqdm(
                #     pool.imap(
                #         partial(certify_fragile_with_perturbations, args=args,verifier=verifier, data=data),
                #         zip(candidates, target_preds.tolist(), posteriors)
                #     ),
                #     total=len(candidates), desc=f'At trial {t}, certifing'
                # ))
                # pool.close()
            else:
                raise NotImplementedError('Invalid method:', method)
            total_preparation_time = time.time() - t0

            """ Simulate the behavior of malicious service provider
                that randomly sample p% edges as a subset and do the unlearning or retraining.
            """
            # for num_node_tokens in [10, 20, 30, 40, 50]:
            # for num_node_tokens in [args.num_target_nodes]:
            #     # for candidate, perturbations, pred, attack_label in zip(v_star[:num_node_tokens], e_star[:num_node_tokens], p_star[:num_node_tokens], c_star[:num_node_tokens]):
            #     for candidate, perturbations, pred, attack_label in tqdm(zip(v_star[:num_node_tokens], e_star[:num_node_tokens], p_star[:num_node_tokens], c_star[:num_node_tokens]), desc='verify', total=num_node_tokens):
            #         tp, tn, fp, fn = {}, {}, {}, {}
            #         for p in args.percentages:
            #             # for idx in tqdm(range(len(perturbation)), desc=f'At trial {t}, {method} verifying {p}%'):
            #             """ Temporarily Add
            #                 Each trail only has one target node, and randomly sample 1, 2, 3, 4 perturbations as a subset.
            #             """
            #             t0 = time.time()
            #             tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0

            #             adv_pred = _adv_train_predict(args, data, perturbations, [candidate], device)[0]
            #             adv_data = copy.deepcopy(data)
            #             adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))

            #             # neg_pred = _unlearn_train_predict(args, data, trial_perts, [candidate], device)
            #             if pred != adv_pred:
            #                 tn[p] += 1
            #             else:
            #                 fn[p] += 1

            #             sub_perts = random.sample(perturbations, max(int(len(perturbations) * p), 1))
            #             pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [candidate], device)
            #             if pos_pred[0] == adv_pred:
            #                 tp[p] += 1
            #             else:
            #                 fp[p] += 1
            #             verify_time = time.time() - t0
            #             result['trial'].append(t)
            #             result['method'].append(method)
            #             result['total_preparation_time'].append(total_preparation_time)
            #             result['total_iteration'].append(iter_count)
            #             result['num node tokens'].append(num_node_tokens)
            #             result['p'].append(p)
            #             result['tp'].append(tp[p])
            #             result['tn'].append(tn[p])
            #             result['fp'].append(fp[p])
            #             result['fn'].append(fn[p])    
            #             result['verify time'].append(verify_time)

            # for num_node_tokens in [10, 20, 30, 40, 50]:
            for num_node_tokens in [args.num_target_nodes]:
                _candidates, _perturbations, _predictions, _attack_label = [], [], [], []
                for candidate, perturbation, pred, attack_label in zip(v_star[:num_node_tokens], e_star[:num_node_tokens], p_star[:num_node_tokens], c_star[:num_node_tokens]):
                    if perturbation is not None and len(perturbation) > 1:
                        _candidates.append(candidate)
                        _perturbations.append(perturbation)
                        _predictions.append(pred)
                        _attack_label.append(attack_label)
                # _candidates = np.array(_candidates)
                # _perturbations = np.array(_perturbations)
                all_perturbations = [p for pert in _perturbations for p in pert]
                _predictions = np.array(_predictions)
                _attack_label = np.array(_attack_label)

                # add perturbations to the graph
                adv_predictions = _adv_train_predict(args, data, all_perturbations, _candidates, device)
                # how many nodes are successfully attacked
                consist_asr = np.sum(adv_predictions == _attack_label) / len(_candidates)
                asr = np.sum(adv_predictions != _predictions) / len(_candidates)
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(all_perturbations).t()))

                tp, tn, fp, fn = {}, {}, {}, {}
                for p in args.percentages:
                    tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
                    t0 = time.time()
                    for idx in tqdm(range(len(_candidates)), desc=f'At trial {t}, {method} verifying {p}%'):
                        """ Temporarily Add
                            Each trail only has one target node, and randomly sample 1, 2, 3, 4 perturbations as a subset.
                        """

                        # rand_idx = random.choice(range(len(_candidates)))
                        trial_v = _candidates[idx]
                        trial_perts = _perturbations[idx]
                        if len(trial_perts) != args.num_perts:
                            logging.warning('The number of perturbations is less than 5, but %d', len(trial_perts))
                        # trial_pred = _predictions[idx]

                        adv_pred = adv_predictions[idx]

                        neg_pred = _unlearn_train_predict(args, adv_data, trial_perts, [trial_v], device)
                        if neg_pred[0] != adv_pred:
                            tn[p] += 1
                        else:
                            fn[p] += 1

                        sub_perts = random.sample(trial_perts, max(int(len(trial_perts) * p), 1))
                        pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [trial_v], device)
                        if pos_pred[0] == adv_pred:
                            tp[p] += 1
                        else:
                            fp[p] += 1 

                    verify_time = time.time() - t0
                    result['trial'].append(t)
                    result['method'].append(method)
                    result['total_preparation_time'].append(total_preparation_time)
                    result['total_iteration'].append(iter_count)
                    result['num node tokens'].append(num_node_tokens)
                    result['p'].append(p)
                    result['tp'].append(tp[p])
                    result['tn'].append(tn[p])
                    result['fp'].append(fp[p])
                    result['fn'].append(fn[p])    
                    result['verify time'].append(verify_time)

        ts = int(time.time())
        target_model_filename = _target_model_filename(args, f'main{t}_{ts}')
        target_model.save_model(os.path.join('intermediate', target_model_filename))
        surrogate_model_filename = _surrogate_model_filename(args, f'main{t}_{ts}')
        surrogate.save_model(os.path.join('intermediate', surrogate_model_filename))
        data_filename = _data_filename(args, f'main{t}_{ts}')
        with open(os.path.join('intermediate', data_filename), 'wb') as fp:
            pickle.dump(data, fp)
        perturbations_filename = _perturbations_filename(args, f'main{t}_{ts}', method)
        with open(os.path.join('intermediate', perturbations_filename), 'wb') as fp:
            pickle.dump(e_star, fp)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        trial_df.to_csv(os.path.join('intermediate', f'tmp_result_{args.dataset}_at{t}.csv'))

        print('-' * 80)
        print(f'trial {t} is done')
        print(f'  ==> the target model is saved to', target_model_filename)
        print(f'  ==> the surrogate model is saved to', surrogate_model_filename)
        print(f'  ==> the data is saved to', data_filename)
        print(f'  ==> The main result at {t}:')
        print(f'  ', trial_df.groupby(['method', 'num node tokens', 'p']).mean()[['tp', 'tn', 'fp', 'fn']])
        print('-' * 80)

    try:    
        df = pd.DataFrame(result, index=None)
    except ValueError as err:
        print('result', result)
        raise err
    
    result_filename = _result_filename(args, 'verify')
    df.to_csv(os.path.join('result', result_filename))
    
    print('-' * 80)
    print('Verifing unlearning is done')
    print(f'  ==> the result file is saved to', result_filename)
    print('-' * 80)


def efficiency(args):
    _num_behaviors = 50
    device = utils.get_device(args)
    ts = int(time.time())
    result = defaultdict(list)

    for t in range(args.num_trials): 
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        
        data = data_loader.load(args)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        # target_preds = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist()))
        surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, fix_weight=True)
        surrogate.train(surrogate_data, device)

        # surrogate_nettack = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False)
        # surrogate_nettack.train(surrogate_data, device)

        for alpha in [0.7, 0.8, 0.9, 0.95]:
            # args.num_target_nodes = _calc_m(alpha, _p[args.dataset])
            # args.num_target_nodes = math.ceil(max(math.log(1 - _alpha, 1 - _q[args.dataset][method]), math.log(1 - _beta, 1 - _p[args.dataset][method])))
            args.num_target_nodes = math.ceil(max(math.log(1 - alpha, 1 - _q[args.dataset]['ours']), math.log(1 - _beta, 1 - _p[args.dataset]['ours'])))

            for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}'):
                t0 = time.time()
                v_star, e_star, c_star = find_1pf(
                    args, surrogate, surrogate, data, device, verbose=False, 
                )
                p_star = target_model.predict(data, device, target_nodes=v_star)
                total_preparation_time = time.time() - t0
                result['trial'].append(t)
                result['method'].append('ours')
                result['alpha'].append(alpha)
                result['preparation time'].append(total_preparation_time)

                # for method in ['nettack']:
                #     t0 = time.time()
                #     if method == 'nettack':
                #         # surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pt')
                #         # surrogate.save_model(surrogate_filename)

                #         v_star, e_star, c_star = [], [], []
                #         pbar = tqdm(total=args.num_target_nodes, desc='attacking')
                #         while len(v_star) < args.num_target_nodes:
                #             v = random.choice(data.test_set.nodes.tolist())
                #             if v in v_star:
                #                 continue
                #             pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                #             nettack = ntk(surrogate_nettack, data, v, pred)
                #             nettack.reset()
                #             nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                #             E_t = nettack.structure_perturbations
                #             v_star.append(v)
                #             e_star.append(E_t)
                #             c_star.append(_second_best_labels(post)[0])
                #             pbar.update(1)
                #         pbar.close()
                #         p_star = target_model.predict(data, device, target_nodes=v_star)
                #     else:
                #         v_star, e_star, c_star = targeted_attack(surrogate_data, method, args.num_perts, t, ts, device)
                #         p_star = target_model.predict(data, device, target_nodes=v_star)
                #     total_preparation_time = time.time() - t0
                #     result['trial'].append(t)
                #     result['method'].append(method)
                #     result['running time'].append(total_preparation_time)

                # t0 = time.time()
                verification_time = 0
                retrain_time = 0
                for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                    t0 = time.time()
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))                    
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                    adv.train(adv_data, device)
                    retrain_time += time.time() - t0

                    t0 = time.time()
                    adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                    verification_time += time.time() - t0

                    # if adv_pred != p:
                    #     tn_count += 1

                    p = 0.2
                    sub_perts = random.sample(e, min(int(len(e) * (1 - p)), len(e) - 1))
                    pos_pred, veri_time, rt_time = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)
                    verification_time += veri_time
                    retrain_time += rt_time
                # verification_time = time.time() - t0
                result['verification time'].append(verification_time) 
                result['retrain time'].append(retrain_time)
                
                t0 = time.time()
                test_local = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                test_local.train(adv_data, device)
                result['local time'].append(time.time() - t0)

            _df = pd.DataFrame(result)
            print('alpha:', alpha)
            print(_df.groupby(['method', 'alpha']).mean())
        
        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('-' * 80)
        print(f'trial {t} is done')
        print(f'  ==> The main result at {t}:')
        print(f'  ', trial_df.groupby(['method']).mean())
        print('-' * 80)
   
    try:
        df = pd.DataFrame(result, index=None)
    except ValueError as err:
        print('result', result)
        raise err
    df.to_csv(os.path.join('result', f'efficiency_{args.dataset}_{ts}.csv'))
    print('-' * 80)
    print('Efficiency is done, result is saved to', f'efficiency_{args.dataset}_{ts}.csv')
    print('-' * 80)
    print()


def global_attack_for_1perturbation(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fix_seed = True
    else:
        is_fix_seed = False
 
    result = defaultdict(list)
    for _ in range(args.num_trials):
        if not is_fix_seed:
            args.seed = random.randint(0, 1e+5)
            random.seed(args.seed)
            np.random.seed(args.seed)
            torch.manual_seed(args.seed)
        data = data_loader.load(args)

        target_model = _get_target_model(args, data, device)
        target_train_preds, target_posts = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist(), return_posterior=True)
        target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
        test_nodes2preds = {v: pred for v, pred in zip(data.test_set.nodes.tolist(), target_test_preds)}

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = target_train_preds
        if args.edge_sampler == 'nettack':
            surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False)
        else:
            surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True)
        surrogate.train(surrogate_data, device)
        surr_test_preds = surrogate.predict(surrogate_data, device, target_nodes=data.test_set.nodes.tolist())

        attacker = Minimum_MinMax_Attack(surrogate, data, budget=10)
        adj = data.adjacency_matrix()
        perturbations = attacker.attack(data.x, adj, data.y, data.train_set.nodes)
        if perturbations is None or len(perturbations) == 0:
            print('No perturbations found.')
            exit(0)
        print('perturbations:', perturbations)

        adv_data = copy.deepcopy(data)
        adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
        adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
        adv.train(adv_data, device)
        adv_pred = adv.predict(adv_data, device, target_nodes=data.test_set.nodes.tolist())

        print((surr_test_preds != adv_pred).sum())


def estimate_pm_on_1pertubation_fragile_nodes(args):
    device = utils.get_device(args)
    # random generate a seed for each trial if args.seed is None
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fix_seed = True
    else:
        is_fix_seed = False
 
    result = defaultdict(list)
    for _ in range(args.num_trials):
        if not is_fix_seed:
            args.seed = random.randint(0, 1e+5)
            random.seed(args.seed)
            np.random.seed(args.seed)
            torch.manual_seed(args.seed)
        data = data_loader.load(args)

        target_model = _get_target_model(args, data, device)
        target_train_preds, target_posts = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist(), return_posterior=True)
        target_test_preds, target_test_posts = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
        test_nodes2preds = {v: pred for v, pred in zip(data.test_set.nodes.tolist(), target_test_preds)}

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = target_train_preds
        if args.edge_sampler == 'nettack':
            surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, bias=False)
        else:
            surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True)
        surrogate.train(surrogate_data, device)

        one_pert_fragile_candidates = {}
        t0 = time.time()
        if args.find_fragile_method == 'certify':
            one_pert_fragile_candidates = find_non_robust_nodes(args, surrogate, data, data.test_set.nodes.tolist())
        elif args.find_fragile_method == 'margin':
            predictions, _ = surrogate.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
            one_pert_fragile_candidates = find_1perturbation_fragile_nodes(surrogate.model, data, data.test_set.nodes.tolist(), predictions, device)
        elif args.find_fragile_method == 'boundary':
            near_boundary_nodes = {}
            for idx, p in enumerate(target_test_posts):
                # if utils.near_boundary(z, args.k):
                near_boundary_nodes[data.test_set.nodes.tolist()[idx]] = utils.boundary_score(p)
            sorted_boundary_nodes = {k: v for k,v in sorted(near_boundary_nodes.items(), key=lambda item: item[1])}
            one_pert_fragile_candidates = list(sorted_boundary_nodes.keys())[:369]
        else:
            for v in tqdm(data.test_set.nodes.tolist(), desc=f'  find 1-perturbation fragile nodes'):
                perturbations = sample_edge_tokens(args, data, v, surrogate, test_nodes2preds[v], data.y[v])
                if perturbations is None or len(perturbations) == 0:
                    continue
                one_pert_fragile_candidates[v] = perturbations
        fragile_time = int(time.time() - t0)
        print(f'Number of 1-perturbation fragile candidates: {len(one_pert_fragile_candidates)}')
        print(f' The running time: {fragile_time}s')

        one_pert_fragile_nodes = {}
        one_pert_fragile_nodes2pred = {}
        t0 = time.time()
        if args.skip_fragile_check:
            for v, perturbations in one_pert_fragile_candidates.items():
                one_pert_fragile_nodes[v] = perturbations
                one_pert_fragile_nodes2pred[v] = -1
        else:
            if args.find_fragile_method == args.find_pert_method:
                for v, perturbations in tqdm(one_pert_fragile_candidates.items(), desc=f'  verify 1-perturbation fragile nodes', total=len(one_pert_fragile_candidates)):
                    verification_edges, verification_preds = _verify_1perturbation_fragile(data, v, test_nodes2preds[v], perturbations, device)
                    if len(verification_edges) > 0:
                        value, indices, c = np.unique(verification_preds, return_inverse=True, return_counts=True)
                        if len(value) > 1:
                            filter_indices = np.where(indices == np.argmax(c))[0]
                            one_pert_fragile_nodes[v] = [e for i, e in enumerate(verification_edges) if i in filter_indices]
                            one_pert_fragile_nodes2pred[v] = value[np.argmax(c)]
                        else:
                            one_pert_fragile_nodes[v] = verification_edges
                            one_pert_fragile_nodes2pred[v] = value[0]
            else:
                args.edge_sampler = args.find_pert_method
                for v in tqdm(one_pert_fragile_candidates, 'verify 1-perturbation fragile nodes'):
                    perturbations = sample_edge_tokens(args, data, v, surrogate, test_nodes2preds[v], data.y[v])
                    if perturbations is None or len(perturbations) == 0:
                        continue
                    verification_edges, verification_preds = _verify_1perturbation_fragile(data, v, test_nodes2preds[v], perturbations, device)
                    if len(verification_edges) > 0:
                        value, indices, c = np.unique(verification_preds, return_inverse=True, return_counts=True)
                        if len(value) > 1:
                            filter_indices = np.where(indices == np.argmax(c))[0]
                            one_pert_fragile_nodes[v] = [e for i, e in enumerate(verification_edges) if i in filter_indices]
                            one_pert_fragile_nodes2pred[v] = value[np.argmax(c)]
                        else:
                            one_pert_fragile_nodes[v] = verification_edges
                            one_pert_fragile_nodes2pred[v] = value[0]
        
        print(f'Verification time: {int(time.time() - t0)}s')
        print(f'Number of verified 1-perturbation fragile nodes: {len(one_pert_fragile_nodes)}.')
        print(f'  The successful rate is {(len(one_pert_fragile_nodes) / len(data.test_set.nodes)):.4f}')
        # print('  ', one_pert_fragile_nodes)

        # for v, perturbations in tqdm(one_pert_fragile_nodes.items(), desc='  estimating pm', total=len(one_pert_fragile_nodes)): 
        for v, perturbations in one_pert_fragile_nodes.items(): 
            # clean_pred = target_model.predict(data, device, target_nodes=[v])
            print(f'Checking node {v} (clean prediction: {test_nodes2preds[v]}), with {len(perturbations)} perturbations...')

            adv_data = copy.deepcopy(data)
            adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
            adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
            adv.train(adv_data, device)
            adv_pred = adv.predict(adv_data, device, target_nodes=[v])

            is_incompleteness = check_incompleteness(args, v, test_nodes2preds[v], adv_pred[0], adv_data, perturbations, device)
            result['target'].append(v)
            result['label'].append(data.y[v].item())
            result['clean prediction'].append(test_nodes2preds[v])
            result['adv prediction'].append(adv_pred[0])
            result['perturbations'].append(perturbations)
            result['single perturbations'].append(one_pert_fragile_nodes2pred[v])
            result['is incompleteness'].append(1 if is_incompleteness else 0)
            print(f'  {v} imcompleteness: {is_incompleteness}')
            print()

        df = pd.DataFrame(result)
        result_filename = _result_filename(args, '1pert_fragile')
        df.to_csv(os.path.join('result', result_filename))

        pm = df['is incompleteness'].sum() / len(df) 
        print('p_m:', pm)
        print('Verifing the 1-perturbation fragility is Done, the result file is saved to', result_filename)


def measure_asr(args):
    device = utils.get_device(args)
    # random generate a seed for each trial if args.seed is None
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fix_seed = True
    else:
        is_fix_seed = False

    asr_list = []
    result = defaultdict(list)
    for _ in range(args.num_trials):
        if not is_fix_seed:
            args.seed = random.randint(-1e+5, 1e+5)
        data = data_loader.load(args)

        target_model = _get_target_model(args, data, device)
        target_preds, target_post = target_model.predict(
            data, device, 
            target_nodes=data.train_set.nodes.tolist(), 
            return_posterior=True
        )
        node_tokens = sample_node_tokens(
            args, data, 
            data.train_set.nodes.tolist(), 
            posterior=target_post,
            amplify=1
        )

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.labels = target_preds

        if args.edge_sampler == 'nettack':
            surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, bias=False)
        else:
            surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes)
        surrogate.train(surrogate_data, device)
        attack_success_count = 0
        for target_node in tqdm(node_tokens, desc='asr'):
            if args.verbose:
                print(f'Attack {target_node} (degree: {data.degree(target_node)})')
            clean_pred = target_model.predict(data, device, target_nodes=[target_node])

            pred, surr_logit = surrogate.predict(data, device, target_nodes=[target_node], return_logit=True)
            triggers = sample_edge_tokens(args, data, target_node, surrogate, clean_pred[0], data.y[target_node])
            # if args.verbose:
            print('E_t:', triggers)
            if triggers is None or len(triggers) == 0:
                continue
            edge_index_t = to_undirected(torch.tensor(triggers).t()) 
            adv_data = copy.deepcopy(data)
            adv_data.add_edges(edge_index_t)
            adv_model = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
            adv_model.train(adv_data, device)
            adv_pred = adv_model.predict(adv_data, device, target_nodes=[target_node])

            if adv_pred[0] != clean_pred[0]:
                attack_success_count += 1

            result['clean prediction'].append(clean_pred[0])
            result['adv prediction'].append(adv_pred[0])
            result['surr prediction'].append(pred[0])
            result['perturbations'].append(triggers)
            # result['asr'].append(attack_success_count / len(node_tokens))
        asr = attack_success_count / len(node_tokens)
        asr_list.append(asr)

 
    df = pd.DataFrame(data=result)
    print('=' * 25, 'RESULT', '=' * 25)
    print('  ', np.mean(asr_list))
    print('-' * 58)
    result_path = _result_filename(args, 'asr')
    df.to_csv(os.path.join('result', result_path))
    print('Measuring ASR is Done, the result file is saved to', result_path)

def _verify(args):
    device = utils.get_device(args)

    result = defaultdict(list)
    for t in range(args.num_trials):
        data = data_loader.load(args)

        target_model = _get_target_model(args, data, device=device)
        target_result = target_model.evaluate(data, device) 
        target_preds, target_post = target_model.predict(
            data, device,
            target_nodes=data.train_set.nodes.tolist(),
            return_posterior=True
        )
        node_tokens = sample_node_tokens(args, data, data.train_set.nodes.tolist(), posterior=target_post)

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.labels = target_preds
        surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes)
        surrogate.train(surrogate_data, device)

        attack_success_count = 0
        result = defaultdict(list)
        for target_node in tqdm(node_tokens, desc='verifing'):
            clean_pred = target_model.predict(data, device, target_nodes=[target_node], return_posterior=True)

            perturbations = sample_edge_tokens(args, data, target_node, surrogate, clean_pred[0])
            print('perturbation:', perturbations)
            if perturbations is None or len(perturbations) == 0:
                continue
                
            attack_success_count += 1

            edge_index_t = to_undirected(torch.tensor(perturbations).t())                
            adv_data = copy.deepcopy(data)
            adv_data.add_edges(edge_index_t)
            adv_model = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False)
            adv_model.train(adv_data, device)
            adv_pred = adv_model.predict(adv_data, device, target_nodes=[target_node])
            adv_result = adv_model.evaluate(data, device)

            result['target node'].append(target_node)
            result['adv edges'].append(perturbations)
            result['# of adv edges'].append(len(perturbations))
            result['clean acc'].append(target_result['accuracy'])
            result['adv acc'].append(adv_result['accuracy'])
            result['success'].append(1 if adv_pred[0] != clean_pred[0] else 0)

            # num_of_c = sum([math.comb(len(E_t), p) for p in range(1, len(E_t))])
            # num_of_flip = 0
            # statistic = defaultdict(int)
            # for length in range(1, len(E_t)):
            #     for _edges in combinations(E_t, length):
            #         sub_adv_nodes = [v for _, v in _edges]
            #         sub_adv_data = copy.deepcopy(adv_data)
            #         sub_adv_data.remove_edges(_edges)
            #         # print(adv_data.edge_index.size(1), '-', len(_edges), '=', sub_adv_data.edge_index.size(1))
            #         sub_adv_model = GNN(args, sub_adv_data.num_features, sub_adv_data.num_classes, surrogate=False)
            #         sub_adv_model.train(sub_adv_data, device)
            #         sub_adv_pred, _,  sub_adv_post = sub_adv_model.predict(sub_adv_data, device, target_nodes=[target_node], return_posterior=True)
            #         if adv_pred[0] != sub_adv_pred[0]:
            #             num_of_flip += 1
            #             statistic[len(_edges)] += 1
            if attack_success_count == args.num_target_nodes - 1:
                break
 
    df = pd.DataFrame(result)
    result_name = _result_filename(args, 'verify')
    df.to_csv(os.path.join('result', result_name))
    print('Finished, save the result to', result_name)
    return df


def calc_escape_prob_by_trials(df, num_per_trial, q):
    p_e = []
    for i in range(0, len(df), num_per_trial):
        _df = df[i: i+num_per_trial]
        K = np.sum(_df['success'].values)
        K_t = len(_df)
        p_e.append(_escape_probability(K, K_t, q))
    return np.mean(p_e)

logging.basicConfig(
    level=logging.WARNING,
    format='%(asctime)s %(name)s:%(lineno)d - %(levelname)s - %(message)s',
)

def sensitivity_b(args):
    device = utils.get_device(args)
    ts = int(time.time())
    result = defaultdict(list)

    t = args.trial
    for t in range(args.num_trials):
        # if os.path.exists(seed_file):
        #     with open(seed_file, 'rb') as fp:
        #         args.seed = pickle.load(fp)
        # else:
        seed_file = os.path.join('intermediate', f'sensitivity{t}_{ts}_seed.pkl')
        args.seed = random.randint(0, 1e+5)
        with open(seed_file, 'wb') as fp:
            pickle.dump(args.seed, fp)

        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data = data_loader.load(args)
        data_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_data.pkl')
        with open(data_filename, 'wb') as fp:
            pickle.dump(data, fp)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        target_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_target.pkl')
        target_model.save_model(target_filename)
        
        surrogate_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_surrogate.pkl')
        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        surrogate = copy.deepcopy(target_model)
        surrogate.save_model(surrogate_filename)

        # predictions, posterior = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist(), return_posterior=True)
        # attack_labels = _second_best_labels(posterior)
        
        t0 = time.time()
        args.num_perts = 30
        args.T = args.num_perts * 2
        v_star_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_v_star_b{args.num_perts}_t{args.T}.pkl')
        e_star_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_e_star_b{args.num_perts}_t{args.T}.pkl')
        c_star_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_c_star_b{args.num_perts}_t{args.T}.pkl')

        if not os.path.exists(v_star_filename) \
            or not os.path.exists(e_star_filename) \
            or not os.path.exists(c_star_filename):
        
            weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
            verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False, num_layer=1 if args.gcn_type == '1-layer' else 2)
            v_star, e_star, c_star = [], [], []
            t0 = time.time()
            pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
            iter_count = 0
            while len(v_star) < args.num_target_nodes:
                # sample a node
                v = random.choice(data.test_set.nodes.tolist())
                if v in v_star:
                    continue
                pred, post, logit = target_model.predict(data, device, target_nodes=[v], return_posterior=True, return_logit=True)
                c = _second_best_labels(post)[0]
                _, perturbation, _ = certify_fragile_with_perturbations((v, pred[0], c), args, verifier, data)
                iter_count += 1

                if perturbation is not None:
                    v_star.append(v)
                    e_star.append(perturbation)
                    c_star.append(c)
                    pbar.update(1)

                pbar.set_description(f'At trial {t}, after certifing {iter_count} nodes')
            pbar.close()
            with open(v_star_filename, 'wb') as fp:
                pickle.dump(v_star, fp)
            with open(e_star_filename, 'wb') as fp:
                pickle.dump(e_star, fp)
            with open(c_star_filename, 'wb') as fp:
                pickle.dump(c_star, fp)
            preparation_time = time.time() - t0
        else:
            with open(v_star_filename, 'rb') as fp:
                v_star = pickle.load(fp)
            with open(e_star_filename, 'rb') as fp:
                e_star = pickle.load(fp)
            with open(c_star_filename, 'rb') as fp:
                c_star = pickle.load(fp)
        p_star = target_model.predict(data, device, target_nodes=list(v_star))

        for b in [5, 10, 15, 20, 25, 30]:
            # e_star_b = [e[:b] for e in e_star]
            e_star_b = []
            for e in e_star:
                if len(e) > b:
                    e_star_b.append(random.sample(e, b))
                else:
                    e_star_b.append(e)

            ''' Inject all perturbations first instead of injecting one by one '''
            # _candidates, _perturbations, _predictions = [], [], []
            # for candidate, perturbation, pred in zip(v_star, e_star, p_star):
            #     if perturbation is not None and len(perturbation) > 1:
            #         _candidates.append(candidate)
            #         _perturbations.append(perturbation)
            #         _predictions.append(pred)
            # all_perturbations = [p for pert in _perturbations for p in pert]
            # _predictions = np.array(_predictions)

            # # add perturbations to the graph
            # adv_predictions = _adv_train_predict(args, data, all_perturbations, _candidates, device)
            # adv_data = copy.deepcopy(data)
            # adv_data.add_edges(to_undirected(torch.tensor(all_perturbations).t()))

            tp, tn, fp, fn = {}, {}, {}, {}
            for p in args.percentages:
                tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
                # for idx in tqdm(range(len(_candidates)), desc=f'At trial {t}, verifying'):
                for v, e, c, pred in tqdm(zip(v_star, e_star_b, c_star, p_star), total=len(v_star), desc=f'At trial {t}, verifying'):
                    t0 = time.time()
                    # v = _candidates[idx]
                    # e = _perturbations[idx]
                    # c = _predictions[idx]
                    # adv_pred = adv_predictions[idx]
                    adv_pred = _adv_train_predict(args, data, e, [v], device)[0]
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))

                    neg_pred, verify_time1 = _unlearn_train_predict(args, adv_data, e, [v], device)
                    if neg_pred[0] != adv_pred:
                        tn[p] += 1
                    else:
                        fp[p] += 1

                    sub_perts = random.sample(e, max(int(len(e) * (1 - p)), 1))
                    pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)
                    if pos_pred[0] == adv_pred:
                        tp[p] += 1
                    else:
                        fn[p] += 1

                    retrain_time = time.time() - t0
                result['trial'].append(t)
                result['method'].append('ours')
                # result['prepare time'].append(preparation_time)
                result['p'].append(p)
                result['b'].append(b)
                result['m'].append(args.candidate_size)
                result['t'].append(args.T)
                result['tp'].append(tp[p])
                result['tn'].append(tn[p])
                result['fp'].append(fp[p])
                result['fn'].append(fn[p])
                result['verify time'].append((verify_time1 + verify_time2) / 2)
                result['retrain time'].append(retrain_time)

        _df = pd.DataFrame(result)
        # b_df = b_df[b_df['b'] == b]
        _df = _df[_df['trial'] == t]
        _df.to_csv(os.path.join('intermediate', f'sensitivity{t}_{ts}_{args.dataset}_b{b}.csv'))

        print('-' * 80)
        print(f'trial {t} is done')
        print(f'  ==> The main result at {t}:')
        print(f'  ', _df.groupby(['method', 'p', 'b']).mean()[['tp', 'tn', 'fp', 'fn']])
        print('       ==> the data model is saved to ', data_filename)
        print('     ==> the target model is saved to ', target_filename)
        print('  ==> the surrogate model is saved to ', surrogate_filename)
        print('           ==> the v_star is saved to ', v_star_filename)
        print('           ==> the e_star is saved to ', e_star_filename)
        print('           ==> the c_star is saved to ', c_star_filename)
        print('             ==> the seed is saved to ', seed_file)
        print('-' * 80)

    df = pd.DataFrame(result)
    result_filename = f'sensitivity_{ts}_{args.dataset}_b.csv'
    df.to_csv(os.path.join('result', result_filename))

    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print('-' * 80)

def sensitivity_m(args):
    device = utils.get_device(args)

    ts = int(time.time())
    result = defaultdict(list)
    # for t in range(args.num_trials):
    t = args.trial
    seed_file = os.path.join('archive', str(t), args.dataset, 'seed_ours.pkl')
    if os.path.exists(seed_file):
        with open(seed_file, 'rb') as fp:
            args.seed = pickle.load(fp)
    else:
        args.seed = random.randint(0, 1e+5)
    torch.manual_seed(args.seed)
    torch.cuda.manual_seed_all(args.seed)
    np.random.seed(args.seed)
    random.seed(args.seed)

    data_filename = os.path.join('archive', str(t), args.dataset, 'data_ours.pkl')
    with open(data_filename, 'rb') as fp:
        data = pickle.load(fp)
    target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
    target_filename = os.path.join('archive', str(t), args.dataset, 'target_ours.pt')
    target_model.load_model(target_filename)

    surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
    surrogate_filename = os.path.join('archive', str(t), args.dataset, 'surrogate_ours.pt')
    surrogate.load_model(surrogate_filename)

    for m in [1, 2, 3, 4, 5]:
        args.candidate_size = m
        v_star_filename = os.path.join('archive', str(t), args.dataset, f'v_star_ours_b{args.num_perts}_m{m}_t{args.T}.pkl')
        e_star_filename = os.path.join('archive', str(t), args.dataset, f'e_star_ours_b{args.num_perts}_m{m}_t{args.T}.pkl')
        c_star_filename = os.path.join('archive', str(t), args.dataset, f'c_star_ours_b{args.num_perts}_m{m}_t{args.T}.pkl')
        if not os.path.exists(v_star_filename) \
            or not os.path.exists(e_star_filename) \
            or not os.path.exists(c_star_filename):
            weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
            verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False, num_layer=1 if args.gcn_type == '1-layer' else 2)
            v_star, e_star, c_star = [], [], []
            t0 = time.time()
            pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
            iter_count = 0
            while len(v_star) < args.num_target_nodes:
                # sample a node
                v = random.choice(data.test_set.nodes.tolist())
                if v in v_star:
                    continue
                pred, post, logit = target_model.predict(data, device, target_nodes=[v], return_posterior=True, return_logit=True)
                c = _second_best_labels(post)[0]
                _, perturbation, _ = certify_fragile_with_perturbations((v, pred[0], c), args, verifier, data)
                iter_count += 1

                if perturbation is not None:
                    v_star.append(v)
                    e_star.append(perturbation)
                    c_star.append(c)
                    pbar.update(1)

                pbar.set_description(f'At trial {t}, after certifing {iter_count} nodes')
            pbar.close()
            with open(e_star_filename, 'wb') as fp:
                pickle.dump(e_star, fp)
            preparation_time = time.time() - t0

            with open(v_star_filename, 'wb') as fp:
                pickle.dump(v_star, fp)
            with open(e_star_filename, 'wb') as fp:
                pickle.dump(e_star, fp)
            with open(c_star_filename, 'wb') as fp:
                pickle.dump(c_star, fp)
        else:
            with open(v_star_filename, 'rb') as fp:
                v_star = pickle.load(fp)
            with open(e_star_filename, 'rb') as fp:
                e_star = pickle.load(fp)
            with open(c_star_filename, 'rb') as fp:
                c_star = pickle.load(fp)

        p_star = target_model.predict(data, device, target_nodes=list(v_star))

        tp, tn, fp, fn = {}, {}, {}, {}
        for p in args.percentages:
            tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
            # for idx in tqdm(range(len(_candidates)), desc=f'At trial {t}, verifying'):
            for v, e, c, pred in tqdm(zip(v_star, e_star, c_star, p_star), total=len(v_star), desc=f'At trial {t}, verifying'):
                t0 = time.time()
                # v = _candidates[idx]
                # e = _perturbations[idx]
                # c = _predictions[idx]
                # adv_pred = adv_predictions[idx]
                adv_pred = _adv_train_predict(args, data, e, [v], device)[0]
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(e).t()))

                neg_pred, verify_time1 = _unlearn_train_predict(args, adv_data, e, [v], device)
                if neg_pred[0] != adv_pred:
                    tn[p] += 1
                else:
                    fp[p] += 1

                sub_perts = random.sample(e, max(int(len(e) * p), 1))
                pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)
                if pos_pred[0] == adv_pred:
                    tp[p] += 1
                else:
                    fn[p] += 1

                retrain_time = time.time() - t0
            result['trial'].append(t)
            result['method'].append('ours')
            # result['prepare time'].append(preparation_time)
            result['p'].append(p)
            result['b'].append(args.num_perts)
            result['m'].append(m)
            result['t'].append(args.T)
            result['tp'].append(tp[p])
            result['tn'].append(tn[p])
            result['fp'].append(fp[p])
            result['fn'].append(fn[p])
            result['verify time'].append((verify_time1 + verify_time2) / 2)
            result['retrain time'].append(retrain_time)
        df_m = pd.DataFrame(result)
        df_m = df_m[df_m['m'] == m]
        print('-' * 80)
        print(f'  ==> The main result at {t}:')
        print(f'  ', df_m.groupby(['method', 'p']).mean()[['tp', 'tn', 'fp', 'fn']])
        print('-' * 80)
    df = pd.DataFrame(result)
    result_filename = f'sensitivity{t}_{ts}_{args.dataset}_m.csv'
    df.to_csv(os.path.join('result', result_filename))
    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print('-' * 80)

def sensitivity_t_verify(args):
    device = utils.get_device(args)

    result = defaultdict(list)
    for t in range(args.num_trials):
        seed_filename = os.path.join('archive', str(t), 'sensitivity', 'T', 'seed.pkl')
        with open(seed_filename, 'rb') as fp:
            args.seed = pickle.load(fp)

        data_filename = os.path.join('archive', str(t), 'sensitivity', 'T', 'data.pkl')
        with open(data_filename, 'rb') as fp:
            data = pickle.load(fp)
        
        target_filename = os.path.join('archive', str(t), 'sensitivity', 'T', 'target.pt')
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.load_model(target_filename)

        surrogate_filename = os.path.join('archive', str(t), 'sensitivity', 'T', 'surrogate.pt')
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        surrogate.load_model(surrogate_filename)

        for T in [10, 20, 30, 40, 50]:
            v_star_filename = os.path.join('archive', str(t), 'sensitivity', 'T', f'v_star_b{10}_t{T}.pkl')
            e_star_filename = os.path.join('archive', str(t), 'sensitivity', 'T', f'e_star_b{10}_t{T}.pkl')
            c_star_filename = os.path.join('archive', str(t), 'sensitivity', 'T', f'c_star_b{10}_t{T}.pkl')

            with open(v_star_filename, 'rb') as fp:
                v_star = pickle.load(fp)
            with open(e_star_filename, 'rb') as fp:
                e_star = pickle.load(fp)
            with open(c_star_filename, 'rb') as fp:
                c_star = pickle.load(fp)

            p_star = target_model.predict(data, device, target_nodes=list(v_star))
            tp, tn, fp, fn = {}, {}, {}, {}
            for p in args.percentages:
                tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
                for v, e, c, pred in tqdm(zip(v_star, e_star, c_star, p_star), total=len(v_star), desc=f'At trial {t}, verifying'):
                    t0 = time.time()
                    # v = _candidates[idx]
                    # e = _perturbations[idx]
                    # c = _predictions[idx]
                    # adv_pred = adv_predictions[idx]
                    adv_pred = _adv_train_predict(args, data, e, [v], device)[0]
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))

                    neg_pred, verify_time1 = _unlearn_train_predict(args, adv_data, e, [v], device)
                    if neg_pred[0] != adv_pred:
                        tn[p] += 1
                    else:
                        fp[p] += 1

                    sub_perts = random.sample(e, max(int(len(e) * (1 - p)), 1))
                    pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)
                    if pos_pred[0] == adv_pred:
                        tp[p] += 1
                    else:
                        fn[p] += 1

                    retrain_time = time.time() - t0
                result['trial'].append(t)
                result['method'].append('ours')
                # result['prepare time'].append(preparation_time)
                result['p'].append(p)
                result['b'].append(args.num_perts)
                result['m'].append(args.candidate_size)
                result['t'].append(T)
                result['tp'].append(tp[p])
                result['tn'].append(tn[p])
                result['fp'].append(fp[p])
                result['fn'].append(fn[p])
                result['verify time'].append((verify_time1 + verify_time2) / 2)
                result['retrain time'].append(retrain_time)
        df_t = pd.DataFrame(result)
        df_t = df_t[df_t['trial'] == t]
        print('-' * 80)
        print(f'  ==> The main result at {t}:')
        print(f'  ', df_t.groupby(['method', 't']).mean()[['tp', 'tn', 'fp', 'fn']])
        print('-' * 80)

    ts = int(time.time())
    df = pd.DataFrame(result)
    result_filename = f'sensitivity_{ts}_{args.dataset}_t.csv'
    df.to_csv(os.path.join('result', result_filename))
    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print('-' * 80)

def sensitivity_t(args):
    device = utils.get_device(args)

    ts = int(time.time())
    result = defaultdict(list)
    # for t in range(args.num_trials):
    t = args.trial
    for t in range(args.num_trials):
        seed_file = os.path.join('intermediate', f'sensitivity{t}_{ts}_seed.pkl')
        args.seed = random.randint(0, 1e+5)
        with open(seed_file, 'wb') as fp:
            pickle.dump(args.seed, fp)

        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_data.pkl')
        data = data_loader.load(args)
        with open(data_filename, 'wb') as fp:
            pickle.dump(data, fp)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        target_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_target.pt')
        target_model.save_model(target_filename)


        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        surrogate = copy.deepcopy(target_model)
        surrogate_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_surrogate.pt')
        surrogate.save_model(surrogate_filename)

        # for T in [10, 20, 30, 40, 50]:
        for T in [40]:
            args.T = T

            v_star_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_v_star_b{args.num_perts}_t{args.T}.pkl')
            e_star_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_e_star_b{args.num_perts}_t{args.T}.pkl')
            c_star_filename = os.path.join('intermediate', f'sensitivity{t}_{ts}_c_star_b{args.num_perts}_t{args.T}.pkl')
            weights = copy.deepcopy([p.detach().numpy() for p in surrogate.parameters()])
            verifier = CertifiedFragilenessLazy(args, weights, data, verbose=False, num_layer=1 if args.gcn_type == '1-layer' else 2)
            v_star, e_star, c_star = [], [], []
            t0 = time.time()
            pbar = tqdm(total=args.num_target_nodes, desc=f'At trial {t}, certifing')
            iter_count = 0
            while len(v_star) < args.num_target_nodes:
                # sample a node
                v = random.choice(data.test_set.nodes.tolist())
                if v in v_star:
                    continue
                pred, post, logit = target_model.predict(data, device, target_nodes=[v], return_posterior=True, return_logit=True)
                c = _second_best_labels(post)[0]
                _, perturbation, _ = certify_fragile_with_perturbations((v, pred[0], c), args, verifier, data)
                iter_count += 1

                if perturbation is not None:
                    v_star.append(v)
                    e_star.append(perturbation)
                    c_star.append(c)
                    pbar.update(1)

                pbar.set_description(f'At trial {t}, after certifing {iter_count} nodes')
            pbar.close()
            with open(e_star_filename, 'wb') as fp:
                pickle.dump(e_star, fp)
            preparation_time = time.time() - t0

            with open(v_star_filename, 'wb') as fp:
                pickle.dump(v_star, fp)
            with open(e_star_filename, 'wb') as fp:
                pickle.dump(e_star, fp)
            with open(c_star_filename, 'wb') as fp:
                pickle.dump(c_star, fp)

            p_star = target_model.predict(data, device, target_nodes=list(v_star))

            tp, tn, fp, fn = {}, {}, {}, {}
            for p in args.percentages:
                tp[p], tn[p], fp[p], fn[p] = 0, 0, 0, 0
                for v, e, c, pred in tqdm(zip(v_star, e_star, c_star, p_star), total=len(v_star), desc=f'At trial {t}, verifying'):
                    t0 = time.time()
                    # v = _candidates[idx]
                    # e = _perturbations[idx]
                    # c = _predictions[idx]
                    # adv_pred = adv_predictions[idx]
                    adv_pred = _adv_train_predict(args, data, e, [v], device)[0]
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))

                    neg_pred, verify_time1 = _unlearn_train_predict(args, adv_data, e, [v], device)
                    if neg_pred[0] != adv_pred:
                        tn[p] += 1
                    else:
                        fp[p] += 1

                    sub_perts = random.sample(e, max(int(len(e) * (1 - p)), 1))
                    pos_pred, verify_time2 = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)
                    if pos_pred[0] == adv_pred:
                        tp[p] += 1
                    else:
                        fn[p] += 1

                    retrain_time = time.time() - t0
                result['trial'].append(t)
                result['method'].append('ours')
                # result['prepare time'].append(preparation_time)
                result['p'].append(p)
                result['b'].append(args.num_perts)
                result['m'].append(args.candidate_size)
                result['t'].append(args.T)
                result['tp'].append(tp[p])
                result['tn'].append(tn[p])
                result['fp'].append(fp[p])
                result['fn'].append(fn[p])
                result['verify time'].append((verify_time1 + verify_time2) / 2)
                result['retrain time'].append(retrain_time)
        df_t = pd.DataFrame(result)
        df_t = df_t[df_t['trial'] == t]
        print('-' * 80)
        print(f'  ==> The main result at {t}:')
        print(f'  ', df_t.groupby(['method', 't']).mean()[['tp', 'tn', 'fp', 'fn']])
        print('-' * 80)

    df = pd.DataFrame(result)
    result_filename = f'sensitivity_{ts}_{args.dataset}_t.csv'
    df.to_csv(os.path.join('result', result_filename))
    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print('-' * 80)

def composition(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fix_seed = True
    else:
        is_fix_seed = False

    ts = int(time.time())

    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fix_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args, binary=args.binary)

        if args.gcn_type == '1-layer':
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True, layer1=True)
        elif args.gcn_type == 'standard':
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        # elif args.gcn_type == 'large':
        #     args.condidate_size = 1
        #     args.hidden_size = 64
        #     target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        #     args.hidden_size = 16
        elif args.gcn_type == '3-layer':
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True, layer3=True)
        else:
            raise ValueError(f'Unknown gcn_type {args.gcn_type}')

        target_model.train(data, device)
        target_res = target_model.evaluate(data, device)
        print('target results:', target_res)

        # print(f'  ==> the target model is saved to', target_model_filename)
        weights = copy.deepcopy([p.detach().numpy() for p in target_model.parameters()])
        if args.gcn_type == '1-layer':
            num_layer = 1
        elif args.gcn_type == '3-layer':
            num_layer = 3
        else:
            num_layer = 2

        args.num_target_nodes = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
        _num_behaviors = 50

        tp, tn = 0, 0
        for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}, verifying'):
            v_star, e_star, c_star = find_1pf(
                args, target_model, target_model, data, device,
                num_layer=num_layer
            )
            p_star = target_model.predict(data, device, target_nodes=list(v_star))

            _tp_count, tn_count = 0, 0
            for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                adv_pred = _adv_train_predict(args, data, e, [v], device, args.gcn_type)[0]
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(e).t()))
                if args.gcn_type == '1-layer':
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True, layer1=True)
                elif args.gcn_type == 'standard':
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                elif args.gcn_type == '3-layer':
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True, layer3=True)
                else:
                    raise ValueError(f'Unknown gcn_type {args.gcn_type}') 
                adv.train(adv_data, device)

                if adv_pred != p:
                    tn_count += 1

                sub_perts = random.sample(e, min(int(len(e) * (1 - 0.2)), len(e) - 1))
                adv_data.remove_edges(sub_perts)
                if args.gcn_type == '1-layer':
                    unlearn = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True, layer1=True)
                elif args.gcn_type == 'standard':
                    unlearn = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                elif args.gcn_type == '3-layer':
                    unlearn = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True, layer3=True)
                else:
                    raise ValueError(f'Unknown gcn_type {args.gcn_type}')  
                unlearn.train(adv_data, device)
                unlearn_pred = unlearn.predict(adv_data, device, target_nodes=[v])
                if unlearn_pred == adv_pred:
                    _tp_count += 1

            if _tp_count != 0:
                tp += 1
            if tn_count == args.num_target_nodes:
                tn += 1

        result['trial'].append(t)
        result['gcn_type'].append(args.gcn_type)
        result['binary'].append(1 if args.binary else 0)
        # result['target node'].append(v)
        # result['adv edges'].append(e)
        # result['# of adv edges'].append(len(e))
        # result['adv prediction'].append(adv_pred)
        # result['clean prediction'].append(p)
        # result['pos pred'].append(pos_pred[0].item())
        # result['neg pred'].append(neg_pred[0].item())
        result['tp'].append(tp)
        result['tn'].append(tn)

        _df = pd.DataFrame(result)
        _df = _df[_df['trial'] == t]
        _df.to_csv(os.path.join('result', f'composition{t}_{ts}_{args.dataset}_{args.gcn_type}.csv'))
        print('-' * 80)
        print(f'  ==> The main result at {t}:')
        print(f'  ', _df.groupby(['gcn_type', 'binary']).sum()[['tp', 'tn']])
        print('-' * 80)

    df = pd.DataFrame(result)
    result_filename = f'composition_{ts}_{args.dataset}_{args.gcn_type}'
    result_filename += '_binary' if args.binary else ''
    result_filename += '.csv'
    df.to_csv(os.path.join('result', result_filename))

    print('-' * 80)
    print(f'  ==> The main result:')
    print(f'  ', df.groupby(['gcn_type', 'binary']).sum()[['tp', 'tn']])
    # print(f'  ', df.groupby(['gcn_type', 'binary']).sum()[['soundness', 'necessity']])
    # print(f'Soundness: ', df['soundness'].sum() / len(df))
    # print(f'Necessity: ', (len(_df_necessity) - _df_necessity['necessity'].sum()) / len(_df_necessity))
    # print('Composition is done, the result file is saved to', result_filename)
    print('-' * 80)


def vary_surrogate(args):
    _num_behaviors = 50
    args.num_target_nodes = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])

    device = utils.get_device(args)
    ts = int(time.time())
    result = defaultdict(list)
    # for t in range(args.num_trials):
    t = args.trial
    for t in range(args.num_trials):
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        # data_file = os.path.join('archive', str(t), args.dataset, 'data_ours.pkl')
        # with open(data_file, 'rb') as fp:
        #     data = pickle.load(fp)
        data = data_loader.load(args)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        # target_preds = target_model.predict(data, device, target_nodes=data.test_set.nodes.tolist())

        # subsample to have a partial graph as surrgoate data
        surrogate_data = copy.deepcopy(data)
        surrogate_data.partial_graph(size=args.surr_size)
        
        idx_nodes_whole = [surrogate_data.partial_to_original[v] for v in surrogate_data.train_set.nodes.tolist()]
        target_preds = target_model.predict(data, device, target_nodes=idx_nodes_whole)
        surrogate_data.train_set.labels = target_preds

        # for surrogate_type in ['simplified', 'standard', 'large', '3-layer', 'target']:
        for surrogate_type in ['simplified', '4-neurons', '8-neurons', 'standard']:
            if surrogate_type == 'simplified':
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=True, fix_weight=True, bias=False)
                surrogate.train(surrogate_data, device)
            elif surrogate_type == '4-neurons':
                args.hidden_size = 4
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=True)
                args.hidden_size = 16
                surrogate.train(surrogate_data, device)
            elif surrogate_type == '8-neurons':
                args.hidden_size = 8
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=True)
                args.hidden_size = 16
                surrogate.train(surrogate_data, device)
            elif surrogate_type == 'standard':
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=True)
                surrogate.train(surrogate_data, device)
            elif surrogate_type == 'large':
                args.hidden_size = 64
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=False)
                args.hidden_size = 16
                surrogate.train(surrogate_data, device)
            elif surrogate_type == '3-layer':
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=False, layer3=True)
                surrogate.train(surrogate_data, device)
            elif surrogate_type == 'target':
                surrogate = GNN(args, surrogate_data.num_features, surrogate_data.num_classes, surrogate=False, fix_weight=False)
                surrogate.train(data, device)

            tp, tn = 0, 0
            for _ in tqdm(range(_num_behaviors), desc=f'method={surrogate_type}'):
                if surrogate_type == 'target':
                    v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, num_layer=3 if surrogate_type=='3-layer' else 2, verbose=False)
                else:
                    v_star, e_star, c_star = find_1pf(
                        args, target_model, surrogate, data, device, 
                        num_layer=3 if surrogate_type=='3-layer' else 2, verbose=False, 
                        surrogate_data=surrogate_data
                    )
                p_star = target_model.predict(data, device, target_nodes=v_star)
                
                _tp_count, tn_count = 0, 0
                for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))                    
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                    adv.train(adv_data, device)
                    adv_pred = adv.predict(adv_data, device, target_nodes=[v])

                    if adv_pred != p:
                        tn_count += 1

                    p = 0.2
                    sub_perts = random.sample(e, min(int(len(e) * (1 - p)), len(e) - 1))
                    pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                    if pos_pred == adv_pred:
                        _tp_count += 1
                if _tp_count != 0:
                    tp += 1
                if tn_count == args.num_target_nodes:
                    tn += 1
            result['trial'].append(t)
            result['surrogate'].append(surrogate_type)
            result['tp'].append(tp)
            result['tn'].append(tn)
            result['tpr'].append(tp / _num_behaviors)
            result['tnr'].append(tn / _num_behaviors)
        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('At trial', t,' result:', trial_df.groupby(['surrogate']).mean())

    df = pd.DataFrame(result)
    result_filename = f'surrogate_{ts}_{args.dataset}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print('-' * 80)
    print('Verifing unlearning is done, the result file is saved to', result_filename)
    print('-' * 80)

def vary_unlearning(args):
    device = utils.get_device(args)

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data = data_loader.load(args)
        config = {
            'nhid': args.hidden_size,
            'dropout': args.dropout,
            'lr': args.lr,
            'idx_train': data.train_set.nodes.tolist(),
            'idx_val': data.valid_set.nodes.tolist(),
            'idx_test': data.test_set.nodes.tolist(),
        }
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        res = target_model.evaluate(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        target_valid_preds = target_model.predict(data, device, target_nodes=data.valid_set.nodes.tolist())
        print(f'  ==> The target is trained, the result is {res["accuracy"]}')

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate_data.valid_set.y = torch.from_numpy(target_valid_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, bias=True, fix_weight=True)
        surrogate.train(surrogate_data, device)

        # args.num_target_nodes = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
        args.num_target_nodes = 2

        # for unlearn_method in ['retrain', 'eraser', 'ceu', 'gnndelete']:
        for unlearn_method in ['gnndelete']:
            # p_list, neg_list = [], []
            # adv_list = []
            # if unlearn_method == 'eraser':
            #     target_model = unlearn.GraphEraser(
            #         args.seed, data.x, data.adjacency_matrix().to_dense(), data.y, 
            #         config, device, model_type='gcn', epochs=args.epochs, patience=args.patience
            #     )
            #     res = target_model.train()
            #     target_train_preds = target_model.predict(data.train_set.nodes.tolist())
            #     target_valid_preds = target_model.predict(data.valid_set.nodes.tolist())
            # elif unlearn_method == 'ceu':
            #     target_model = unlearn.CEU(
            #         args.seed, data.x, data.adjacency_matrix().to_dense(), data.y, 
            #         config, device, model_type='gcn', epochs=args.epochs, patience=args.patience
            #     )
            #     res = target_model.train()
            #     target_train_preds = target_model.predict(data.train_set.nodes.tolist())
            #     target_valid_preds = target_model.predict(data.valid_set.nodes.tolist())
            # elif unlearn_method == 'gnndelete':
            #     target_model = unlearn.GNNDelete(
            #         args.seed, data, data.x, data.adjacency_matrix().to_dense(), data.y,
            #         config, device, model_type='gcn', epochs=args.epochs, verbose=args.verbose
            #     )
            #     res = target_model.train()
            #     target_train_preds = target_model.predict(data.train_set.nodes.tolist())
            #     target_valid_preds = target_model.predict(data.valid_set.nodes.tolist())
            # else:
            #     target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            #     target_model.train(data, device)
            #     target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
            #     target_valid_preds = target_model.predict(data, device, target_nodes=data.valid_set.nodes.tolist())
            #     res = target_model.evaluate(data, device)

            print(f'  ==> The {unlearn_method} is trained, the result is {res["accuracy"]}')

            # surrogate_data = copy.deepcopy(data)
            # surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
            # surrogate_data.valid_set.y = torch.from_numpy(target_valid_preds)
            # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, bias=True, fix_weight=True)
            # surrogate.train(surrogate_data, device)
            # surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{unlearn_method}.pt')
            # surrogate.save_model(surrogate_filename)

            _num_behaviors = 3
            tp, tn = 0, 0
            pos_token_node_acc, neg_token_node_acc = 0, 0
            used_token_nodes = []
            for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}, certifing'):
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=False, used_token_nodes=used_token_nodes)
                p_star = surrogate.predict(data, device, target_nodes=v_star)
                used_token_nodes.extend(v_star)

                # perturbations = [ee for e in e_star for ee in e]

                # adv_data = copy.deepcopy(data)
                # adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                # if unlearn_method == 'retrain':
                #     unlearn_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
                #     unlearn_model.train(adv_data, device)
                #     adv_pred = unlearn_model.predict(adv_data, device, target_nodes=v_star)[0]
                # elif unlearn_method == 'eraser':
                #     unlearn_model = unlearn.GraphEraser(
                #         args.seed, adv_data.x, adv_data.adjacency_matrix().to_dense(), adv_data.y, 
                #         config, device, model_type='gcn', epochs=args.epochs, patience=args.patience
                #     )
                #     unlearn_model.train()
                #     adv_preds = unlearn_model.predict(v_star)
                # elif unlearn_method == 'ceu':
                #     unlearn_model = unlearn.CEU(
                #         args.seed, adv_data.x, adv_data.adjacency_matrix().to_dense(), adv_data.y, 
                #         config, device, model_type='gcn', epochs=args.epochs, patience=args.patience
                #     )
                #     unlearn_model.train()
                #     adv_preds = unlearn_model.predict(v_star)
                # elif unlearn_method == 'gnndelete':
                #     unlearn_model = unlearn.GNNDelete(
                #         args.seed, adv_data, adv_data.x, adv_data.adjacency_matrix().to_dense(), adv_data.y,
                #         config, device, model_type='gcn', epochs=args.epochs, verbose=args.verbose
                #     )
                #     unlearn_model.train()
                #     adv_preds = unlearn_model.predict(v_star)
                # else:
                #     raise ValueError(f'Unknown unlearn method {unlearn_method}')

                # if unlearn_method == 'retrain':
                #     neg_data = copy.deepcopy(adv_data)
                #     neg_data.remove_edges(perturbations)

                #     neg_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
                #     neg_model.train(neg_data, device)
                #     neg_preds = neg_model.predict(neg_data, device, target_nodes=v_star)[0]
                # else:
                #     neg_model = copy.deepcopy(unlearn_model)
                #     neg_model.unlearn(perturbations)
                #     neg_preds = neg_model.predict(v_star, use_retrained=True)
                # if np.sum(adv_preds == neg_preds) == args.num_target_nodes:
                #     tn += 1

                # sub_perts = random.sample(perturbations, min(int(len(perturbations) * (1 - 0.2)), len(perturbations)))
                # if unlearn_method == 'retrain':
                #     pos_preds = _unlearn_train_predict(args, adv_data, sub_perts, v_star, device)[0]
                # else:
                #     pos_model = copy.deepcopy(unlearn_model)
                #     pos_model.unlearn(sub_perts)
                #     pos_preds = pos_model.predict(v_star, use_retrained=True)
                # if np.sum(adv_preds == pos_preds) > 0:
                #     tp += 1 
                p_preds = []
                adv_preds, neg_preds, pos_preds = [], [], []
                _tp_count, _tn_count = 0, 0
                adv_acc_list, neg_acc_list, pos_acc_list = [], [], []
                for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))

                    if unlearn_method == 'retrain':
                        unlearn_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
                        unlearn_model.train(adv_data, device)
                        adv_pred = unlearn_model.predict(adv_data, device, target_nodes=[v])[0]
                        adv_res = unlearn_model.evaluate(adv_data, device)
                    elif unlearn_method == 'eraser':
                        unlearn_model = unlearn.GraphEraser(
                            args.seed, adv_data.x, adv_data.adjacency_matrix().to_dense(), adv_data.y, 
                            config, device, model_type='gcn', epochs=args.epochs, patience=args.patience
                        )
                        adv_res = unlearn_model.train()
                        adv_pred = unlearn_model.predict([v])[0]
                    elif unlearn_method == 'ceu':
                        unlearn_model = unlearn.CEU(
                            args.seed, adv_data.x, adv_data.adjacency_matrix().to_dense(), adv_data.y, 
                            config, device, model_type='gcn', epochs=args.epochs, patience=args.patience
                        )
                        adv_res = unlearn_model.train()
                        adv_pred = unlearn_model.predict([v])[0]
                    elif unlearn_method == 'gnndelete':
                        unlearn_model = unlearn.GNNDelete(
                            args.seed, adv_data, adv_data.x, adv_data.adjacency_matrix().to_dense(), adv_data.y,
                            config, device, model_type='gcn', epochs=args.epochs, verbose=args.verbose
                        )
                        adv_res = unlearn_model.train()
                        adv_pred = unlearn_model.predict([v])[0]
                    else:
                        raise ValueError(f'Unknown unlearn method {unlearn_method}')
                    
                    if unlearn_method == 'retrain':
                        neg_data = copy.deepcopy(adv_data)
                        neg_data.remove_edges(e)

                        neg_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
                        neg_model.train(neg_data, device)
                        neg_pred = neg_model.predict(neg_data, device, target_nodes=[v])[0]
                        neg_res = neg_model.evaluate(neg_data, device)
                    else:
                        neg_model = copy.deepcopy(unlearn_model)
                        neg_res = neg_model.unlearn(e)
                        neg_pred = neg_model.predict([v], use_retrained=True)[0]

                    if adv_pred != neg_pred:
                        _tn_count += 1
                    if neg_pred == p:
                        neg_token_node_acc += 1
                    # p_list.append(p)
                    # neg_list.append(neg_pred)
                    # adv_list.append(adv_pred)

                    sub_perts = random.sample(e, min(int(len(e) * (1 - 0.4)), len(e)))
                    if unlearn_method == 'retrain':
                        pos_data = copy.deepcopy(adv_data)
                        pos_data.remove_edges(sub_perts)

                        pos_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
                        pos_model.train(pos_data, device)
                        pos_pred = pos_model.predict(pos_data, device, target_nodes=[v])[0]
                        pos_res = pos_model.evaluate(pos_data, device)
                    else:
                        pos_model = copy.deepcopy(unlearn_model)
                        pos_res = pos_model.unlearn(sub_perts)
                        pos_pred = pos_model.predict([v], use_retrained=True)[0]
                    if pos_pred == adv_pred:
                        _tp_count += 1
                    if pos_pred == p:
                        pos_token_node_acc += 1

                    p_preds.append(p)
                    adv_preds.append(adv_pred)
                    neg_preds.append(neg_pred)
                    pos_preds.append(pos_pred)
                    adv_acc_list.append(adv_res['accuracy'])
                    neg_acc_list.append(neg_res['accuracy'])
                    pos_acc_list.append(pos_res['accuracy'])

                if _tp_count != 0:
                    tp += 1
                if _tn_count == args.num_target_nodes:
                    tn += 1
                print(f'At trial {t}, the prediction of {unlearn_method}:')
                print('truth:', p_preds)
                print('adv_preds:', adv_preds)
                print('neg_preds:', neg_preds)
                print('pos_preds:', pos_preds)
                print('adv_acc:', adv_acc_list)
                print('neg_acc:', neg_acc_list)
                print('pos_acc:', pos_acc_list)
                print('-' * 80)

            result['trial'].append(t)
            result['method'].append(unlearn_method)
            result['m'].append(args.num_target_nodes)
            result['TPR'].append(tp / _num_behaviors)
            result['TNR'].append(tn / _num_behaviors)
            result['adv acc'].append(np.mean(adv_acc_list))
            result['neg acc'].append(np.mean(neg_acc_list))
            result['pos acc'].append(np.mean(pos_acc_list))
            result['neg token acc'].append(neg_token_node_acc / (args.num_target_nodes * _num_behaviors))
            result['pos token acc'].append(pos_token_node_acc / (args.num_target_nodes * _num_behaviors))

            # print('-' * 50, f'{unlearn_method}', '-' * 50)
            # print(f'  ==> The main result at {t}:')
            # print(f'  ==> ground truth:', p_list)
            # print(f'  ==> adv prediction:', adv_list)
            # print(f'  ==> neg prediction:', neg_list)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        # trial_df.to_csv(os.path.join('intermediate', f'unlearning{t}_{ts}_{args.dataset}.csv'))
        print('-' * 80)
        print(f'trial {t} is done')
        print(f'  ==> The main result at {t}:')
        print(f'  ', trial_df.groupby(['method']).mean())

    df = pd.DataFrame(result)
    print(df.groupby(['method']).mean())
    result_filename = f'unlearning_{ts}_{args.dataset}.csv'
    df.to_csv(os.path.join('result', result_filename))


def test_rank(args):
    # for dataset in ['citeseer', 'lastfm', 'cs']:
    for dataset in ['lastfm']:
        args.dataset = dataset
        data = data_loader.load(args)
        adj = data.adjacency_matrix().to_dense().numpy()
        # rank = np.linalg.matrix_rank(adj)
        u, s, v = np.linalg.svd(adj)
        # print(u.shape, s.shape, v.shape)
        print('sorted singal values ', np.argsort(s)[::-1][:10])



def test_nettack_edges(args):
    device = utils.get_device(args)

    # for dataset in ['citeseer', 'lastfm', 'cs']:
    for dataset in ['lastfm']:
        args.dataset = dataset 
        if dataset == 'cs':
            args.subgraph = 10000
        
        data_filename = os.path.join('archive', '1', dataset, 'data_nettack.pkl')
        with open(data_filename, 'rb') as fp:
            data = pickle.load(fp)
        # data = data_loader.load(args)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        target_filename = os.path.join('archive', '1', dataset, 'target_nettack.pt')
        target_model.load_model(target_filename)
        # target_model.train(data, device)
        # target_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        # surrogate_data = copy.deepcopy(data)
        # surrogate_data.train_set.y = torch.from_numpy(target_preds)
        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=True, fix_weight=False)
        # surrogate.train(surrogate_data, device)
        t0 = time.time()
        # print(f'On {args.dataset}, obtaining the {data.num_nodes} posterior...')
        target_preds, posteriors = target_model.predict(data, device, return_posterior=True)
        # print('Done, duration:', int(time.time() - t0))

        # print('-' * 50, f'Dataset: {dataset}', '-' * 50)
        # print(f' ==> Proximity1, min: {np.min(prox1)}, max: {np.max(prox1)}, mean: {np.mean(prox1)}')
        # print(f' ==> Proximity2, min: {np.min(prox2)}, max: {np.max(prox2)}, mean: {np.mean(prox2)}')

        v_star_filename = os.path.join('archive', '1', dataset, 'v_star_nettack.pkl')
        with open(v_star_filename, 'rb') as fp:
            v_star = pickle.load(fp)
        e_star_filename = os.path.join('archive', '1', dataset, 'e_star_nettack.pkl')
        with open(e_star_filename, 'rb') as fp:
            e_star = pickle.load(fp)
        # c_star_filename = os.path.join('archive', '0', dataset, 'c_star_nettack.pkl')
        # with open(c_star_filename, 'rb') as fp:
        #     c_star = pickle.load(fp)

        for v, e in tqdm(zip(v_star, e_star), total=len(v_star), desc=f'At dataset {dataset}, calculating discrepancy'):
            print(f'target node {v}, label {data.y[v]}, prediction {target_preds[v]}')
            print(f'pertubations:', e)
            print(f'labels of pertubations:', [data.y[_e[1]].item() for _e in e])
            print(f'degrees of pertubations:', [data.degree(_e[1]) for _e in e])
            print('-' * 80)



def test_discrepancy(args):
    from detection import ProximityDetector
    device = utils.get_device(args)

    # for dataset in ['citeseer', 'lastfm', 'cs']:
    for dataset in ['lastfm']:
        args.dataset = dataset 
        if dataset == 'cs':
            args.subgraph = 10000
        
        data_filename = os.path.join('archive', '0', dataset, 'data_nettack.pkl')
        with open(data_filename, 'rb') as fp:
            data = pickle.load(fp)
        # data = data_loader.load(args)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        target_model.train(data, device)
        target_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=True, fix_weight=False)
        surrogate.train(surrogate_data, device)
        t0 = time.time()
        # print(f'On {args.dataset}, obtaining the {data.num_nodes} posterior...')
        _, posteriors = target_model.predict(data, device, return_posterior=True)
        # print('Done, duration:', int(time.time() - t0))

        # print('-' * 50, f'Dataset: {dataset}', '-' * 50)
        # print(f' ==> Proximity1, min: {np.min(prox1)}, max: {np.max(prox1)}, mean: {np.mean(prox1)}')
        # print(f' ==> Proximity2, min: {np.min(prox2)}, max: {np.max(prox2)}, mean: {np.mean(prox2)}')

        v_star_filename = os.path.join('archive', '0', dataset, 'v_star_nettack.pkl')
        with open(v_star_filename, 'rb') as fp:
            v_star = pickle.load(fp)
        e_star_filename = os.path.join('archive', '0', dataset, 'e_star_nettack.pkl')
        with open(e_star_filename, 'rb') as fp:
            e_star = pickle.load(fp)
        c_star_filename = os.path.join('archive', '0', dataset, 'c_star_nettack.pkl')
        with open(c_star_filename, 'rb') as fp:
            c_star = pickle.load(fp)

        prox1_orig, prox2_orig = [], []
        prox1_diff, prox2_diff = [], []
        for v, e, c in tqdm(zip(v_star, e_star, c_star), total=len(v_star), desc=f'At dataset {dataset}, calculating discrepancy'):

            kl_list = []
            for i in range(data.num_nodes):
                if i == v:
                    continue

                kl_list.append(utils.kl_divergence(posteriors[v], posteriors[i]))
            
            print('top 10:', np.argsort(kl_list)[::-1][:10])
            # detector = ProximityDetector(data, None, None, device)
            # prox1, prox2 = detector.discrepancy(data, posteriors, target_nodes=[v])
            # prox1_orig.extend(prox1)
            # prox2_orig.extend(prox2)

            # adv_data = copy.deepcopy(data)
            # adv_data.add_edges(to_undirected(torch.tensor(e).t()))

            # detector2 = ProximityDetector(adv_data, None, None, device)
            # prox1, prox2 = detector2.discrepancy(adv_data, posteriors, target_nodes=[v])
            # prox1_diff.extend(prox1)
            # prox2_diff.extend(prox2)
        
        # print('-' * 50, f'Dataset: {dataset}', '-' * 50)
        # print(f' ==> Proximity1, min: {np.min(prox1_orig)}, max: {np.max(prox1_orig)}, mean: {np.mean(prox1_orig)}')
        # print(f' ==> Proximity1, min: {np.min(prox1_diff)}, max: {np.max(prox1_diff)}, mean: {np.mean(prox1_diff)}')
        # print(f' ==> Proximity2, min: {np.min(prox2_orig)}, max: {np.max(prox2_orig)}, mean: {np.mean(prox2_orig)}')
        # print(f' ==> Proximity2, min: {np.min(prox2_diff)}, max: {np.max(prox2_diff)}, mean: {np.mean(prox2_diff)}')

def estimate_p1_p2(args):
    device = utils.get_device(args)

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data = data_loader.load(args)

        # for target in ['gat', 'sage', 'gin']:
        for target in ['gcn']:
            args.target = target
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            target_model.train(data, device)
            res = target_model.evaluate(data, device)
            target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
            target_valid_preds = target_model.predict(data, device, target_nodes=data.valid_set.nodes.tolist())

            args.target = 'gcn'
            surrogate_data = copy.deepcopy(data)
            surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
            surrogate_data.valid_set.y = torch.from_numpy(target_valid_preds)
            surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            surrogate.train(surrogate_data, device)
            args.target = target

            v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=True)
            p_star = target_model.predict(data, device, target_nodes=v_star)

            num_completeness = 0
            num_correctness = 0
            for v, pred, perturbations, attack_label in tqdm(zip(v_star, p_star, e_star, c_star), total=len(v_star), desc=f'estimating p1 and p2'):
                # result['trial'].append(t)
                # result['target node'].append(v)
                # result['ground truth'].append(data.y[v].item())
                # result['prediction'].append(pred)
                # result['attack_label'].append(attack_label)
                # result['perturbations'].append(perturbations)

                # # verification
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                adv_pred = _adv_train_predict(args, data, perturbations, [v], device)[0]
                if adv_pred != pred:
                    num_correctness += 1

                if not check_incompleteness(args, v, pred, adv_pred, adv_data, perturbations, device):
                    num_completeness += 1

            print(f'Trial {target}', t)
            print('  => The number of completeness:', num_completeness)
            print('  => The number of correctness:', num_correctness)

        result['trial'].append(t)
        result['target'].append(target)
        result['completeness'].append(num_completeness)
        result['q'].append(num_completeness / (len(v_star)))
        result['correctness'].append(num_correctness)
        result['p'].append(num_correctness / len(v_star))

    try:
        df = pd.DataFrame(result)
    except ValueError as err:
        print('result', result)
        raise err
    result_filename = f'estimate_{args.dataset}_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print(df.groupby('target').mean())

    # for t in range(args.num_trials):
    #     _df = df[df['trial'] == t]
    #     print(f'Trial {t}, the number of incompleteness:', _df['incomplete'].values.sum())
    #     # print(f'Trial {t}, the number of fragile:', _df['fragileness'].values.sum())
    # # incompleteness = df['incomplete'].values.sum()
    # # print('  ==> The incompleteness:', incompleteness)

    # result_filename = f'estimate_{ts}.csv'
    # df.to_csv(os.path.join('result', result_filename))
    # # fpr = utils.calc_fpr(df, 100)
    # # fnr = utils.calc_fnr(df, 100)
    # print('-' * 80)
    # print(f' At trial {t}', '-' * 80)
    # print(f'  => P count:', trial_df['p count'].mean())
    # print(f'  => P:', trial_df['p'].mean())
    # # print('  => FPR:', fpr)
    # # print('  => FNR:', fnr)
    # print('Verifing unlearning is done, the result file is saved to', result_filename)
    # print('-' * 80)

def estimate_lastfm(args):
    device = utils.get_device(args)

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(0, args.num_trials):
        # for method in ['sga', 'fga', 'rnd', 'ig', 'nettack', 'ours']:
        for method in ['sga']:
            if os.path.exists(os.path.join('archive', str(t), 'lastfm', f'seed_{method}.pkl')):
                with open(os.path.join('archive', str(t), 'lastfm', f'seed_{method}.pkl'), 'rb') as f:
                    args.seed = pickle.load(f)
            else:
                args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

            data_file = os.path.join('archive', str(t), 'lastfm', f'data_{method}.pkl')
            print('data_file', data_file)
            with open(data_file, 'rb') as f:
                data = pickle.load(f)
            target_model_file = os.path.join('archive', str(t), 'lastfm', f'target_{method}.pt')
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
            target_model.load_model(target_model_file)

            # surrogate_model_file = os.path.join('archive1', str(t), 'lastfm', f'surrogate_{method}.pt')
            # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=method=='nettack', fix_weight=False)
            # surrogate.load_model(surrogate_model_file)
            v_star_file = os.path.join('archive', str(t), 'lastfm', f'v_star_{args.method}.pkl')
            with open(v_star_file, 'rb') as f:
                v_star = pickle.load(f)
            e_star_file = os.path.join('archive', str(t), 'lastfm', f'e_star_{args.method}.pkl')
            with open(e_star_file, 'rb') as f:
                e_star = pickle.load(f)
            p_star = target_model.predict(data, device, target_nodes=v_star)
            v_star = v_star[:args.num_target_nodes]
            e_star = e_star[:args.num_target_nodes]
            p_star = p_star[:args.num_target_nodes]

            num_completeness = 0
            num_correctness = 0
            for v, e, pred in tqdm(zip(v_star, e_star, p_star), total=len(v_star), desc=f'Trial {t}, method {method}, evaluating'):
                if e is None or len(e) == 0:
                    continue
                if len(e) >= 5:
                    e = random.sample(e, 5)
                else:
                    raise ValueError('The number of perturbations is less than 5')

                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(e).t()))
                adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                adv_filename = os.path.join('archive', str(t), 'lastfm', f'adv_{method}_{v}.pt')
                if os.path.exists(adv_filename):
                    adv.load_model(adv_filename)
                else:
                    adv.train(adv_data, device)
                    adv.save_model(adv_filename)
                adv_pred = adv.predict(adv_data, device, target_nodes=[v])[0]
                if adv_pred != pred:
                    num_correctness += 1

                if not check_incompleteness(args, v, pred, adv_pred, adv_data, e, device):
                    num_completeness += 1
            print('Trial', t)
            print('  => The number of completeness:', num_completeness)
            print('  => The number of correctness:', num_correctness)

            result['trial'].append(t)
            result['method'].append(method)
            result['completeness'].append(num_completeness)
            result['q'].append(num_completeness / len(v_star))
            result['correctness'].append(num_correctness)
            result['p'].append(num_correctness / len(v_star))

    try:    
        df = pd.DataFrame(result)
    except ValueError as err:
        print('result', result)
        raise err
    result_filename = f'estimate_lastfm_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print(df.mean())

def estimate_p1_p2_baselines(args):
    device = utils.get_device(args)

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data = data_loader.load(args)

        for target in ['gat', 'sage', 'gin']:
            args.target = target
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            target_model.train(data, device)
            # res = target_model.evaluate(data, device)
            target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

            surrogate_data = copy.deepcopy(data)
            surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)
            surrogate_data.train_set.y = torch.from_numpy(target_train_preds)

            for method in ['sga', 'fga', 'nettack']:
                num_completeness = 0
                num_correctness = 0
                if method == 'nettack':
                    args.target = 'gcn'
                    surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False)
                    surrogate.train(surrogate_data, device)
                    args.target = target
                    # surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pt')
                    # surrogate.save_model(surrogate_filename)

                    v_star, e_star, c_star = [], [], []
                    pbar = tqdm(total=args.num_target_nodes, desc='attacking')
                    while len(v_star) < args.num_target_nodes:
                        v = random.choice(data.test_set.nodes.tolist())
                        if v in v_star:
                            continue
                        pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                        nettack = ntk(surrogate, data, v, pred)
                        nettack.reset()
                        nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                        E_t = nettack.structure_perturbations
                        v_star.append(v)
                        e_star.append(E_t)
                        c_star.append(_second_best_labels(post)[0])
                        pbar.update(1)
                    pbar.close()
                    p_star = target_model.predict(data, device, target_nodes=v_star)
                else:
                    v_star, e_star, c_star = targeted_attack(surrogate_data, method, args.num_perts, t, ts, device)
                    p_star = target_model.predict(data, device, target_nodes=v_star)

                for v, pred, perturbations, attack_label in tqdm(zip(v_star, p_star, e_star, c_star), total=len(v_star), desc=f'estimating p1 and p2'):
                    # # verification
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                    adv_pred = _adv_train_predict(args, data, perturbations, [v], device)[0]
                    if adv_pred != pred:
                        num_correctness += 1

                    if not check_incompleteness(args, v, pred, adv_pred, adv_data, perturbations, device):
                        num_completeness += 1

                result['trial'].append(t)
                result['method'].append(method)
                result['target'].append(args.target)
                result['completeness'].append(num_completeness)
                result['q'].append(num_completeness / len(v_star))
                result['correctness'].append(num_correctness)
                result['p'].append(num_correctness / len(v_star))
                
        print('Trial', t)
        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('  =>', trial_df.groupby(['method', 'target']).mean())
        # print('  => The number of completeness:', num_completeness)
        # print('  => The number of correctness:', num_correctness)

    try:    
        df = pd.DataFrame(result)
    except ValueError as err:
        print('result', result)
        raise err
    df.to_csv(os.path.join('result', f'estimate_baselines_{ts}.csv'))
    print(df.groupby(['method', 'target']).mean())

def empirical_vs_theoretical(args):
    device = utils.get_device(args)

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        args.seed = random.randint(0, 1e+5)
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)

        data = data_loader.load(args)
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        surrogate.train(surrogate_data, device)

        # for p in [0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:
        for alpha in [0.99]:
            m = _calc_m(alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
            print('Number of node tokens:', m, args.dataset)
            args.num_target_nodes = m

            tp, tn = 0, 0
            for _ in tqdm(range(50), desc=f'At trial {t}'):
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device)
                p_star = target_model.predict(data, device, target_nodes=v_star)

                _tp_count, _tn_count = 0, 0
                for v, pred, perturbations, attack_label in zip(v_star, p_star, e_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                    adv_pred = _adv_train_predict(args, data, perturbations, [v], device)[0]
                    if adv_pred != pred:
                        _tn_count += 1

                    sub_perts = random.sample(perturbations, max(int(len(perturbations) - math.ceil(m)), 1))
                    pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                    if pos_pred[0] == adv_pred:
                        _tp_count += 1

                if _tp_count != 0:
                    tp += 1
                if _tn_count == args.num_target_nodes:
                    tn += 1

            result['trial'].append(t)
            result['m'].append(m)
            result['alpha'].append(alpha)
            result['beta'].append(_beta)
            result['tp'].append(tp)
            result['tpr'].append(tp / 50)
            result['tn'].append(tn)
            result['tnr'].append(tn / 50)

    df = pd.DataFrame(result)
    result_filename = f'empirical_vs_theoretical_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print('-' * 80)
    print(df.mean())
    print('Empirical vs Theoretical is done, the result file is saved to', result_filename)
    print('-' * 80)
            

def analyze_dataset(args):

    for dataset in ['citeseer', 'lastfm', 'cs']:
        args.dataset = dataset
        if dataset == 'cs':
            args.subgraph = 10000
        data = data_loader.load(args)
        print('num nodes:', data.num_nodes)
        print('num edges:', data.edge_index.shape[1] / 2)
        print('num features:', data.num_features)
        print('num classes:', data.num_classes)
        print('label distribution:', torch.unique(data.y, return_counts=True))

        degrees = [data.degree(i) for i in range(data.num_nodes)]
        print('degree distribution:', np.unique(degrees, return_counts=True))

        # node features
        print('node features:', data.x.shape)
        # for x in data.x:
        print('number of nodes that have zero feature:', (np.sum(data.x.numpy(), axis=1) == 0).sum())
        print('mean:', np.mean(data.x.numpy(), axis=1).mean())
        print('max:', np.std(data.x.numpy(), axis=1).max())
        print('min:', np.std(data.x.numpy(), axis=1).min())
        print('std:', np.std(data.x.numpy(), axis=1).std())

def _calc_m(alpha, beta, p, q):
    m = math.ceil(math.log(1 - alpha, 1 - q))
    if m <= math.ceil(math.log(beta, p)):
        return m
    else:
        return None
    # return math.ceil(max(math.log(1 - alpha, 1 - q), math.log(1 - beta, 1 - p)))

_alpha = 0.9
_beta = 0.9
_q = {
    'cora': {'ours': 0.5},
    # 'citeseer': {'nettack': 0.34, 'sga':0.472, 'fga': 0.308, 'rnd': 0.344, 'ours': 0.788},
    'citeseer': {'nettack': 0.38, 'sga':0.472, 'fga': 0.44, 'rnd': 0.324, 'ours': 0.788},
    'lastfm': {'nettack': 0.464, 'sga':0.5, 'fga': 0.448, 'rnd': 0.44, 'ours': 0.542},
    'cs': {'nettack': 0.31, 'sga':0.348, 'fga': 0.336, 'rnd': 0.44, 'ours': 0.608},
}

_p = {
    'cora': {'ours': 0.999},
    'citeseer': {'nettack': 0.876, 'sga':0.664, 'fga': 0.832, 'rnd': 0.428, 'ours': 0.999},
    'lastfm': {'nettack': 0.848, 'sga':0.756, 'fga': 0.728, 'rnd': 0.392, 'ours': 0.98},
    'cs': {'nettack': 0.83, 'sga':0.72, 'fga': 0.796, 'rnd': 0.42, 'ours': 0.999},
}

def varying_num_token_nodes(args):
    # args.num_target_nodes = math.ceil(_calc_m(_alpha, _p[args.dataset]))
    # args.num_target_nodes = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
    incomplete_ratio = 0.2

    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)
        
        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        surrogate.train(surrogate_data, device)

        _num_behaviors = 5
        for num_token_nodes in [6]:
            # args.num_target_nodes = 2 # When P=0.9, q=0.73, the number of target nodes is 2
            # args.num_perts = num_pert_edges
            # args.T = num_pert_edges * 3
            args.num_target_nodes = num_token_nodes

            tp, tn = 0, 0
            for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}, num_token_nodes {num_token_nodes}'):
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device)
                p_star = target_model.predict(data, device, target_nodes=v_star)

                _tp_count, _tn_count = 0, 0
                for v, pred, perturbations, attack_label in zip(v_star, p_star, e_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                    adv_pred = _adv_train_predict(args, data, perturbations, [v], device)[0]
                    if adv_pred != pred:
                        _tn_count += 1

                    assert math.floor(len(perturbations) * (1-incomplete_ratio)) < len(perturbations)
                    sub_perts = random.sample(perturbations, math.floor(len(perturbations) * (1 - incomplete_ratio)))
                    pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                    if pos_pred == adv_pred:
                        _tp_count += 1
                if _tp_count > 0:
                    tp += 1
                if _tn_count == args.num_target_nodes:
                    tn += 1
            result['trial'].append(t)
            # result['num_token_nodes'].append(num_pert_edges)
            result['num_token_nodes'].append(args.num_target_nodes)
            result['incomplete_ratio'].append(incomplete_ratio)
            result['tp'].append(tp)
            result['tn'].append(tn)
            result['tpr'].append(tp / _num_behaviors)
            result['tnr'].append(tn / _num_behaviors)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print(f'At trial {t}', '-' * 80)
        print(trial_df.groupby(['num_token_nodes']).mean())
    
    df = pd.DataFrame(result)
    result_filename = f'varying_num_tokens_ours_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print(trial_df.groupby(['num_pert_edges']).mean())

def varying_num_edges(args):
    # args.num_target_nodes = math.ceil(_calc_m(_alpha, _p[args.dataset]))
    args.num_target_nodes = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
    incomplete_ratio = 0.2

    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)
        
        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        surrogate.train(surrogate_data, device)

        _num_behaviors = 50
        for num_pert_edges in [5, 10, 15, 20, 25]:
            # args.num_target_nodes = 2 # When P=0.9, q=0.73, the number of target nodes is 2
            args.num_perts = num_pert_edges
            args.T = num_pert_edges * 3

            tp, tn = 0, 0
            for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}, num_pert_edges {num_pert_edges}'):
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device)
                p_star = target_model.predict(data, device, target_nodes=v_star)

                _tp_count, _tn_count = 0, 0
                for v, pred, perturbations, attack_label in zip(v_star, p_star, e_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                    adv_pred = _adv_train_predict(args, data, perturbations, [v], device)[0]
                    if adv_pred != pred:
                        _tn_count += 1

                    assert math.floor(len(perturbations) * (1-incomplete_ratio)) < len(perturbations)
                    sub_perts = random.sample(perturbations, math.floor(len(perturbations) * (1 - incomplete_ratio)))
                    pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                    if pos_pred == adv_pred:
                        _tp_count += 1
                if _tp_count > 0:
                    tp += 1
                if _tn_count == args.num_target_nodes:
                    tn += 1
            result['trial'].append(t)
            result['num_pert_edges'].append(num_pert_edges)
            result['num_token_nodes'].append(args.num_target_nodes)
            result['incomplete_ratio'].append(incomplete_ratio)
            result['tp'].append(tp)
            result['tn'].append(tn)
            result['tpr'].append(tp / _num_behaviors)
            result['tnr'].append(tn / _num_behaviors)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print(f'At trial {t}', '-' * 80)
        print(trial_df.mean())
    
    df = pd.DataFrame(result)
    result_filename = f'varying_num_edges_ours_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print(trial_df.groupby(['num_pert_edges']).mean())

def varying_num_edges_baselines(args):
    incomplete_ratio = 0.2

    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)
        
        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        surrogate.train(surrogate_data, device)

        _num_behaviors = 50
        for num_pert_edges in [5, 10, 15, 20, 25]:
            args.num_perts = num_pert_edges
                
            for method in ['sga', 'fga', 'nettack']:
                m = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
                if m is None:
                    raise ValueError('The number of target nodes is None,', _alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
                args.num_target_nodes = m 
                tp, tn = 0, 0
                for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}, method:{method}, num_pert_edges {num_pert_edges}'):
                    if method == 'nettack':
                        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False)
                        surrogate.train(surrogate_data, device)
                        # surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pt')
                        # surrogate.save_model(surrogate_filename)

                        v_star, e_star, c_star = [], [], []
                        # pbar = tqdm(total=args.num_target_nodes, desc='attacking')
                        while len(v_star) < args.num_target_nodes:
                            v = random.choice(data.test_set.nodes.tolist())
                            if v in v_star:
                                continue
                            pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                            nettack = ntk(surrogate, data, v, pred)
                            nettack.reset()
                            nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                            E_t = nettack.structure_perturbations
                            v_star.append(v)
                            e_star.append(E_t)
                            c_star.append(_second_best_labels(post)[0])
                            # pbar.update(1)
                        # pbar.close()
                        p_star = target_model.predict(data, device, target_nodes=v_star)
                    else:
                        v_star, e_star, c_star = targeted_attack(surrogate_data, method, args.num_perts, t, ts, device)
                        p_star = target_model.predict(data, device, target_nodes=v_star)

                    _tp_count, _tn_count = 0, 0
                    for v, pred, perturbations, attack_label in zip(v_star, p_star, e_star, c_star):
                        adv_data = copy.deepcopy(data)
                        adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                        adv_pred = _adv_train_predict(args, data, perturbations, [v], device)[0]
                        if adv_pred != pred:
                            _tn_count += 1

                        assert math.floor(len(perturbations) * (1-incomplete_ratio)) < len(perturbations)
                        sub_perts = random.sample(perturbations, math.floor(len(perturbations) * (1 - incomplete_ratio)))
                        pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                        if pos_pred == adv_pred:
                            _tp_count += 1
                    if _tp_count > 0:
                        tp += 1
                    if _tn_count == args.num_target_nodes:
                        tn += 1
                result['trial'].append(t)
                result['method'].append(method)
                result['num_pert_edges'].append(num_pert_edges)
                result['num_token_nodes'].append(args.num_target_nodes)
                result['incomplete_ratio'].append(incomplete_ratio)
                result['tp'].append(tp)
                result['tn'].append(tn)
                result['tpr'].append(tp / _num_behaviors)
                result['tnr'].append(tn / _num_behaviors)
                print(f'At trial {t}, method:{method}, num_pert_edges {num_pert_edges}', '-' * 80)
                print('  => The number of completeness:', tp)
                print('  => The number of correctness:', tn)
                print('-' * 100)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print(f'At trial {t}', '-' * 80)
        print(trial_df.groupby(['method', 'num_pert_edges']).mean())
    
    df = pd.DataFrame(result)
    result_filename = f'varying_num_edges_baselines_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print(trial_df.groupby(['method', 'num_pert_edges']).mean())


def varying_incomplete_ratio(args):
    args.num_target_nodes = _calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours'])
    args.num_perts = 10

    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)
        
        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        surrogate.train(surrogate_data, device)

        _num_behaviors = 50
        # for incomplete_ratio in [0.1, 0.2, 0.3, 0.4, 0.5]:
        tn = 0
        tp = defaultdict(int)
        for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}'):
            v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device)
            p_star = target_model.predict(data, device, target_nodes=v_star)

            _tn_count = 0
            _tp_count = defaultdict(int)
            for v, pred, perturbations, attack_label in zip(v_star, p_star, e_star, c_star):
                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                adv_pred = _adv_train_predict(args, data, perturbations, [v], device)[0]
                if adv_pred != pred:
                    _tn_count += 1

                # assert math.floor(len(perturbations) * (1-incomplete_ratio)) < len(perturbations)
                for incomplete_ratio in [0.1, 0.2, 0.3, 0.4, 0.5]:
                    # assert math.floor(len(perturbations) * (1-incomplete_ratio)) < len(perturbations)
                    sub_perts = random.sample(perturbations, math.floor(len(perturbations) * (1 - incomplete_ratio)))
                    # pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                    unlearn_data = copy.deepcopy(adv_data)
                    unlearn_data.remove_edges(sub_perts)
                    unlearn = GNN(args, unlearn_data.num_features, unlearn_data.num_classes, surrogate=False, fix_weight=False)
                    unlearn.train(unlearn_data, device)
                    unlearn_pred = unlearn.predict(unlearn_data, device, target_nodes=[v])
                    if unlearn_pred == adv_pred:
                        _tp_count[incomplete_ratio] += 1

            for incomplete_ratio in [0.1, 0.2, 0.3, 0.4, 0.5]:
                if _tp_count[incomplete_ratio] > 0:
                    tp[incomplete_ratio] += 1
            if _tn_count > 0:
                tn += 1

        for incomplete_ratio in [0.1, 0.2, 0.3, 0.4, 0.5]:
            result['trial'].append(t)
            result['method'].append('ours')
            result['num_pert_edges'].append(args.num_perts)
            result['num_token_nodes'].append(args.num_target_nodes)
            result['incomplete_ratio'].append(incomplete_ratio)
            result['tp'].append(tp[incomplete_ratio])
            result['tn'].append(tn)
            result['tpr'].append(tp[incomplete_ratio] / _num_behaviors)
            result['tnr'].append(tn / _num_behaviors)
            print(f'At trial {t}, incomplete_ratio {incomplete_ratio}', '-' * 80)
            print('  => The number of completeness:', tp)
            print('  => The number of correctness:', tn)
            print('-' * 100)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print(f'At trial {t}', '-' * 80)
        print(trial_df.mean())
    
    df = pd.DataFrame(result)
    result_filename = f'varying_incomplete_ratio_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print(trial_df.groupby(['incomplete_ratio']).mean())


def varying_incomplete_ratio_baselines(args):
    args.num_perts = 10

    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        torch.cuda.manual_seed_all(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    ts = int(time.time())
    result = defaultdict(list)
    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)
        
        data = data_loader.load(args)
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        target_model.train(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        # surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=False)
        # surrogate.train(surrogate_data, device)

        _num_behaviors = 50
        for method in ['sga', 'fga', 'nettack']: 
            args.num_target_nodes = _calc_m(_alpha, _beta, _p[args.dataset][method], _q[args.dataset][method])
            tn = 0
            tp = defaultdict(int)
            for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}'):
                if method == 'nettack':
                    surrogate = GNN(args, data.num_features, data.num_classes, surrogate=True, bias=False)
                    surrogate.train(surrogate_data, device)
                    # surrogate_filename = os.path.join('intermediate', args.dataset, f'surrogate{t}_{ts}_{args.method}.pt')
                    # surrogate.save_model(surrogate_filename)

                    v_star, e_star, c_star = [], [], []
                    while len(v_star) < args.num_target_nodes:
                        v = random.choice(data.test_set.nodes.tolist())
                        if v in v_star:
                            continue
                        pred, post= target_model.predict(data, device, target_nodes=[v], return_posterior=True)
                        nettack = ntk(surrogate, data, v, pred)
                        nettack.reset()
                        nettack.attack_surrogate(args.num_perts, perturb_structure=True, perturb_features=False, direct=True, n_influencers=1)
                        E_t = nettack.structure_perturbations
                        v_star.append(v)
                        e_star.append(E_t)
                        c_star.append(_second_best_labels(post)[0])
                    p_star = target_model.predict(data, device, target_nodes=v_star)
                else:
                    v_star, e_star, c_star = targeted_attack(surrogate_data, method, args.num_perts, t, ts, device)
                    p_star = target_model.predict(data, device, target_nodes=v_star)

                _tn_count = 0
                _tp_count = defaultdict(int)
                for v, pred, perturbations, attack_label in zip(v_star, p_star, e_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=False)
                    adv.train(adv_data, device)
                    adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                    if adv_pred != pred:
                        _tn_count += 1


                    for incomplete_ratio in [0.1, 0.2, 0.3, 0.4, 0.5]:
                        # assert math.floor(len(perturbations) * (1-incomplete_ratio)) < len(perturbations)
                        sub_perts = random.sample(perturbations, math.floor(len(perturbations) * (1 - incomplete_ratio)))
                        # pos_pred = _unlearn_train_predict(args, adv_data, sub_perts, [v], device)[0]
                        unlearn_data = copy.deepcopy(adv_data)
                        unlearn_data.remove_edges(sub_perts)
                        unlearn = GNN(args, unlearn_data.num_features, unlearn_data.num_classes, surrogate=False, fix_weight=False)
                        unlearn.train(unlearn_data, device)
                        unlearn_pred = unlearn.predict(unlearn_data, device, target_nodes=[v])
                        if unlearn_pred == adv_pred:
                            _tp_count[incomplete_ratio] += 1

                for incomplete_ratio in [0.1, 0.2, 0.3, 0.4, 0.5]:
                    if _tp_count[incomplete_ratio] > 0:
                        tp[incomplete_ratio] += 1
                if _tn_count > 0:
                    tn += 1

            for incomplete_ratio in [0.1, 0.2, 0.3, 0.4, 0.5]:
                result['trial'].append(t)
                result['method'].append(method)
                result['num_pert_edges'].append(args.num_perts)
                result['num_token_nodes'].append(args.num_target_nodes)
                result['incomplete_ratio'].append(incomplete_ratio)
                result['tp'].append(tp[incomplete_ratio])
                result['tn'].append(tn)
                result['tpr'].append(tp[incomplete_ratio] / _num_behaviors)
                result['tnr'].append(tn / _num_behaviors)
                print(f'At trial {t}, method:{method}, incomplete_ratio {incomplete_ratio}', '-' * 80)
                print('  => The number of completeness:', tp)
                print('  => The number of correctness:', tn)
                print('-' * 100)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print(f'At trial {t}', '-' * 80)
        print(trial_df.groupby(['method', 'incomplete_ratio']).mean())
    
    df = pd.DataFrame(result)
    result_filename = f'varying_incomplete_ratio_baselines_{ts}.csv'
    df.to_csv(os.path.join('result', result_filename))
    print(trial_df.groupby(['method', 'incomplete_ratio']).mean())

def batch_verify(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False
    result = defaultdict(list)
    ts = int(time.time())

    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        target_model = _get_target_model(args, data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

        surrogate_data = copy.deepcopy(data)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        surrogate.train(surrogate_data, device)

        _num_behaviors = 1
        # for beta in [0.7, 0.75, 0.8, 0.85, 0.9, 0.95]:
        args.num_target_nodes = 50
        tp, tn = 0, 0
        for _ in range(_num_behaviors):
            v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=True)
            p_star = target_model.predict(data, device, target_nodes=v_star)

            perturbations = [ee for e in e_star for ee in e]

            adv_data = copy.deepcopy(data)
            adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
            adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=False)
            adv.train(adv_data, device)
            adv_preds = adv.predict(adv_data, device, target_nodes=v_star)

            tn_count = np.sum(adv_preds != p_star)

            sub_perts = []
            for e in e_star:
                sub_perts.extend(random.sample(e, min(int(len(e) * (1 - 0.2)), len(e) - 1)))

            unlearn_data = copy.deepcopy(adv_data)
            unlearn_data.remove_edges(sub_perts)
            unlearn = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=False) 
            unlearn.train(unlearn_data, device)
            unlearn_preds = unlearn.predict(unlearn_data, device, target_nodes=v_star)
            tp_count = np.sum(unlearn_preds == adv_preds)

            result['trial'].append(t)
            result['tp'].append(tp_count)
            result['tn'].append(tn_count)
            result['tpr'].append(tp_count / len(v_star))
            result['tnr'].append(tn_count / len(v_star))

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('At trial', t, 'result', trial_df)

    df = pd.DataFrame(result)
    df.to_csv(os.path.join('result', f'batch_verify_unlearning_{ts}_{args.dataset}.csv'))
    print('-' * 80)
    print('  ==>', df.mean())
    print('The result is saved to', f'batch_verify_unlearning_{ts}_{args.dataset}.csv')


def _mix_P(t, c, r, p, q):
    """ t: the number of edges that are requested to unlearn.
        c: the number of challenge edges.
        r: the number of edges that the server actually removes.
    """
    if r >= c:
        return math.comb(t - c, r -c) / math.comb(t, r) * p \
            + math.comb(t - c, r) / math.comb(t, r) \
            + (1 - math.comb(t - c, r) / math.comb(t, r) - math.comb(t - c, r) / math.comb(t, r)) * (1 - q)
    else:
        return math.comb(t - c, r) / math.comb(t, r) \
            + (1 - math.comb(t - c, r) / math.comb(t, r)) * (1 - q)

def verify_mix_unlearning(args):
    device = utils.get_device(args)

    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False
    result = defaultdict(list)
    ts = int(time.time())

    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)

        data = data_loader.load(args)
        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        target_res = target_model.evaluate(data, device)

        surrogate_data = copy.deepcopy(data)
        surrogate_data = copy.deepcopy(data)
        surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)
        surrogate_data.train_set.y = torch.from_numpy(target_train_preds)

        surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, bias=True)
        surrogate.train(surrogate_data, device)
        
        _num_behaviors = 50
        _num_unlearn_edges = 40
        for num_challenges in [0.3]:
            num_challenge_edges = math.ceil(num_challenges * _num_unlearn_edges)
            # args.num_target_nodes = int(num_challenge_edges / args.num_perts)
            args.num_target_nodes = 4
            args.num_perts = int(num_challenge_edges / args.num_target_nodes)

            tn = 0
            tp = defaultdict(int)
            for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}'):
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=False)
                # p_star = target_model.predict(data, device, target_nodes=v_star)

                perturbations = [ee for e in e_star for ee in e]

                adv_data = copy.deepcopy(data)
                adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))
                adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                adv.train(adv_data, device)
                adv_preds = adv.predict(adv_data, device, target_nodes=v_star)

                benign_edges = random.sample(data.edges, _num_unlearn_edges - num_challenge_edges)
                unlearn_edges = benign_edges + perturbations

                neg_unlearn_data = copy.deepcopy(adv_data)
                neg_unlearn_data.remove_edges(unlearn_edges)
                neg_unlearn = GNN(args, neg_unlearn_data.num_features, neg_unlearn_data.num_classes, surrogate=False, fix_weight=True)
                neg_unlearn.train(neg_unlearn_data, device)
                neg_unlearn_preds = neg_unlearn.predict(neg_unlearn_data, device, target_nodes=v_star)
                if np.sum(adv_preds != neg_unlearn_preds) == args.num_target_nodes:
                    tn += 1
            
                for r in [0.2]:
                    sub_unlearn = random.sample(unlearn_edges, int(len(unlearn_edges) * (1 - r)))
                    pos_unlearn_data = copy.deepcopy(adv_data)
                    pos_unlearn_data.remove_edges(sub_unlearn)
                    pos_unlearn = GNN(args, pos_unlearn_data.num_features, pos_unlearn_data.num_classes, surrogate=False, fix_weight=True)
                    pos_unlearn.train(pos_unlearn_data, device)
                    pos_unlearn_preds = pos_unlearn.predict(pos_unlearn_data, device, target_nodes=v_star)
                    if np.sum(adv_preds == pos_unlearn_preds) > 0:
                        tp[r] += 1

            for incomplete_ratio, tp in tp.items():
                result['trial'].append(t)
                result['num unlearn edges'].append(len(unlearn_edges))
                # result['m'].append(args.num_target_nodes)
                result['B'].append(args.num_perts)
                result['num challenge edges'].append(num_challenge_edges)
                result['incomplete_ratio'].append(incomplete_ratio)
                result['num sub unlearn edges'].append(int(len(unlearn_edges) * incomplete_ratio))
                result['tp'].append(tp)
                result['tn'].append(tn)
                result['tpr'].append(tp / _num_behaviors)
                result['tnr'].append(tn / _num_behaviors)

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('At trial', t, 'result', trial_df)
        print('-' * 80)

    df = pd.DataFrame(result)
    df.to_csv(os.path.join('result', f'mix_verify_unlearning_{ts}_{args.dataset}.csv'))
    print('-' * 80)
    print('  ==>', df.mean())
    print('  theoretical r=5:', _mix_P(20, 10, 5, _p[args.dataset]['ours'], _q[args.dataset]['ours']))
    print('  theoretical r=5:', _mix_P(20, 10, 15, _p[args.dataset]['ours'], _q[args.dataset]['ours']))
    print('The result is saved to', f'mix_verify_unlearning_{ts}_{args.dataset}.csv')
    print('-' * 80)
    print()


def vary_target_model(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    result = defaultdict(list)
    ts = int(time.time())

    for t in range(args.num_trials):
        if not is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)
        
        data = data_loader.load(args)

        # for target in ['gat', 'sage', 'gin']:
        for target in ['gat']:
            args.target = target
            target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            target_model.train(data, device)
            target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
            target_res = target_model.evaluate(data, device)
            print(f'  ==> The {target} is trained, the result is {target_res["accuracy"]}')

            surrogate_data = copy.deepcopy(data)
            surrogate_data.y[surrogate_data.train_set.nodes] = torch.from_numpy(target_train_preds)
            surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
            args.target = 'gcn'
            surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
            surrogate.train(surrogate_data, device)
            args.target = target
            
            _num_behaviors = 50
            args.num_target_nodes = math.ceil(max(math.log(1 - _alpha, 1 - _q[args.dataset]['ours']), math.log(1 - _beta, 1 - _p[args.dataset]['ours'])))
            tp, tn = 0, 0
            for _ in tqdm(range(_num_behaviors), desc=f'At trial {t}'):
                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=False)
                p_star = target_model.predict(data, device, target_nodes=v_star)

                _tp_count, _tn_count = 0, 0
                _acc_loss = []
                for v, e, p, c in zip(v_star, e_star, p_star, c_star):
                    adv_data = copy.deepcopy(data)
                    adv_data.add_edges(to_undirected(torch.tensor(e).t()))                    
                    # adv_pred = _adv_train_predict(args, adv_data, e, [v], device)[0]
                    adv = GNN(args, adv_data.num_features, adv_data.num_classes, surrogate=False, fix_weight=True)
                    adv.train(adv_data, device)
                    adv_pred = adv.predict(adv_data, device, target_nodes=[v])
                    adv_res = adv.evaluate(adv_data, device) 
                    _acc_loss.append(np.abs(target_res['accuracy'] - adv_res['accuracy']) / target_res['accuracy'])

                    if adv_pred != p:
                        _tn_count += 1

                    # p = 0.2
                    sub_perts = random.sample(e, min(int(len(e) * (1 - 0.2)), len(e) - 1))
                    unlearn_data = copy.deepcopy(adv_data)
                    unlearn_data.remove_edges(sub_perts)
                    unlearn = GNN(args, unlearn_data.num_features, unlearn_data.num_classes, surrogate=False, fix_weight=True)
                    unlearn.train(unlearn_data, device)
                    unlearn_pred = unlearn.predict(unlearn_data, device, target_nodes=[v])
                    if unlearn_pred == adv_pred:
                        _tp_count += 1
                    
                    # if _tp_count != 0 and _tn_count != 0:
                    #     break

                # statistics['tp count'].append(_tp_count)
                # statistics['tn count'].append(_tn_count)
                # statistics['accuracy loss'].append(np.sum(_acc_loss))

                if _tp_count != 0:
                    tp += 1
                if _tn_count == args.num_target_nodes:
                    tn += 1
                # if _tp_count >= len(v_star) * 0.5:
                #     tp += 1
                # if _tn_count >= len(v_star) * 0.5:
                #     tn += 1
            # print(f'At trial {t}, TPR: {tp / 50}, TNR: {tn / 50}')
            result['trial'].append(t)
            result['target'].append(target)
            result['m'].append(args.num_target_nodes)
            result['TPR'].append(tp / _num_behaviors)
            result['TNR'].append(tn / _num_behaviors)
            result['accuracy loss'].append(np.sum(_acc_loss))

        trial_df = pd.DataFrame(result)
        trial_df = trial_df[trial_df['trial'] == t]
        print('At trial', t, 'result', trial_df.groupby(['target']).mean())
        # print('statistics', statistics)
        print('-' * 80)

    df = pd.DataFrame(result)
    df.to_csv(os.path.join('result', f'target_model_{ts}_{args.dataset}.csv'))
    print('-' * 80)
    print('  ==>', df.groupby(['target']).mean())
    print('The result is saved to', f'target_model_{ts}_{args.dataset}.csv')

def mix_guarantee(args):
    _t = 40
    for c in [0.3, 0.4, 0.5, 0.6, 0.7]:
        p = _mix_P(_t, int(_t * c), int(_t * 0.8), _p[args.dataset]['ours'], _q[args.dataset]['ours'])
        m1 = math.ceil(math.log(1 - 0.9, p))
        m2 = math.ceil(math.log(0.9, _p[args.dataset]['ours']))

        if m1 <= m2:
            m = m1
        else:
            print(f'there is no m for c={c}')
            continue
        B = (c * _t) / m
        print(f'c={c}, p={p}, m1={m1}, m2={m2}, B={B}, m={m}')

def m_guarantee():
    for alpha in [0.65]:
        # for beta in [0.6]:
        for beta in [0.65]:
            for d in ['citeseer', 'lastfm', 'cs']:
                for method in ['ours', 'nettack', 'fga', 'sga']:
                    m = _calc_m(alpha, beta, _p[d][method], _q[d][method])
                    if m is None:
                        print(f'There is no m for {d} and {method}, alpha={alpha}, beta={beta}')
                    else:
                        print(f'{d} and {method} => m={m}, alpha={alpha}, beta={beta}')

def _jaccard_similarity(u, v):
    """
    J_u,v = M_11 / (M_01 + M_10 + M_11)
    """
    M_11 = np.sum(u * v)
    M_01 = np.sum(u * (1 - v))
    M_10 = np.sum((1 - u) * v)
    return M_11 / (M_01 + M_10 + M_11)

def detection_analysis(args):

    zero_count = 0 
    non_edge_pairs = 0
    data = data_loader.load(args)

    print(np.unique(data.x.numpy(), return_counts=True))

    # for u in tqdm(range(data.num_nodes)):
    #     for v in range(u + 1, data.num_nodes):
    #         if data.has_edge(u, v):
    #             continue
    #         if data.y[u] == data.y[v]:
    #             continue
    #         js = _jaccard_similarity(data.x[u].numpy(), data.x[v].numpy())
    #         if js == 0:
    #             zero_count += 1
    #         non_edge_pairs += 1
    # print('The number of zero Jaccard similarity:', zero_count, 'out of', data.num_nodes * (data.num_nodes - 1) / 2)
    # print('The number of non-edge pairs:', zero_count/ non_edge_pairs)


    # args.num_target_nodes = math.ceil(_calc_m(_alpha, _beta, _p[args.dataset]['ours'], _q[args.dataset]['ours']))
    # device = utils.get_device(args)
    # if args.seed is not None:
    #     torch.manual_seed(args.seed)
    #     np.random.seed(args.seed)
    #     random.seed(args.seed)
    #     is_fixed_seed = True
    # else:
    #     is_fixed_seed = False
    # result = defaultdict(list)
    # ts = int(time.time())

    # for t in range(args.num_trials):
    #     if not is_fixed_seed:
    #         args.seed = random.randint(0, 1e+5)
    #         torch.manual_seed(args.seed)
    #         torch.cuda.manual_seed_all(args.seed)
    #         np.random.seed(args.seed)
    #         random.seed(args.seed)

    #     data = data_loader.load(args)
    #     target_model = _get_target_model(args, data, device)
    #     target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())

    #     surrogate_data = copy.deepcopy(data)
    #     surrogate_data.train_set.y = torch.from_numpy(target_train_preds)
    #     surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
    #     surrogate.train(surrogate_data, device)

    #     # _num_behaviors = 5
    #     # for _ in tqdm(range(_num_behaviors), desc=f'verify vs detect'):
    #     v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device)
    #     p_star = target_model.predict(data, device, target_nodes=v_star)

    #     perturbations = [ee for e in e_star for ee in e]
    #     adv_data = copy.deepcopy(data)
    #     adv_data.add_edges(to_undirected(torch.tensor(perturbations).t()))

    #     adv_data.lp_analysis(perturbations)

            # for v, e, p, c in zip(v_star, e_star, p_star, c_star):
            #     adv_data = copy.deepcopy(data)


def build_features(edges, posterior, node_features=None, verbose=False, node2idx=None):
    mia_features = []
    for i, edge in enumerate(edges):
        v1, v2 = edge
        # if v1 not in node2idx or v2 not in node2idx:
        #     drop_indices.append(i)
        #     continue
        v1_idx, v2_idx = node2idx[v1], node2idx[v2]
        post1, post2 = posterior[v1_idx], posterior[v2_idx]
        similarities = [metric(post1, post2) for metric in similarity_list]
        similarities = np.nan_to_num(similarities)
        entr1, entr2 = _entropy(post1), _entropy(post2)

        if node_features is not None:
            feat1, feat2 = node_features[v1_idx], node_features[v2_idx]
            feature_similarities = [metric(feat1, feat2) for metric in similarity_list]
            _features = np.concatenate([post1, post2, similarities, np.array(
                [entr1, entr2]), feature_similarities])
        else:
            _features = np.concatenate([
                post1, post2,
                similarities,
                np.array([entr1, entr2])
            ])
        # if verbose:
        #     print('nodes:', v1, v2)
        #     print('post:', post1, post2)
        #     print('feat:', feat1, feat2)
        #     print('output:', _features)

        mia_features.append(_features.reshape(1, -1))

    # if len(drop_indices) > int(len(edges) * 0.2):
    #     print(f'WARNING: mia dropped {len(drop_indices)} edges.')

    return np.concatenate(mia_features, axis=0)

def _generate_mia_features(edges, labels, posterior, features, node2idx):
    x_train = build_features(edges, posterior, node_features=features, node2idx=node2idx)
    y_train = np.array(labels)
    # drop_indices = np.zeros_like(y_train)
    # drop_indices[_indices] = 1
    # y_train = y_train[~(drop_indices == 1)]

    x_test = build_features(test_edges, posterior, node_features=features, node2idx=node2idx)
    y_test = np.array(test_labels)
    # drop_indices = np.zeros_like(y_test)
    # drop_indices[_indices] = 1
    # y_test = y_test[~(drop_indices == 1)]

    x_train = np.nan_to_num(x_train)
    x_test = np.nan_to_num(x_test)

    x_train = x_train.astype('float')
    x_test = x_test.astype('float')

    ss = StandardScaler()
    x_train = ss.fit_transform(x_train)
    x_test = ss.fit_transform(x_test)

    return x_train, y_train, x_test, y_test

def MIA(x_train, y_train):

    # mlp = MLPClassifier(solver='adam', batch_size=batch_size, alpha=1e-5, hidden_layer_sizes=(32, 32), random_state=1,
    #                     max_iter=100, early_stopping=True)
    mlp = MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 32),random_state=1, learning_rate_init=0.01)
    mlp.fit(x_train, y_train)
    return mlp


def evaluate_mia(mlp, x_test, y_test):
    y_pred = mlp.predict(x_test)
    test_acc = accuracy_score(y_test, y_pred)
    # auc = 0
    if np.unique(y_test).shape[0] == 1:
        auc = 0
    else:
        y_prob = mlp.predict_proba(x_test)
        auc = roc_auc_score(y_test, y_prob[:, 1])
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)

    # tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
    # tpr = tp / (tp + fn)
    # # fpr = fp / (fp+tn)
    # tnr = tn / (tn + fp)

    return test_acc, auc, precision, recall


def steal_link(args):
    device = utils.get_device(args)
    if args.seed is not None:
        torch.manual_seed(args.seed)
        np.random.seed(args.seed)
        random.seed(args.seed)
        is_fixed_seed = True
    else:
        is_fixed_seed = False

    result = defaultdict(list)
    for t in range(args.num_trials):
        if is_fixed_seed:
            args.seed = random.randint(0, 1e+5)
            torch.manual_seed(args.seed)
            torch.cuda.manual_seed_all(args.seed)
            np.random.seed(args.seed)
            random.seed(args.seed)
        
        data = data_loader.load(args)

        target_model = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
        target_model.train(data, device)
        target_train_preds = target_model.predict(data, device, target_nodes=data.train_set.nodes.tolist())
        target_res = target_model.evaluate(data, device)
        print(f'  ==> The target model is trained, the result is {target_res["accuracy"]}')

        # train a SL model
        features = data.x.to(device)
        edge_index = data.edge_index.to(device)
        with torch.no_grad():
            posterior = F.softmax(target_model(features, edge_index), dim=1).cpu().numpy()
        random_idx = random.sample(range(_edge_index.size(1)), int(len(_edge_index.size(1) * 0.5)))
        pos_edges = _edge_index[:, random_idx].t().cpu().tolist()
        neg_edges = negative_sampling(_edge_index, num_neg_samples=len(pos_edges)).t().cpu().tolist()
        train_edges = pos_edges + neg_edges
        train_labels = [1] * len(pos_edges) + [0] * len(neg_edges)
        # shuffle the training data
        random_indices = list(range(len(train_edges)))
        random.shuffle(random_indices)
        train_edges = np.array(train_edges)[random_indices].tolist()
        train_labels = np.array(train_labels)[random_indices].tolist()
        train_edges, test_edges, train_labels, test_labels = train_test_split(
            train_edges, train_labels, test_size=0.2, random_state=args.seed)
        x_train, y_train, x_test, y_test = _generate_mia_features(
            train_edges, train_labels, test_edges, test_labels, posterior, features, node2idx=None)
        mlp = MIA(x_train, y_train)

        
        
        for method in ['random', 'panda']:
            # randomly pick the same number of challenges as the number of perturbations generated by PANDA
            num_challenges = 10

            if method == 'random':
                _edge_index = utils.to_directed(data.edge_index)
                random_idx = random.sample(range(_edge_index.size(1)), num_challenges)
                unlearning_edges = _edge_index[:, random_idx].t().cpu().tolist()
            elif method == 'panda':
                surrogate = GNN(args, data.num_features, data.num_classes, surrogate=False, fix_weight=True)
                data.train_set.y = torch.from_numpy(target_train_preds)
                surrogate.train(data, device)

                v_star, e_star, c_star = find_1pf(args, target_model, surrogate, data, device, verbose=False)
                p_star = target_model.predict(data, device, target_nodes=v_star)
                unlearning_edges = [ee for e in e_star for ee in e]
            
            result_all = evaluate_mia(mlp, unlearning_edges, [0] * len(unlearning_edges))














if __name__ == '__main__':

    parser = argument.load_parser()
    parser.add_argument('--task', type=str, required=True, 
                        help='Calculate q or verify the removal probability, [q|verify].')
    parser.add_argument('--baseline', action='store_true')
    parser.add_argument('--backdoor', action='store_true')

    parser.add_argument('--num-target-nodes', dest='num_target_nodes', type=int, default=50)
    parser.add_argument('--node-sampler', dest='node_sampler', type=str, default='random', 
                        help='How to sample target nodes, distance|boundary')
    parser.add_argument('--theta', type=float, default=0.)
    # parser.add_argument('--epsilon', type=float, default=-1)
    parser.add_argument('--edge-sampler', dest='edge_sampler', type=str, default='nettack')
    parser.add_argument('--sigma', type=float, nargs='+', default=[0.01, 0.1, 1, 10])
    parser.add_argument('--check-incompleteness', action='store_true')
    parser.add_argument('--check-incorrectness', action='store_true')
    parser.add_argument('--batch-attack', action='store_true')
    
    parser.add_argument('--candidate-method', default='label', type=str)
    parser.add_argument('--candidate-size', default=1, type=int)
    parser.add_argument('--candidate-hop', type=int, default=1)

    parser.add_argument('--num-perts', dest='num_perts', type=int, default=5)
    parser.add_argument('--percentages', type=float, nargs='+', default=[0.1, 0.2])
    parser.add_argument('--methods', type=str, nargs='+', default=['ours'])
    parser.add_argument('--method', type=str, default='nettack')
    parser.add_argument('--gcn-type', type=str, default='standard')
    parser.add_argument('--binary', action='store_true')
    parser.add_argument('--trial', type=int, default=0)
    parser.add_argument('--surr-size', type=float, default=0.5)


    args = parser.parse_args()

    args.T = args.num_perts * 3
    
    # mp.set_start_method('spawn')

    if args.task == 'q': 
        # find_certified_nodes(args)
        # estimate q of setting1
        df_q = estimate_q(args)
        asr = utils.calc_asr_by_trials(df_q, args.num_target_nodes)
        print('#' * 50)
        print('                    ASR:', asr)
        if args.check_incompleteness:
            q = utils.calc_q_by_trials(df_q, args.num_target_nodes)
            print('         Incompleteness:', q) 
        if args.check_incorrectness:
            for s in args.sigma:
                q_n = utils.calc_incorrectness_noise_by_trials(df_q, args.num_target_nodes, sigma=s)
                print(f'  Incorrectness@NI@{s}:', q_n)
            ii = utils.calc_incorrectness_ii_by_trials(df_q, args.num_target_nodes)
            print('       Incorrectness@II:', ii)
            print('-' * 50)
    elif args.task == '1pf':
        find_1pf_and_perturbation(args)
    elif args.task == 'perturb':
        # find_perturbations(args)
        find_perturbations_baselines(args)
    elif args.task == 'baseline':
        verify_unlearning_baselines(args)
    elif args.task == 'verify':
        verify(args)
        # if args.baseline:
        #     # for attack in ['pgd', 'ig', 'gf', 'minmax']:
        #     for attack in ['nettack']:
        #         args.edge_sampler = attack
        #         print('-' * 80)
        #         print('Attack:', attack)
        #         print('-' * 80)
        #         verify_unlearning_baselines(args)
        # elif args.backdoor:
        #     verify_unlearning_backdoor(args)
        # else:
        #     verify_unlearning(args)
    elif args.task == 'verify_ours':
        # _verify_unlearning(args)
        # verify_unlearning_ours(args)
        new_verify_unlearning(args)
    elif args.task == 'asr':
        measure_asr(args)
        # for attack in ['nettack', 'pgd', 'ig', 'gf', 'minmax']:
        #     args.edge_sampler = attack
        #     args.seed = None
        #     measure_asr(args)

    elif args.task == 'compare':
        compare_node_samplers(args)
    elif args.task == 'fragile':
        verify_1perturbation_fragile_nodes(args)
    elif args.task == 'fragile-pm':
        estimate_pm_on_1pertubation_fragile_nodes(args)
    elif args.task == 'global':
        global_attack_for_1perturbation(args)
    elif args.task == 'efficiency':
        efficiency(args)
    elif args.task == 'sen-b':
        sensitivity_b(args)
    elif args.task == 'sen-m':
        sensitivity_m(args)
    elif args.task == 'sen-t':
        sensitivity_t(args)
    elif args.task == 'sen-t-verify':
        sensitivity_t_verify(args)
    elif args.task == 'composition':
        # for d in ['lastfm', 'cs']:
            # args.dataset = d
        for gcn_type in ['standard', '3-layer']:
            args.gcn_type = gcn_type
            for b in [True, False]:
                args.binary = b
                composition(args)
    elif args.task == 'surrogate':
        vary_surrogate(args)
    elif args.task == 'acc-loss':
        accuracy_loss(args)
    elif args.task == 'check-alg':
        # check_num_trials_and_success_rate(args)
        check_1pf_success_rate(args)
    # elif args.task == 'secret':
    #     secret_test(args)
    elif args.task == 'unlearn':
        vary_unlearning(args)
    elif args.task == 'nettack':
        # test_nettack_edges(args)
        # test_discrepancy(args)
        test_nettack_on_lastfm(args)
    elif args.task == 'rank':
        test_rank(args)
    elif args.task == 'dataset':
        analyze_dataset(args)
    elif args.task == 'mix':
        # verify_mix_unlearning(args)
        # citeseer: mix_verify_unlearning_1723832725_citeseer.csv
        for d in ['citeseer']:
            args.dataset = d
            if d == 'cs':
                args.subgraph = 10000
            verify_mix_unlearning(args)
        # verify_mix_unlearning(args)
    elif args.task == 'estimate':
        estimate_p1_p2(args)
    elif args.task == 'estimate-baselines':
        estimate_p1_p2_baselines(args)
    elif args.task == 'empirical':
        for d in ['citeseer', 'lastfm', 'cs']:
            args.dataset = d
            if d == 'cs':
                args.subgraph = 10000
            else:
                args.subgraph = None
            empirical_vs_theoretical(args)
    elif args.task == 'num-edges':
        varying_num_edges(args)
    elif args.task == 'incomplete-ratio':
        varying_incomplete_ratio(args)
    elif args.task == 'num-edges-baselines':
        varying_num_edges_baselines(args)
    elif args.task == 'incomplete-ratio-baselines':
        varying_incomplete_ratio_baselines(args)
    elif args.task == 'estimate-lastfm':
        estimate_lastfm(args)
    elif args.task == 'perform-comp':
        # for d in ['citeseer', 'cs']:
        #     args.dataset = d
        # if args.dataset == 'cs':
        #     args.subgraph = 10000
        # else:
        #     args.subgraph = None
        performance_comparison(args)
    elif args.task == 'detect':
        for d in ['citeseer', 'lastfm', 'cs']:
        # for d in ['lastfm', 'cs']:
            args.dataset = d
            if d == 'cs':
                args.subgraph = 10000
            else:
                args.subgraph = None
            detect_challenge_edges(args)

    elif args.task == 'verify-detect':
        # for d in ['cs']:
        #     args.dataset = d
        #     if d == 'cs':
        #         args.subgraph = 10000
        #     else:
        #         args.subgraph = None
        # for d in ['lastfm']:
        #     args.dataset = d
        if args.dataset == 'cs':
            args.subgraph = 10000
        verification_with_detection(args)


    elif args.task == 'data':
        analyze_dataset(args)

    elif args.task == 'batch':
        batch_verify(args)

    elif args.task == 'transfer':
        vary_target_model(args)
    elif args.task == 'num-nodes':
        varying_num_token_nodes(args)
    elif args.task == 'mix-guarantee':
        mix_guarantee(args)
    elif args.task == 'm':
        m_guarantee()
    elif args.task == 'detection-analysis':
        detection_analysis(args)
    elif args.task == 'steallink':
        steal_link(args)
    